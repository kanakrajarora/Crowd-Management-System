{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCZVLiQbJRK_",
        "outputId": "960cf29f-226f-4b29-ccbb-08520f1e002a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.78-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Downloading ultralytics-8.3.78-py3-none-any.whl (921 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m921.5/921.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.78 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics opencv-python numpy torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "w6QftyH5KrGy",
        "outputId": "c8d571a1-34f9-4534-fb1e-a9ed21068b15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82da359d-3303-4bb4-85b7-aa9da5f3bf8b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-82da359d-3303-4bb4-85b7-aa9da5f3bf8b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving gettyimages-514539492-640_adpp.mp4 to gettyimages-514539492-640_adpp (1).mp4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Select a video file to upload\n",
        "video_path = list(uploaded.keys())[0]  # Get uploaded file name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOLLe-UwnBHh",
        "outputId": "a0540af1-bf8b-406d-e3be-a7542ee033f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎥 Video FPS: 25.0\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(f\"🎥 Video FPS: {fps}\")\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkR7ZkNUJ6gK",
        "outputId": "2c970328-5a3f-4b83-862f-be9900618f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # 'yolov8x.pt' is the most accurate model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffVwsw7hLJ9a",
        "outputId": "70512f29-118d-4386-9205-96dc612d8548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 736x1280 13 persons, 1 boat, 1 suitcase, 34.9ms\n",
            "Speed: 6.3ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 boat, 34.7ms\n",
            "Speed: 6.5ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 34.7ms\n",
            "Speed: 6.6ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 34.6ms\n",
            "Speed: 7.0ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 34.9ms\n",
            "Speed: 9.4ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 34.8ms\n",
            "Speed: 6.7ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 34.6ms\n",
            "Speed: 6.8ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 54.8ms\n",
            "Speed: 8.9ms preprocess, 54.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 45.2ms\n",
            "Speed: 8.9ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 bicycle, 35.3ms\n",
            "Speed: 7.2ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 34.7ms\n",
            "Speed: 8.4ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 bicycle, 34.6ms\n",
            "Speed: 6.7ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 34.9ms\n",
            "Speed: 6.8ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 34.7ms\n",
            "Speed: 6.0ms preprocess, 34.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 34.0ms\n",
            "Speed: 7.2ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 31.6ms\n",
            "Speed: 6.8ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 31.2ms\n",
            "Speed: 6.6ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 31.3ms\n",
            "Speed: 6.3ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 34.7ms\n",
            "Speed: 8.8ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 30.9ms\n",
            "Speed: 5.7ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 30.9ms\n",
            "Speed: 6.1ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 30.9ms\n",
            "Speed: 6.8ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.8ms\n",
            "Speed: 7.6ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.5ms\n",
            "Speed: 6.7ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 handbag, 28.2ms\n",
            "Speed: 8.7ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 28.1ms\n",
            "Speed: 7.3ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.6ms\n",
            "Speed: 7.2ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 handbag, 29.2ms\n",
            "Speed: 6.9ms preprocess, 29.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 26 persons, 28.5ms\n",
            "Speed: 7.8ms preprocess, 28.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.2ms\n",
            "Speed: 7.7ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 34.5ms\n",
            "Speed: 8.6ms preprocess, 34.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.2ms\n",
            "Speed: 7.3ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 38.8ms\n",
            "Speed: 10.6ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 30.3ms\n",
            "Speed: 8.6ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 31.3ms\n",
            "Speed: 8.7ms preprocess, 31.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 33.9ms\n",
            "Speed: 9.2ms preprocess, 33.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 30.2ms\n",
            "Speed: 9.5ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 handbag, 32.9ms\n",
            "Speed: 8.9ms preprocess, 32.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 35.2ms\n",
            "Speed: 9.3ms preprocess, 35.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 34.9ms\n",
            "Speed: 10.1ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 35.3ms\n",
            "Speed: 9.8ms preprocess, 35.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 34.1ms\n",
            "Speed: 9.1ms preprocess, 34.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 34.8ms\n",
            "Speed: 9.2ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 36.2ms\n",
            "Speed: 9.9ms preprocess, 36.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 40.9ms\n",
            "Speed: 9.0ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 37.8ms\n",
            "Speed: 8.7ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 40.0ms\n",
            "Speed: 9.1ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 46.9ms\n",
            "Speed: 10.9ms preprocess, 46.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 39.3ms\n",
            "Speed: 11.6ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 44.3ms\n",
            "Speed: 9.3ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 34.7ms\n",
            "Speed: 8.4ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 34.6ms\n",
            "Speed: 7.2ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 horse, 34.8ms\n",
            "Speed: 6.8ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 horse, 34.9ms\n",
            "Speed: 5.8ms preprocess, 34.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 horse, 30.4ms\n",
            "Speed: 7.5ms preprocess, 30.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 horse, 32.5ms\n",
            "Speed: 8.3ms preprocess, 32.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 horse, 30.5ms\n",
            "Speed: 7.2ms preprocess, 30.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 suitcase, 33.2ms\n",
            "Speed: 8.0ms preprocess, 33.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 1 suitcase, 30.6ms\n",
            "Speed: 8.1ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 1 suitcase, 30.5ms\n",
            "Speed: 8.0ms preprocess, 30.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 2 horses, 1 backpack, 30.1ms\n",
            "Speed: 6.2ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 horse, 1 backpack, 1 suitcase, 30.0ms\n",
            "Speed: 7.0ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 suitcase, 29.9ms\n",
            "Speed: 7.7ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 bicycle, 1 horse, 1 suitcase, 29.7ms\n",
            "Speed: 6.6ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 horse, 1 suitcase, 29.8ms\n",
            "Speed: 5.3ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 29.8ms\n",
            "Speed: 6.6ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 horse, 30.0ms\n",
            "Speed: 6.8ms preprocess, 30.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 horse, 36.7ms\n",
            "Speed: 11.1ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 horse, 30.2ms\n",
            "Speed: 6.9ms preprocess, 30.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 1 suitcase, 29.4ms\n",
            "Speed: 9.5ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 29.2ms\n",
            "Speed: 6.7ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.2ms\n",
            "Speed: 6.3ms preprocess, 29.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.0ms\n",
            "Speed: 6.3ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 horse, 28.9ms\n",
            "Speed: 5.5ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 horse, 28.9ms\n",
            "Speed: 6.9ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.9ms\n",
            "Speed: 5.5ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 29.2ms\n",
            "Speed: 7.1ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 horse, 1 handbag, 29.0ms\n",
            "Speed: 6.3ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 handbag, 1 suitcase, 29.0ms\n",
            "Speed: 6.9ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 suitcase, 29.2ms\n",
            "Speed: 7.2ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 suitcase, 29.4ms\n",
            "Speed: 8.4ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 handbag, 1 bottle, 30.6ms\n",
            "Speed: 9.7ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 2 backpacks, 1 handbag, 1 suitcase, 29.1ms\n",
            "Speed: 6.7ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 2 backpacks, 1 handbag, 1 suitcase, 29.4ms\n",
            "Speed: 6.4ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 3 backpacks, 29.1ms\n",
            "Speed: 6.5ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 2 backpacks, 1 suitcase, 27.7ms\n",
            "Speed: 6.8ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 suitcase, 27.4ms\n",
            "Speed: 7.6ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 2 suitcases, 27.5ms\n",
            "Speed: 7.2ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 1 handbag, 1 suitcase, 27.4ms\n",
            "Speed: 6.4ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 handbag, 1 suitcase, 27.5ms\n",
            "Speed: 6.3ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 handbag, 1 suitcase, 27.9ms\n",
            "Speed: 7.9ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.8ms\n",
            "Speed: 5.6ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 33.2ms\n",
            "Speed: 5.2ms preprocess, 33.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 backpack, 32.7ms\n",
            "Speed: 7.5ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 27.9ms\n",
            "Speed: 7.0ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 28.0ms\n",
            "Speed: 7.3ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 2 backpacks, 28.3ms\n",
            "Speed: 7.2ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 29.2ms\n",
            "Speed: 7.7ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 27.4ms\n",
            "Speed: 5.6ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 34.9ms\n",
            "Speed: 8.3ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 backpack, 27.7ms\n",
            "Speed: 6.7ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 1 handbag, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 1 handbag, 28.0ms\n",
            "Speed: 7.4ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 2 backpacks, 27.8ms\n",
            "Speed: 7.1ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 27.3ms\n",
            "Speed: 6.8ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 30.8ms\n",
            "Speed: 8.2ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.6ms\n",
            "Speed: 6.4ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 2 backpacks, 27.5ms\n",
            "Speed: 7.6ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.9ms\n",
            "Speed: 7.7ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 27.6ms\n",
            "Speed: 6.8ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.4ms\n",
            "Speed: 6.3ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.5ms\n",
            "Speed: 6.3ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.3ms\n",
            "Speed: 5.9ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 handbag, 28.2ms\n",
            "Speed: 6.9ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.0ms\n",
            "Speed: 8.1ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.7ms\n",
            "Speed: 6.6ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.6ms\n",
            "Speed: 6.3ms preprocess, 27.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.8ms\n",
            "Speed: 6.6ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 31.7ms\n",
            "Speed: 8.0ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.8ms\n",
            "Speed: 6.3ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.7ms\n",
            "Speed: 6.5ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 27.6ms\n",
            "Speed: 5.5ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.2ms\n",
            "Speed: 7.5ms preprocess, 28.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.8ms\n",
            "Speed: 6.7ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.7ms\n",
            "Speed: 7.5ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.6ms\n",
            "Speed: 6.2ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.5ms\n",
            "Speed: 6.7ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 cup, 27.5ms\n",
            "Speed: 6.2ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.5ms\n",
            "Speed: 6.4ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 handbag, 27.5ms\n",
            "Speed: 7.8ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 32.5ms\n",
            "Speed: 6.5ms preprocess, 32.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 27.9ms\n",
            "Speed: 6.9ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 handbag, 27.8ms\n",
            "Speed: 6.9ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 27.9ms\n",
            "Speed: 7.5ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 27.6ms\n",
            "Speed: 6.6ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 skateboard, 27.5ms\n",
            "Speed: 5.7ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.7ms\n",
            "Speed: 6.7ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 28.5ms\n",
            "Speed: 6.3ms preprocess, 28.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 28.5ms\n",
            "Speed: 7.9ms preprocess, 28.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 28.4ms\n",
            "Speed: 10.3ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.8ms\n",
            "Speed: 5.7ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 27.9ms\n",
            "Speed: 7.7ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 28.3ms\n",
            "Speed: 6.6ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 37.5ms\n",
            "Speed: 8.2ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.2ms\n",
            "Speed: 5.7ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 28.3ms\n",
            "Speed: 6.7ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.1ms\n",
            "Speed: 8.7ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.9ms\n",
            "Speed: 7.3ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 28.8ms\n",
            "Speed: 6.4ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.3ms\n",
            "Speed: 6.8ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.6ms\n",
            "Speed: 6.6ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.4ms\n",
            "Speed: 6.6ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.8ms\n",
            "Speed: 5.7ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.5ms\n",
            "Speed: 8.5ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.4ms\n",
            "Speed: 5.4ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 30.7ms\n",
            "Speed: 6.8ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 33.3ms\n",
            "Speed: 7.4ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.8ms\n",
            "Speed: 7.2ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.5ms\n",
            "Speed: 8.3ms preprocess, 27.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.0ms\n",
            "Speed: 6.9ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.6ms\n",
            "Speed: 6.4ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.8ms\n",
            "Speed: 8.2ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.4ms\n",
            "Speed: 7.1ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.5ms\n",
            "Speed: 6.8ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 skateboard, 27.7ms\n",
            "Speed: 6.6ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.9ms\n",
            "Speed: 8.8ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 car, 27.6ms\n",
            "Speed: 7.1ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 30.9ms\n",
            "Speed: 7.6ms preprocess, 30.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.6ms\n",
            "Speed: 6.6ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.6ms\n",
            "Speed: 7.9ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 handbag, 27.6ms\n",
            "Speed: 5.5ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.4ms\n",
            "Speed: 8.0ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 37.9ms\n",
            "Speed: 12.0ms preprocess, 37.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 34.6ms\n",
            "Speed: 8.7ms preprocess, 34.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 34.7ms\n",
            "Speed: 8.4ms preprocess, 34.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 33.2ms\n",
            "Speed: 8.9ms preprocess, 33.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 31.8ms\n",
            "Speed: 8.3ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 32.0ms\n",
            "Speed: 10.3ms preprocess, 32.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 33.2ms\n",
            "Speed: 8.8ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 34.6ms\n",
            "Speed: 8.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 handbag, 32.2ms\n",
            "Speed: 18.0ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 handbag, 32.5ms\n",
            "Speed: 8.7ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 33.3ms\n",
            "Speed: 9.0ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 38.5ms\n",
            "Speed: 8.9ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 38.2ms\n",
            "Speed: 9.5ms preprocess, 38.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 34.4ms\n",
            "Speed: 11.5ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 46.2ms\n",
            "Speed: 8.4ms preprocess, 46.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 36.9ms\n",
            "Speed: 9.3ms preprocess, 36.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 39.3ms\n",
            "Speed: 9.6ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 38.4ms\n",
            "Speed: 9.8ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 handbag, 34.4ms\n",
            "Speed: 6.7ms preprocess, 34.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 handbag, 34.7ms\n",
            "Speed: 6.4ms preprocess, 34.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 handbag, 34.8ms\n",
            "Speed: 6.6ms preprocess, 34.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 handbag, 34.6ms\n",
            "Speed: 7.3ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 handbag, 36.3ms\n",
            "Speed: 6.9ms preprocess, 36.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 34.7ms\n",
            "Speed: 6.3ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 handbag, 34.0ms\n",
            "Speed: 6.8ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 33.4ms\n",
            "Speed: 8.7ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 32.0ms\n",
            "Speed: 5.8ms preprocess, 32.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 32.3ms\n",
            "Speed: 6.9ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 32.3ms\n",
            "Speed: 8.0ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 32.1ms\n",
            "Speed: 6.6ms preprocess, 32.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 32.3ms\n",
            "Speed: 5.6ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 32.3ms\n",
            "Speed: 6.3ms preprocess, 32.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 29.0ms\n",
            "Speed: 7.8ms preprocess, 29.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 28.3ms\n",
            "Speed: 7.8ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 handbag, 32.1ms\n",
            "Speed: 7.8ms preprocess, 32.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 28.7ms\n",
            "Speed: 7.4ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 28.8ms\n",
            "Speed: 6.4ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 35.1ms\n",
            "Speed: 9.3ms preprocess, 35.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.2ms\n",
            "Speed: 6.6ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.2ms\n",
            "Speed: 7.9ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.2ms\n",
            "Speed: 6.1ms preprocess, 29.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.3ms\n",
            "Speed: 6.7ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 28.2ms\n",
            "Speed: 9.2ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 28.4ms\n",
            "Speed: 8.0ms preprocess, 28.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.5ms\n",
            "Speed: 6.2ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.6ms\n",
            "Speed: 8.1ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 28.7ms\n",
            "Speed: 6.7ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.1ms\n",
            "Speed: 8.0ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.6ms\n",
            "Speed: 6.6ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 horse, 28.1ms\n",
            "Speed: 8.1ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 horse, 28.4ms\n",
            "Speed: 6.7ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 30.1ms\n",
            "Speed: 6.8ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.6ms\n",
            "Speed: 6.5ms preprocess, 28.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.2ms\n",
            "Speed: 7.0ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.3ms\n",
            "Speed: 8.1ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.0ms\n",
            "Speed: 7.5ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.4ms\n",
            "Speed: 7.0ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.9ms\n",
            "Speed: 6.8ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.8ms\n",
            "Speed: 8.4ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 33.3ms\n",
            "Speed: 7.8ms preprocess, 33.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.3ms\n",
            "Speed: 6.6ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 29.8ms\n",
            "Speed: 6.5ms preprocess, 29.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 38.7ms\n",
            "Speed: 8.5ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.7ms\n",
            "Speed: 5.4ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.8ms\n",
            "Speed: 6.3ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.4ms\n",
            "Speed: 7.8ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 29.1ms\n",
            "Speed: 6.5ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 29.2ms\n",
            "Speed: 6.6ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.0ms\n",
            "Speed: 5.6ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 29.2ms\n",
            "Speed: 7.5ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 32.7ms\n",
            "Speed: 8.7ms preprocess, 32.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 skateboard, 29.5ms\n",
            "Speed: 5.8ms preprocess, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 29.4ms\n",
            "Speed: 6.5ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 30.6ms\n",
            "Speed: 8.2ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 29.7ms\n",
            "Speed: 8.3ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 30.4ms\n",
            "Speed: 6.4ms preprocess, 30.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 29.3ms\n",
            "Speed: 5.8ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 30.3ms\n",
            "Speed: 6.6ms preprocess, 30.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 30.2ms\n",
            "Speed: 7.5ms preprocess, 30.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 32.3ms\n",
            "Speed: 7.0ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 28.2ms\n",
            "Speed: 5.8ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 28.1ms\n",
            "Speed: 6.4ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 31.0ms\n",
            "Speed: 8.9ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.8ms\n",
            "Speed: 6.5ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 28.0ms\n",
            "Speed: 7.3ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 27.4ms\n",
            "Speed: 7.6ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 31.9ms\n",
            "Speed: 6.3ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.7ms\n",
            "Speed: 6.7ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 29.5ms\n",
            "Speed: 6.7ms preprocess, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 27.6ms\n",
            "Speed: 7.1ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.7ms\n",
            "Speed: 6.5ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 27.5ms\n",
            "Speed: 5.3ms preprocess, 27.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 27.7ms\n",
            "Speed: 6.8ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.4ms\n",
            "Speed: 7.1ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 29.9ms\n",
            "Speed: 8.3ms preprocess, 29.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.2ms\n",
            "Speed: 7.8ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.4ms\n",
            "Speed: 6.8ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 28.7ms\n",
            "Speed: 5.3ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 30.9ms\n",
            "Speed: 6.5ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.4ms\n",
            "Speed: 8.7ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.5ms\n",
            "Speed: 7.0ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.6ms\n",
            "Speed: 6.7ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.5ms\n",
            "Speed: 8.1ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 27.5ms\n",
            "Speed: 6.4ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 1 umbrella, 27.5ms\n",
            "Speed: 6.5ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 10 persons, 1 umbrella, 27.1ms\n",
            "Speed: 6.4ms preprocess, 27.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 1 umbrella, 30.5ms\n",
            "Speed: 6.7ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 umbrella, 27.3ms\n",
            "Speed: 8.0ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 umbrella, 27.5ms\n",
            "Speed: 6.4ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 27.8ms\n",
            "Speed: 5.6ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 27.4ms\n",
            "Speed: 8.0ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 32.8ms\n",
            "Speed: 7.4ms preprocess, 32.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 29.1ms\n",
            "Speed: 6.7ms preprocess, 29.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 umbrella, 27.9ms\n",
            "Speed: 5.6ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 27.8ms\n",
            "Speed: 7.8ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 28.5ms\n",
            "Speed: 6.2ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 umbrella, 28.4ms\n",
            "Speed: 6.9ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 umbrella, 28.7ms\n",
            "Speed: 6.9ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.5ms\n",
            "Speed: 7.9ms preprocess, 28.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.3ms\n",
            "Speed: 8.2ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.1ms\n",
            "Speed: 6.7ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 28.9ms\n",
            "Speed: 9.1ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 29.0ms\n",
            "Speed: 8.2ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.5ms\n",
            "Speed: 5.3ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.2ms\n",
            "Speed: 8.2ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 elephant, 27.9ms\n",
            "Speed: 6.8ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 elephant, 1 handbag, 27.7ms\n",
            "Speed: 7.7ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 handbag, 27.9ms\n",
            "Speed: 7.9ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 1 handbag, 28.1ms\n",
            "Speed: 6.8ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.9ms\n",
            "Speed: 6.8ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 27.3ms\n",
            "Speed: 7.9ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 30.5ms\n",
            "Speed: 7.5ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 1 umbrella, 27.3ms\n",
            "Speed: 6.4ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 27.2ms\n",
            "Speed: 6.3ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 27.3ms\n",
            "Speed: 7.3ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 27.1ms\n",
            "Speed: 7.1ms preprocess, 27.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 1 umbrella, 31.1ms\n",
            "Speed: 8.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 1 umbrella, 27.6ms\n",
            "Speed: 6.2ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 1 bicycle, 1 umbrella, 37.0ms\n",
            "Speed: 8.2ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 37.0ms\n",
            "Speed: 8.0ms preprocess, 37.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 33.9ms\n",
            "Speed: 9.2ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 33.4ms\n",
            "Speed: 8.6ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 bicycle, 1 umbrella, 1 tie, 32.9ms\n",
            "Speed: 8.8ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 30.2ms\n",
            "Speed: 8.3ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 32.2ms\n",
            "Speed: 9.0ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 29.6ms\n",
            "Speed: 8.5ms preprocess, 29.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 2 umbrellas, 34.7ms\n",
            "Speed: 10.2ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 33.3ms\n",
            "Speed: 9.1ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 1 handbag, 32.5ms\n",
            "Speed: 8.8ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 33.3ms\n",
            "Speed: 8.6ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 39.5ms\n",
            "Speed: 8.4ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 umbrella, 38.3ms\n",
            "Speed: 14.2ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 umbrella, 1 tie, 36.3ms\n",
            "Speed: 8.6ms preprocess, 36.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 39.9ms\n",
            "Speed: 8.2ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 1 tie, 2 suitcases, 36.9ms\n",
            "Speed: 10.5ms preprocess, 36.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 2 suitcases, 39.0ms\n",
            "Speed: 9.9ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 1 tie, 2 suitcases, 39.5ms\n",
            "Speed: 8.2ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 1 suitcase, 34.4ms\n",
            "Speed: 6.6ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 1 tie, 34.4ms\n",
            "Speed: 7.7ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 34.9ms\n",
            "Speed: 8.6ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 2 handbags, 31.7ms\n",
            "Speed: 5.6ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 1 handbag, 31.4ms\n",
            "Speed: 5.6ms preprocess, 31.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 1 suitcase, 31.3ms\n",
            "Speed: 7.7ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 31.1ms\n",
            "Speed: 6.8ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 31.1ms\n",
            "Speed: 5.6ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 31.1ms\n",
            "Speed: 6.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 31.3ms\n",
            "Speed: 8.3ms preprocess, 31.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 30.5ms\n",
            "Speed: 6.9ms preprocess, 30.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 29.9ms\n",
            "Speed: 6.5ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 1 umbrella, 29.7ms\n",
            "Speed: 6.5ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 29.8ms\n",
            "Speed: 8.2ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 32.6ms\n",
            "Speed: 9.1ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 29.0ms\n",
            "Speed: 7.0ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 28.9ms\n",
            "Speed: 6.6ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 28.6ms\n",
            "Speed: 8.7ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 28.8ms\n",
            "Speed: 7.2ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 28.6ms\n",
            "Speed: 6.7ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 28.3ms\n",
            "Speed: 7.0ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 31.9ms\n",
            "Speed: 8.2ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 28.6ms\n",
            "Speed: 7.6ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 1 suitcase, 28.5ms\n",
            "Speed: 7.6ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 28.4ms\n",
            "Speed: 6.7ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 28.4ms\n",
            "Speed: 6.2ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 umbrella, 32.4ms\n",
            "Speed: 7.0ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 umbrella, 29.1ms\n",
            "Speed: 6.7ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 umbrella, 28.5ms\n",
            "Speed: 6.4ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 umbrella, 28.3ms\n",
            "Speed: 7.4ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 28.4ms\n",
            "Speed: 7.5ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 28.3ms\n",
            "Speed: 6.6ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 29.4ms\n",
            "Speed: 8.8ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 umbrella, 27.9ms\n",
            "Speed: 8.0ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 umbrella, 27.8ms\n",
            "Speed: 6.5ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 13 persons, 1 umbrella, 27.7ms\n",
            "Speed: 6.5ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.6ms\n",
            "Speed: 6.4ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.8ms\n",
            "Speed: 8.6ms preprocess, 27.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 30.3ms\n",
            "Speed: 7.5ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.6ms\n",
            "Speed: 7.7ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.6ms\n",
            "Speed: 6.4ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 27.8ms\n",
            "Speed: 7.9ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 29.2ms\n",
            "Speed: 6.8ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.5ms\n",
            "Speed: 6.5ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.8ms\n",
            "Speed: 6.5ms preprocess, 27.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.5ms\n",
            "Speed: 8.3ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 27.4ms\n",
            "Speed: 5.4ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 9 persons, 27.9ms\n",
            "Speed: 5.9ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 28.0ms\n",
            "Speed: 6.4ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 28.0ms\n",
            "Speed: 8.5ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 27.5ms\n",
            "Speed: 7.1ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 11 persons, 31.7ms\n",
            "Speed: 8.5ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.6ms\n",
            "Speed: 6.7ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 27.4ms\n",
            "Speed: 8.3ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.9ms\n",
            "Speed: 7.0ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 12 persons, 28.0ms\n",
            "Speed: 7.3ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.6ms\n",
            "Speed: 6.5ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 28.1ms\n",
            "Speed: 8.3ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.5ms\n",
            "Speed: 6.9ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.6ms\n",
            "Speed: 6.6ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.9ms\n",
            "Speed: 6.5ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 27.8ms\n",
            "Speed: 7.6ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 29.4ms\n",
            "Speed: 7.0ms preprocess, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 31.2ms\n",
            "Speed: 7.0ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.6ms\n",
            "Speed: 7.9ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 27.8ms\n",
            "Speed: 8.3ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.5ms\n",
            "Speed: 6.9ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 27.8ms\n",
            "Speed: 6.7ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.5ms\n",
            "Speed: 7.9ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.6ms\n",
            "Speed: 8.1ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.6ms\n",
            "Speed: 7.7ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.4ms\n",
            "Speed: 6.3ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 31.8ms\n",
            "Speed: 8.2ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 handbag, 27.9ms\n",
            "Speed: 8.6ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.9ms\n",
            "Speed: 7.3ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.7ms\n",
            "Speed: 6.8ms preprocess, 27.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.0ms\n",
            "Speed: 8.9ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.6ms\n",
            "Speed: 8.2ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.8ms\n",
            "Speed: 7.1ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.3ms\n",
            "Speed: 6.5ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.4ms\n",
            "Speed: 7.2ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 cup, 28.3ms\n",
            "Speed: 7.3ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.6ms\n",
            "Speed: 6.9ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.3ms\n",
            "Speed: 5.4ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.7ms\n",
            "Speed: 8.4ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 29.0ms\n",
            "Speed: 9.0ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 32.1ms\n",
            "Speed: 8.2ms preprocess, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.2ms\n",
            "Speed: 7.2ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 31.8ms\n",
            "Speed: 7.7ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.9ms\n",
            "Speed: 8.2ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.3ms\n",
            "Speed: 7.0ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 29.2ms\n",
            "Speed: 6.8ms preprocess, 29.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 29.3ms\n",
            "Speed: 6.7ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 30.2ms\n",
            "Speed: 8.1ms preprocess, 30.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.7ms\n",
            "Speed: 6.8ms preprocess, 29.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 29.4ms\n",
            "Speed: 6.2ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 31.3ms\n",
            "Speed: 6.8ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 30.6ms\n",
            "Speed: 8.7ms preprocess, 30.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 30.4ms\n",
            "Speed: 7.3ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 32.9ms\n",
            "Speed: 5.9ms preprocess, 32.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 30.5ms\n",
            "Speed: 7.3ms preprocess, 30.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 30.6ms\n",
            "Speed: 7.4ms preprocess, 30.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 handbag, 30.5ms\n",
            "Speed: 7.9ms preprocess, 30.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 1 handbag, 30.8ms\n",
            "Speed: 6.6ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 29.8ms\n",
            "Speed: 6.7ms preprocess, 29.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 31.5ms\n",
            "Speed: 6.0ms preprocess, 31.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 29.8ms\n",
            "Speed: 8.5ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 30.0ms\n",
            "Speed: 8.2ms preprocess, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 29.2ms\n",
            "Speed: 5.9ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 elephant, 1 backpack, 28.9ms\n",
            "Speed: 7.9ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.0ms\n",
            "Speed: 8.4ms preprocess, 29.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 31.7ms\n",
            "Speed: 7.8ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 1 handbag, 28.8ms\n",
            "Speed: 7.9ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.8ms\n",
            "Speed: 6.2ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 1 handbag, 29.0ms\n",
            "Speed: 8.7ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.9ms\n",
            "Speed: 5.5ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 27.7ms\n",
            "Speed: 6.0ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 1 handbag, 28.0ms\n",
            "Speed: 7.0ms preprocess, 28.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 2 handbags, 34.2ms\n",
            "Speed: 8.4ms preprocess, 34.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 2 handbags, 1 chair, 28.1ms\n",
            "Speed: 7.1ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 1 handbag, 27.7ms\n",
            "Speed: 6.2ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 34.5ms\n",
            "Speed: 9.1ms preprocess, 34.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 1 handbag, 39.4ms\n",
            "Speed: 10.8ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 1 handbag, 29.8ms\n",
            "Speed: 9.3ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 1 handbag, 29.2ms\n",
            "Speed: 9.6ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 29.9ms\n",
            "Speed: 8.6ms preprocess, 29.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 1 handbag, 32.7ms\n",
            "Speed: 8.1ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 2 handbags, 29.8ms\n",
            "Speed: 8.2ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 34.6ms\n",
            "Speed: 8.2ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 33.1ms\n",
            "Speed: 8.6ms preprocess, 33.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 1 handbag, 35.2ms\n",
            "Speed: 9.1ms preprocess, 35.2ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 35.3ms\n",
            "Speed: 8.7ms preprocess, 35.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 1 handbag, 37.0ms\n",
            "Speed: 8.1ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 41.4ms\n",
            "Speed: 9.1ms preprocess, 41.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 35.6ms\n",
            "Speed: 11.0ms preprocess, 35.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 41.0ms\n",
            "Speed: 8.7ms preprocess, 41.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 1 cell phone, 37.8ms\n",
            "Speed: 7.9ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 38.3ms\n",
            "Speed: 8.4ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 45.4ms\n",
            "Speed: 8.7ms preprocess, 45.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 1 handbag, 34.7ms\n",
            "Speed: 5.6ms preprocess, 34.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 34.5ms\n",
            "Speed: 8.0ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 34.5ms\n",
            "Speed: 6.6ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 34.1ms\n",
            "Speed: 8.3ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 33.5ms\n",
            "Speed: 8.4ms preprocess, 33.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 33.6ms\n",
            "Speed: 6.2ms preprocess, 33.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 33.3ms\n",
            "Speed: 6.7ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 33.3ms\n",
            "Speed: 5.9ms preprocess, 33.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 33.5ms\n",
            "Speed: 8.4ms preprocess, 33.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 33.1ms\n",
            "Speed: 7.0ms preprocess, 33.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 32.0ms\n",
            "Speed: 7.5ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 31.6ms\n",
            "Speed: 9.1ms preprocess, 31.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 31.2ms\n",
            "Speed: 8.3ms preprocess, 31.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 31.3ms\n",
            "Speed: 7.0ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 31.2ms\n",
            "Speed: 5.8ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 31.1ms\n",
            "Speed: 6.6ms preprocess, 31.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 31.5ms\n",
            "Speed: 8.3ms preprocess, 31.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 28.7ms\n",
            "Speed: 7.2ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.5ms\n",
            "Speed: 6.4ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 29.1ms\n",
            "Speed: 7.5ms preprocess, 29.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.7ms\n",
            "Speed: 8.6ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 28.3ms\n",
            "Speed: 7.1ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 1 backpack, 31.9ms\n",
            "Speed: 7.4ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.6ms\n",
            "Speed: 7.3ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 28.3ms\n",
            "Speed: 6.5ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 28.5ms\n",
            "Speed: 7.1ms preprocess, 28.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.6ms\n",
            "Speed: 8.6ms preprocess, 28.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 26 persons, 1 backpack, 28.3ms\n",
            "Speed: 8.4ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 28.3ms\n",
            "Speed: 6.6ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.4ms\n",
            "Speed: 8.4ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 28.3ms\n",
            "Speed: 6.5ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.6ms\n",
            "Speed: 8.2ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 28.5ms\n",
            "Speed: 7.4ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 28.2ms\n",
            "Speed: 6.7ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 30.7ms\n",
            "Speed: 7.5ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 31.1ms\n",
            "Speed: 8.5ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 1 handbag, 28.6ms\n",
            "Speed: 6.5ms preprocess, 28.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 28.5ms\n",
            "Speed: 7.0ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 30.6ms\n",
            "Speed: 6.8ms preprocess, 30.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 1 backpack, 30.0ms\n",
            "Speed: 6.6ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 32.7ms\n",
            "Speed: 6.2ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 30.3ms\n",
            "Speed: 6.2ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 30.3ms\n",
            "Speed: 6.9ms preprocess, 30.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 30.1ms\n",
            "Speed: 6.9ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 29.7ms\n",
            "Speed: 6.9ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 29.7ms\n",
            "Speed: 8.6ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 33.1ms\n",
            "Speed: 8.9ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 29.4ms\n",
            "Speed: 7.3ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 29.7ms\n",
            "Speed: 7.1ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 29.7ms\n",
            "Speed: 7.6ms preprocess, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 29.4ms\n",
            "Speed: 7.3ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 29.8ms\n",
            "Speed: 7.5ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 29.6ms\n",
            "Speed: 7.7ms preprocess, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 29.6ms\n",
            "Speed: 7.8ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 29.5ms\n",
            "Speed: 7.3ms preprocess, 29.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 29.9ms\n",
            "Speed: 6.5ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 29.3ms\n",
            "Speed: 6.6ms preprocess, 29.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 30.7ms\n",
            "Speed: 8.1ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 27.8ms\n",
            "Speed: 8.9ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 27.8ms\n",
            "Speed: 6.7ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 28.1ms\n",
            "Speed: 7.4ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 28.2ms\n",
            "Speed: 7.9ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.9ms\n",
            "Speed: 9.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.2ms\n",
            "Speed: 6.7ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 27.4ms\n",
            "Speed: 6.4ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 27.4ms\n",
            "Speed: 5.4ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.8ms\n",
            "Speed: 8.9ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 27.8ms\n",
            "Speed: 8.4ms preprocess, 27.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 27.8ms\n",
            "Speed: 7.9ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 31.4ms\n",
            "Speed: 7.0ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 28.3ms\n",
            "Speed: 8.6ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.5ms\n",
            "Speed: 8.1ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 27.4ms\n",
            "Speed: 7.0ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 27.2ms\n",
            "Speed: 6.4ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 27.2ms\n",
            "Speed: 7.7ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.3ms\n",
            "Speed: 7.0ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 1 backpack, 27.3ms\n",
            "Speed: 6.9ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 27.5ms\n",
            "Speed: 6.9ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 28.0ms\n",
            "Speed: 9.2ms preprocess, 28.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 27.9ms\n",
            "Speed: 8.7ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.5ms\n",
            "Speed: 8.2ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 31.3ms\n",
            "Speed: 8.3ms preprocess, 31.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 27.4ms\n",
            "Speed: 8.9ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 28.9ms\n",
            "Speed: 8.5ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 boat, 1 backpack, 27.5ms\n",
            "Speed: 10.2ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 boat, 1 backpack, 28.7ms\n",
            "Speed: 8.4ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 1 backpack, 28.5ms\n",
            "Speed: 7.0ms preprocess, 28.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 28.8ms\n",
            "Speed: 6.7ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 28.0ms\n",
            "Speed: 6.7ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.6ms\n",
            "Speed: 7.4ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 elephant, 1 backpack, 27.9ms\n",
            "Speed: 8.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 28.1ms\n",
            "Speed: 8.3ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.9ms\n",
            "Speed: 8.8ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 elephant, 30.3ms\n",
            "Speed: 6.9ms preprocess, 30.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.1ms\n",
            "Speed: 7.5ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 32.0ms\n",
            "Speed: 8.5ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 27.5ms\n",
            "Speed: 7.6ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 horse, 1 handbag, 27.2ms\n",
            "Speed: 6.5ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 1 handbag, 27.4ms\n",
            "Speed: 7.9ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 handbag, 27.4ms\n",
            "Speed: 7.0ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.3ms\n",
            "Speed: 7.5ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 horse, 27.9ms\n",
            "Speed: 9.0ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.5ms\n",
            "Speed: 6.5ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.4ms\n",
            "Speed: 9.1ms preprocess, 27.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 32.3ms\n",
            "Speed: 8.4ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 27.5ms\n",
            "Speed: 7.9ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 27.9ms\n",
            "Speed: 6.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 27.8ms\n",
            "Speed: 6.9ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 27.8ms\n",
            "Speed: 7.1ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.4ms\n",
            "Speed: 6.0ms preprocess, 27.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.7ms\n",
            "Speed: 6.0ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.6ms\n",
            "Speed: 7.5ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 28.6ms\n",
            "Speed: 7.0ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 28.2ms\n",
            "Speed: 6.0ms preprocess, 28.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 28.3ms\n",
            "Speed: 7.5ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 40.1ms\n",
            "Speed: 9.4ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 38.4ms\n",
            "Speed: 9.4ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 33.8ms\n",
            "Speed: 11.3ms preprocess, 33.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 34.6ms\n",
            "Speed: 9.2ms preprocess, 34.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 33.7ms\n",
            "Speed: 11.6ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 32.6ms\n",
            "Speed: 8.9ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 26 persons, 1 backpack, 32.9ms\n",
            "Speed: 9.4ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 32.6ms\n",
            "Speed: 8.5ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 38.1ms\n",
            "Speed: 9.1ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 32.4ms\n",
            "Speed: 9.0ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 33.1ms\n",
            "Speed: 8.4ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 34.8ms\n",
            "Speed: 9.1ms preprocess, 34.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 33.4ms\n",
            "Speed: 9.2ms preprocess, 33.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 1 backpack, 40.0ms\n",
            "Speed: 12.1ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 37.2ms\n",
            "Speed: 10.0ms preprocess, 37.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 40.9ms\n",
            "Speed: 12.0ms preprocess, 40.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 44.1ms\n",
            "Speed: 8.5ms preprocess, 44.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 1 horse, 1 backpack, 37.2ms\n",
            "Speed: 8.6ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 39.9ms\n",
            "Speed: 12.0ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 backpack, 34.6ms\n",
            "Speed: 8.6ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 backpack, 34.5ms\n",
            "Speed: 6.4ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 34.8ms\n",
            "Speed: 6.9ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 34.6ms\n",
            "Speed: 8.5ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 dining table, 34.1ms\n",
            "Speed: 6.8ms preprocess, 34.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 1 dining table, 32.7ms\n",
            "Speed: 7.0ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 27 persons, 32.2ms\n",
            "Speed: 6.7ms preprocess, 32.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 34.8ms\n",
            "Speed: 9.2ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 31.8ms\n",
            "Speed: 7.5ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 31.6ms\n",
            "Speed: 7.3ms preprocess, 31.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 31.8ms\n",
            "Speed: 7.1ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 38.4ms\n",
            "Speed: 10.1ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 31.7ms\n",
            "Speed: 6.7ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 33.9ms\n",
            "Speed: 8.8ms preprocess, 33.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 31.6ms\n",
            "Speed: 8.3ms preprocess, 31.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 32.6ms\n",
            "Speed: 8.5ms preprocess, 32.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 handbag, 32.0ms\n",
            "Speed: 7.6ms preprocess, 32.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 31.8ms\n",
            "Speed: 7.8ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 34.1ms\n",
            "Speed: 6.9ms preprocess, 34.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.7ms\n",
            "Speed: 10.2ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 31.9ms\n",
            "Speed: 8.0ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 31.7ms\n",
            "Speed: 6.8ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.7ms\n",
            "Speed: 7.2ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 29.4ms\n",
            "Speed: 11.1ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 14 persons, 29.0ms\n",
            "Speed: 6.6ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 30.9ms\n",
            "Speed: 6.7ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 skateboard, 29.2ms\n",
            "Speed: 7.6ms preprocess, 29.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 29.2ms\n",
            "Speed: 8.0ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.1ms\n",
            "Speed: 8.9ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 29.2ms\n",
            "Speed: 6.6ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 32.6ms\n",
            "Speed: 9.1ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 29.0ms\n",
            "Speed: 6.0ms preprocess, 29.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 29.0ms\n",
            "Speed: 8.6ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 29.2ms\n",
            "Speed: 7.8ms preprocess, 29.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.0ms\n",
            "Speed: 6.8ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 32.7ms\n",
            "Speed: 8.6ms preprocess, 32.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.9ms\n",
            "Speed: 7.8ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 29.1ms\n",
            "Speed: 6.7ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 27.6ms\n",
            "Speed: 6.3ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.9ms\n",
            "Speed: 9.2ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 handbag, 27.8ms\n",
            "Speed: 8.9ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 28.3ms\n",
            "Speed: 8.1ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 30.6ms\n",
            "Speed: 9.0ms preprocess, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.5ms\n",
            "Speed: 8.0ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.8ms\n",
            "Speed: 8.2ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.4ms\n",
            "Speed: 7.6ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.5ms\n",
            "Speed: 6.4ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.9ms\n",
            "Speed: 7.0ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.9ms\n",
            "Speed: 8.7ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 29.4ms\n",
            "Speed: 8.8ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.7ms\n",
            "Speed: 7.4ms preprocess, 27.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.8ms\n",
            "Speed: 7.3ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 27.7ms\n",
            "Speed: 8.7ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.8ms\n",
            "Speed: 10.8ms preprocess, 27.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 31.8ms\n",
            "Speed: 8.0ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.6ms\n",
            "Speed: 7.5ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 29.1ms\n",
            "Speed: 8.6ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 29.0ms\n",
            "Speed: 7.5ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 horse, 28.9ms\n",
            "Speed: 8.1ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 horse, 27.8ms\n",
            "Speed: 7.9ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 horse, 27.6ms\n",
            "Speed: 9.2ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 horse, 28.3ms\n",
            "Speed: 7.9ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 1 backpack, 1 handbag, 27.6ms\n",
            "Speed: 6.8ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.0ms\n",
            "Speed: 6.3ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 handbag, 27.7ms\n",
            "Speed: 7.2ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 27.9ms\n",
            "Speed: 8.5ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 31.2ms\n",
            "Speed: 8.9ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 horse, 1 handbag, 27.4ms\n",
            "Speed: 9.1ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.7ms\n",
            "Speed: 8.5ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 27.5ms\n",
            "Speed: 7.2ms preprocess, 27.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.3ms\n",
            "Speed: 8.2ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 horse, 27.5ms\n",
            "Speed: 8.4ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 1 horse, 31.9ms\n",
            "Speed: 8.4ms preprocess, 31.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.3ms\n",
            "Speed: 6.4ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.4ms\n",
            "Speed: 6.5ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 handbag, 27.3ms\n",
            "Speed: 8.0ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.5ms\n",
            "Speed: 6.6ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.5ms\n",
            "Speed: 6.7ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 30.6ms\n",
            "Speed: 7.7ms preprocess, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 27.6ms\n",
            "Speed: 7.9ms preprocess, 27.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.9ms\n",
            "Speed: 6.8ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 28.2ms\n",
            "Speed: 6.7ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 dining table, 27.8ms\n",
            "Speed: 6.5ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 dining table, 27.9ms\n",
            "Speed: 9.2ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 32.6ms\n",
            "Speed: 6.5ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 28.6ms\n",
            "Speed: 7.1ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 28.6ms\n",
            "Speed: 6.6ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 29.0ms\n",
            "Speed: 8.5ms preprocess, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 28.0ms\n",
            "Speed: 6.4ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 28.0ms\n",
            "Speed: 6.4ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 cow, 30.8ms\n",
            "Speed: 7.9ms preprocess, 30.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 28.1ms\n",
            "Speed: 8.4ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 27.9ms\n",
            "Speed: 6.9ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 27 persons, 27.7ms\n",
            "Speed: 6.6ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 28.1ms\n",
            "Speed: 6.7ms preprocess, 28.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.7ms\n",
            "Speed: 8.0ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.5ms\n",
            "Speed: 6.7ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 27.7ms\n",
            "Speed: 7.0ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.7ms\n",
            "Speed: 6.0ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 27.8ms\n",
            "Speed: 6.5ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 28.3ms\n",
            "Speed: 7.1ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.9ms\n",
            "Speed: 7.0ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 31.7ms\n",
            "Speed: 8.2ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.8ms\n",
            "Speed: 8.4ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 27.9ms\n",
            "Speed: 7.4ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.9ms\n",
            "Speed: 6.8ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.7ms\n",
            "Speed: 6.6ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 27.4ms\n",
            "Speed: 8.1ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 25 persons, 27.4ms\n",
            "Speed: 7.1ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.6ms\n",
            "Speed: 6.6ms preprocess, 27.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 27.4ms\n",
            "Speed: 6.9ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 27.4ms\n",
            "Speed: 7.9ms preprocess, 27.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 2 handbags, 27.4ms\n",
            "Speed: 6.7ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.5ms\n",
            "Speed: 6.5ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 30.5ms\n",
            "Speed: 7.6ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.2ms\n",
            "Speed: 8.7ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 27.5ms\n",
            "Speed: 7.3ms preprocess, 27.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 27.4ms\n",
            "Speed: 6.7ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 20 persons, 28.7ms\n",
            "Speed: 6.4ms preprocess, 28.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 24 persons, 1 backpack, 35.1ms\n",
            "Speed: 10.5ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 23 persons, 1 backpack, 35.7ms\n",
            "Speed: 9.6ms preprocess, 35.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 30.4ms\n",
            "Speed: 8.7ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 33.9ms\n",
            "Speed: 8.7ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 22 persons, 1 backpack, 33.8ms\n",
            "Speed: 11.2ms preprocess, 33.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 29.8ms\n",
            "Speed: 8.5ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 21 persons, 32.5ms\n",
            "Speed: 8.5ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 33.9ms\n",
            "Speed: 8.5ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 32.5ms\n",
            "Speed: 8.6ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 32.3ms\n",
            "Speed: 8.4ms preprocess, 32.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 37.8ms\n",
            "Speed: 10.1ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 33.3ms\n",
            "Speed: 10.8ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 39.6ms\n",
            "Speed: 8.6ms preprocess, 39.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 41.7ms\n",
            "Speed: 11.6ms preprocess, 41.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 36.0ms\n",
            "Speed: 8.2ms preprocess, 36.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 38.0ms\n",
            "Speed: 9.4ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 39.7ms\n",
            "Speed: 10.3ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 39.0ms\n",
            "Speed: 9.4ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 1 backpack, 41.7ms\n",
            "Speed: 9.4ms preprocess, 41.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 34.9ms\n",
            "Speed: 7.1ms preprocess, 34.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 1 backpack, 35.2ms\n",
            "Speed: 7.3ms preprocess, 35.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 35.2ms\n",
            "Speed: 9.4ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 backpack, 34.6ms\n",
            "Speed: 8.7ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 horse, 1 backpack, 34.5ms\n",
            "Speed: 7.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 34.5ms\n",
            "Speed: 8.3ms preprocess, 34.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 34.6ms\n",
            "Speed: 7.0ms preprocess, 34.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 handbag, 34.1ms\n",
            "Speed: 8.6ms preprocess, 34.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 1 handbag, 32.9ms\n",
            "Speed: 7.3ms preprocess, 32.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 32.3ms\n",
            "Speed: 6.6ms preprocess, 32.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 handbag, 32.7ms\n",
            "Speed: 6.6ms preprocess, 32.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 backpack, 1 handbag, 36.3ms\n",
            "Speed: 8.1ms preprocess, 36.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 32.1ms\n",
            "Speed: 8.3ms preprocess, 32.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 31.7ms\n",
            "Speed: 7.2ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 34.0ms\n",
            "Speed: 8.1ms preprocess, 34.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.6ms\n",
            "Speed: 9.4ms preprocess, 31.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.7ms\n",
            "Speed: 8.6ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.6ms\n",
            "Speed: 8.0ms preprocess, 31.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.8ms\n",
            "Speed: 7.9ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 1 boat, 31.6ms\n",
            "Speed: 8.6ms preprocess, 31.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 19 persons, 1 boat, 31.8ms\n",
            "Speed: 7.1ms preprocess, 31.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 16 persons, 31.8ms\n",
            "Speed: 6.7ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 15 persons, 29.2ms\n",
            "Speed: 8.9ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 33.8ms\n",
            "Speed: 8.9ms preprocess, 33.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.9ms\n",
            "Speed: 6.8ms preprocess, 28.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.9ms\n",
            "Speed: 7.9ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 31.1ms\n",
            "Speed: 7.5ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 28.9ms\n",
            "Speed: 8.2ms preprocess, 28.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 17 persons, 28.6ms\n",
            "Speed: 8.2ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 18 persons, 27.8ms\n",
            "Speed: 8.2ms preprocess, 27.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "People count data saved as 'people_count_log.csv'\n",
            "Processed video saved as: output_video.mp4\n",
            "Heatmap video saved as: heatmap_video.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize list to store people count and heatmap data\n",
        "people_count_log = []\n",
        "heatmap_data = []  # List to store coordinates of detected people\n",
        "\n",
        "\n",
        "# Open video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = 0  # Counter for processed frames\n",
        "max_frames = 775  # Set the limit for the number of frames to process\n",
        "\n",
        "# Get video properties\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Define VideoWriter to save output (detections + heatmap)\n",
        "output_path = \"output_video.mp4\"\n",
        "heatmap_output_path = \"heatmap_video.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "heatmap_out = cv2.VideoWriter(heatmap_output_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Set crowd alert threshold\n",
        "alert_threshold = 30\n",
        "\n",
        "while cap.isOpened() and frame_count < max_frames:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run YOLOv8 detection\n",
        "    results = model(frame, imgsz=1280, conf=0.4, augment=True)\n",
        "\n",
        "    people_count = 0\n",
        "    frame_heatmap_data = []  # Store coordinates for this frame\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            if box.cls[0] == 0:  # Class 0 = person\n",
        "                people_count += 1\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates\n",
        "                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2  # Get center of bounding box\n",
        "                frame_heatmap_data.append((center_x, center_y))\n",
        "\n",
        "    # Store heatmap data\n",
        "    heatmap_data.append(frame_heatmap_data)\n",
        "\n",
        "    # Append data to list\n",
        "    people_count_log.append({\"Frame\": frame_count, \"People Count\": people_count})\n",
        "\n",
        "    # Generate heatmap\n",
        "    heatmap_frame = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    for x, y in frame_heatmap_data:\n",
        "        cv2.circle(heatmap_frame, (x, y), 40, (255), -1)  # Large radius for smooth transition\n",
        "\n",
        "    heatmap_frame = cv2.GaussianBlur(heatmap_frame, (101, 101), 0)  # Smooth intensity\n",
        "\n",
        "\n",
        "    # Apply colormap to create heatmap effect\n",
        "    heatmap_frame = cv2.applyColorMap(heatmap_frame, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Blend the heatmap with the original frame\n",
        "    blended_frame = cv2.addWeighted(frame, 0.7, heatmap_frame, 0.3, 0)\n",
        "\n",
        "    # Annotate frame with detections\n",
        "    for r in results:\n",
        "        annotated_frame = r.plot()\n",
        "\n",
        "    # Overlay heatmap onto the annotated frame\n",
        "    final_frame = cv2.addWeighted(annotated_frame, 0.7, heatmap_frame, 0.3, 0)\n",
        "\n",
        "    # Save the processed frames to videos\n",
        "    out.write(final_frame)  # Save video with detections + heatmap\n",
        "    heatmap_out.write(heatmap_frame)  # Save only heatmap video\n",
        "\n",
        "    # Check for crowd alerts\n",
        "    if people_count > alert_threshold:\n",
        "        print(f\"⚠️ ALERT! High Crowd Detected at Frame {frame_count}: {people_count} people\")\n",
        "\n",
        "    frame_count += 1  # Increment frame count\n",
        "\n",
        "# Convert to DataFrame and save as CSV\n",
        "df = pd.DataFrame(people_count_log)\n",
        "df.to_csv(\"people_count_log.csv\", index=False)\n",
        "\n",
        "print(\"People count data saved as 'people_count_log.csv'\")\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "heatmap_out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Processed video saved as: {output_path}\")\n",
        "print(f\"Heatmap video saved as: {heatmap_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZYKAlacMRJx",
        "outputId": "2d5e3e09-6979-4bdb-f0c4-d6873f7ebf42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "People Count: 18\n"
          ]
        }
      ],
      "source": [
        "for result in results:\n",
        "    people_count = sum(1 for box in result.boxes if box.cls[0] == 0)  # Class 0 is 'person' in COCO dataset\n",
        "    print(f\"People Count: {people_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_cy9txW3ipX",
        "outputId": "c1ac05d1-0eb2-4179-d980-66119ff00bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Frame  People Count  Next Frame People Count\n",
            "0      0            13                     13.0\n",
            "1      1            13                     16.0\n",
            "2      2            16                     15.0\n",
            "3      3            15                     17.0\n",
            "4      4            17                     14.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the logged people count data\n",
        "df = pd.read_csv(\"people_count_log.csv\")\n",
        "\n",
        "# Create a \"Next Frame People Count\" column (Shift values by -1 to predict next frame)\n",
        "df[\"Next Frame People Count\"] = df[\"People Count\"].shift(-1)\n",
        "\n",
        "# Drop NaN values (last row will have NaN due to shifting)\n",
        "df = df.dropna()\n",
        "\n",
        "print(df.head())  # Check dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOkFA1D_3tnA",
        "outputId": "de93958b-c92d-4090-edb0-0e8df6b4d364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BxPI51HItP_",
        "outputId": "782912b8-907f-4783-c629-fb0f4d7afbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Frame  People Count  Next Frame People Count\n",
            "0      0            13                     13.0\n",
            "1      1            13                     16.0\n",
            "2      2            16                     15.0\n",
            "3      3            15                     17.0\n",
            "4      4            17                     14.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the logged people count data\n",
        "df = pd.read_csv(\"people_count_log.csv\")\n",
        "\n",
        "# Create a \"Next Frame People Count\" column (Shift values by -1 to predict next frame)\n",
        "df[\"Next Frame People Count\"] = df[\"People Count\"].shift(-1)\n",
        "\n",
        "# Drop NaN values (last row will have NaN due to shifting)\n",
        "df = df.dropna()\n",
        "\n",
        "print(df.head())  # Check dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpZSVWbGwVVB",
        "outputId": "ea686664-4f30-4717-eae1-8465ab61b2d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv7Xc4R5y7Ww",
        "outputId": "7ceaf5cd-364e-43af-c8ae-43d0a3621dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Best Parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [5, 10, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring=\"r2\", n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Model\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(f\"✅ Best Parameters: {grid_search.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haPrADa3Izg8",
        "outputId": "7075c36f-ecf9-4236-d029-f79a5cffe7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔮 Predicted crowd count for next frame: 17.562447808093925\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define input (X) and output (y)\n",
        "X = df[[\"Frame\", \"People Count\"]]\n",
        "y = df[\"Next Frame People Count\"]\n",
        "\n",
        "# Split into training & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict future congestion (next frame)\n",
        "future_frame = pd.DataFrame({\"Frame\": [df[\"Frame\"].max() + 1], \"People Count\": [df[\"People Count\"].iloc[-1]]})\n",
        "predicted_count = rf_model.predict(future_frame)\n",
        "\n",
        "print(f\"🔮 Predicted crowd count for next frame: {predicted_count[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K77AI2tQJHu6",
        "outputId": "09b2db57-33bc-49fb-89e6-d02df1ff9e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Model Accuracy Metrics:\n",
            "✅ Mean Absolute Error (MAE): 1.37\n",
            "✅ Mean Squared Error (MSE): 2.95\n",
            "✅ Root Mean Squared Error (RMSE): 1.72\n",
            "✅ R² Score: 0.67 (closer to 1 is better)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"📊 Model Accuracy Metrics:\")\n",
        "print(f\"✅ Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"✅ Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"✅ Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"✅ R² Score: {r2:.2f} (closer to 1 is better)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9vw0jTiJ4mX",
        "outputId": "fa89a271-9b9d-4776-b6c5-6eac75a22d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Frame  Predicted People Count\n",
            "0    774               17.562448\n",
            "1    775               17.756987\n",
            "2    776               17.756987\n",
            "3    777               17.756987\n",
            "4    778               17.756987\n",
            "5    779               17.756987\n",
            "6    780               17.756987\n",
            "7    781               17.756987\n",
            "8    782               17.756987\n",
            "9    783               17.756987\n"
          ]
        }
      ],
      "source": [
        "future_steps = 10  # Number of future frames to predict\n",
        "future_frames = []\n",
        "last_frame = df[\"Frame\"].max()\n",
        "last_people_count = df[\"People Count\"].iloc[-1]\n",
        "\n",
        "for _ in range(future_steps):\n",
        "    future_frame = pd.DataFrame({\"Frame\": [last_frame + 1], \"People Count\": [last_people_count]})\n",
        "    predicted_count = rf_model.predict(future_frame)[0]  # Predict the next frame\n",
        "\n",
        "    # Store the prediction\n",
        "    future_frames.append({\"Frame\": last_frame + 1, \"Predicted People Count\": predicted_count})\n",
        "\n",
        "    # Update values for next iteration\n",
        "    last_frame += 1\n",
        "    last_people_count = predicted_count\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "future_df = pd.DataFrame(future_frames)\n",
        "print(future_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "L6m1CKfZJ-mG",
        "outputId": "6b40e1ca-dd7f-4989-d981-1699ab42f405"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnXd4FUX3x797e3pP7g0JSUiAEAJEOgRChxCkKL6CioovoPKC2Au+KqAodvG1YPmpKIgdVARC7waQTggJEJJASEJ6b7fs74+9u9m9d29LL/N5Hh5yd2dnZ2Znzp49M3MORdM0DQKBQCAQCIQuhKStC0AgEAgEAoHQ2hAFiEAgEAgEQpeDKEAEAoFAIBC6HEQBIhAIBAKB0OUgChCBQCAQCIQuB1GACAQCgUAgdDmIAkQgEAgEAqHLQRQgAoFAIBAIXQ6iABEIBAKBQOhyEAWIQGghQkNDMX/+fO73gQMHQFEUDhw40GZlMsW0jATHGTt2LMaOHdvWxWgyK1euBEVRbV0MAqHVIAoQoVOyfv16UBTF/VOpVOjVqxeWLl2KW7dutXXxHGL79u1YuXJlWxejVbh06RL3vEpLSxudzxtvvIHff/+92crVHISGhgr6pL+/P0aPHo0tW7a0ddFalPT0dDzyyCPo0aMHVCoV3N3dERsbiw8//BA1NTVtXTwAwKeffor169e3dTEIrQxRgAidmldffRUbNmzAxx9/jJEjR2LdunUYMWIEqqurW70scXFxqKmpQVxcnEPXbd++HatWrWqhUrUvNm7cCLVaDQD49ddfG51Pe1SAACAmJgYbNmzAhg0b8MwzzyAnJwd33nknPvvss7YuWouwbds29OvXDz///DOmT5+Ojz76CGvWrEH37t3x7LPP4vHHH2/rIgIgClBXRdbWBSAQWpKpU6di8ODBAICFCxfCx8cH77//Pv744w/cc889otdUVVXBxcWl2csikUigUqmaPd/OAk3T2LRpE+69915kZGTg+++/x8KFC9u6WM1Kt27dMG/ePO73Aw88gIiICHzwwQd49NFH27BkzU9GRgbmzp2LkJAQ7Nu3DxqNhju3ZMkSXL16Fdu2bWvDEhK6OsQCROhSjB8/HgAjnAFg/vz5cHV1RXp6OhISEuDm5ob77rsPAGAwGLB27Vr07dsXKpUKAQEBeOSRR1BSUiLIk6ZprF69GkFBQXB2dsa4ceNw8eJFs3tbWgN0/PhxJCQkwMvLCy4uLujfvz8+/PBDrnyffPIJAAimT1iau4ymaLVaeHt746GHHjI7V15eDpVKhWeeeYY79tFHH6Fv375wdnaGl5cXBg8ejE2bNtm8DwAcPXoUmZmZmDt3LubOnYtDhw4hOzvbLJ3BYMCHH36Ifv36QaVSwc/PD/Hx8Th58iTXTlVVVfj222+59mLXOc2fPx+hoaFmeYqtf/nmm28wfvx4+Pv7Q6lUIioqCuvWrbOrLvaiVqvRp08frj8CwM2bN/Hvf/8bAQEBUCqV6Nu3L77++muza/Pz87FgwQIEBARApVJhwIAB+PbbbwVpMjMzQVEU3n33XXzwwQcICQmBk5MTxowZg+TkZLvKuHHjRgwaNAhOTk7w9vbG3LlzcePGDZvXvf3226isrMRXX30lUH5YIiIiBBYgnU6H1157DeHh4VAqlQgNDcWLL76Iuro6wXUURYlOCZuuZ2OnwY8ePYqnnnoKfn5+cHFxwR133IGCggLBdRcvXsTBgwe5/tIZ1nQRbEMsQIQuRXp6OgDAx8eHO6bT6TBlyhSMGjUK7777LpydnQEAjzzyCNavX4+HHnoIy5YtQ0ZGBj7++GOcOXMGR48ehVwuBwC88sorWL16NRISEpCQkIDTp09j8uTJqK+vt1me3bt34/bbb4dGo8Hjjz8OtVqNS5cu4a+//sLjjz+ORx55BDk5Odi9ezc2bNhgdn1Ll1Eul+OOO+7A5s2b8fnnn0OhUHDnfv/9d9TV1WHu3LkAgC+//BLLli3DXXfdhccffxy1tbU4f/48jh8/jnvvvddmW3z//fcIDw/HkCFDEB0dDWdnZ/zwww949tlnBekWLFiA9evXY+rUqVi4cCF0Oh0OHz6MY8eOYfDgwdiwYQMWLlyIoUOH4uGHHwYAhIeH27y/KevWrUPfvn0xY8YMyGQybN26Ff/5z39gMBiwZMkSh/MTQ6vV4saNG1x/vHXrFoYPHw6KorB06VL4+flhx44dWLBgAcrLy/HEE08AAGpqajB27FhcvXoVS5cuRVhYGH755RfMnz8fpaWlZlNL3333HSoqKrBkyRLU1tbiww8/xPjx43HhwgUEBARYLN/rr7+Ol19+GXfffTcWLlyIgoICfPTRR4iLi8OZM2fg6elp8dqtW7eiR48eGDlypF1tsXDhQnz77be466678PTTT+P48eNYs2YNLl261KR1Uo899hi8vLywYsUKZGZmYu3atVi6dCl++uknAMDatWvx2GOPwdXVFf/9738BwGqbEDoRNIHQCfnmm29oAPSePXvogoIC+saNG/SPP/5I+/j40E5OTnR2djZN0zT94IMP0gDoF154QXD94cOHaQD0999/LziemJgoOJ6fn08rFAp62rRptMFg4NK9+OKLNAD6wQcf5I7t37+fBkDv37+fpmma1ul0dFhYGB0SEkKXlJQI7sPPa8mSJbTYUG2JMoqxc+dOGgC9detWwfGEhAS6R48e3O+ZM2fSffv2tZqXJerr62kfHx/6v//9L3fs3nvvpQcMGCBIt2/fPhoAvWzZMrM8+HVzcXERrdeDDz5Ih4SEmB1fsWKFWRtXV1ebpZsyZYqgzjRN02PGjKHHjBkjUishISEh9OTJk+mCggK6oKCAPnfuHD137lwaAP3YY4/RNE3TCxYsoDUaDV1YWCi4du7cubSHhwdXprVr19IA6I0bN3Jp6uvr6REjRtCurq50eXk5TdM0nZGRQQMQ9Hmapunjx4/TAOgnn3zSYhtkZmbSUqmUfv311wVluXDhAi2TycyO8ykrK6MB0DNnzrTZLjRN02fPnqUB0AsXLhQcf+aZZ2gA9L59+7hjAOgVK1aY5RESEiJ45qwMmDhxoqBvPPnkk7RUKqVLS0u5Y3379rXrGRI6F2QKjNCpmThxIvz8/BAcHIy5c+fC1dUVW7ZsQbdu3QTpFi9eLPj9yy+/wMPDA5MmTUJhYSH3b9CgQXB1dcX+/fsBAHv27EF9fT0ee+wxwRQK+6VujTNnziAjIwNPPPGE2Ze0PduRW6OMADNt6Ovry30xA0BJSQl2796NOXPmcMc8PT2RnZ2Nf/75x658+ezYsQNFRUWCdVn33HMPzp07J5iq++2330BRFFasWGGWR3Nv4XZycuL+LisrQ2FhIcaMGYNr166hrKysUXnu2rULfn5+8PPzw4ABA/DLL7/g/vvvx1tvvQWapvHbb79h+vTpoGla8EynTJmCsrIynD59GgCzMF6tVgvaSy6XY9myZaisrMTBgwcF9501a5agzw8dOhTDhg3D9u3bLZZ18+bNMBgMuPvuuwVlUavV6NmzJ9e/xCgvLwcAuLm52dUubDmeeuopwfGnn34aAJq0Vujhhx8W9I3Ro0dDr9cjKyur0XkSOgdkCozQqfnkk0/Qq1cvyGQyBAQEoHfv3pBIhHq/TCZDUFCQ4NiVK1dQVlYGf39/0Xzz8/MBgBOiPXv2FJz38/ODl5eX1bKx03HR0dH2V6iVywgw7TN79mxs2rQJdXV1UCqV2Lx5M7RarUABev7557Fnzx4MHToUERERmDx5Mu69917ExsbavMfGjRsRFhYGpVKJq1evAmCmrZydnfH999/jjTfeAMC0WWBgILy9vW3m2VSOHj2KFStWICkpyWzXYFlZGTw8PBzOc9iwYVi9ejUoioKzszP69OnDKb/5+fkoLS3FF198gS+++EL0ev4z7dmzp1lf7tOnD3eej+mzB4BevXrh559/tljWK1eugKZp0WsBcNOrYri7uwMAKioqLKbhk5WVBYlEgoiICMFxtVoNT0/PJikr3bt3F/xm+7zpOjlC14MoQIROzdChQ7ldYJZQKpVmLxKDwQB/f398//33otf4+fk1WxkbS2uWce7cufj888+xY8cOzJo1Cz///DMiIyMxYMAALk2fPn2QlpaGv/76C4mJifjtt9/w6aef4pVXXrG6jb+8vBxbt25FbW2t6Mt206ZNeP3115vFwmMpD71eL/idnp6OCRMmIDIyEu+//z6Cg4OhUCiwfft2fPDBBzAYDI26v6+vLyZOnCh6js1z3rx5ePDBB0XT9O/fv1H3bQwGgwEURWHHjh2QSqVm511dXS1e6+7ujsDAQLsXWrM05RmbPkMWsbIDzMYAQteGKEAEggjh4eHYs2cPYmNjBVMhpoSEhABgvpZ79OjBHS8oKLD5hckuzE1OTrb4UgQsvxRao4wscXFx0Gg0+OmnnzBq1Cjs27ePWzDKx8XFBXPmzMGcOXNQX1+PO++8E6+//jqWL19u0QXA5s2bUVtbi3Xr1sHX11dwLi0tDS+99BKOHj2KUaNGITw8HDt37kRxcbFVK5ClNvPy8hJ1sGhqYdi6dSvq6urw559/CiwI1qZ9moqfnx/c3Nyg1+ut9geAeabnz5+HwWAQKO+pqanceT5Xrlwxy+Py5cuiO+JYwsPDQdM0wsLC0KtXLwdqwnD77bfjiy++QFJSEkaMGGE1bUhICAwGA65cucJZsQBmUXhpaamgPmLPsL6+Hrm5uQ6XkYV4wO6akDVABIIId999N/R6PV577TWzczqdjhPAEydOhFwux0cffST4oly7dq3NewwcOBBhYWFYu3atmUDn58X6JDJN0xplZJFIJLjrrruwdetWbNiwATqdTjD9BQBFRUWC3wqFAlFRUaBpGlqt1mLeGzduRI8ePfDoo4/irrvuEvx75pln4Orqylm5Zs+eDZqmRS1Kpm0mpuiEh4ejrKwM58+f547l5uaa7TJirQb8PMvKyvDNN99YrEdTkUqlmD17Nn777TdRywl/63ZCQgLy8vIE67J0Oh0++ugjuLq6YsyYMYJrf//9d9y8eZP7feLECRw/fhxTp061WJ4777wTUqkUq1atMrOW0DRt9rxNee655+Di4oKFCxeKel9PT0/n3D0kJCQAMO+T77//PgBg2rRp3LHw8HAcOnRIkO6LL76waAGyB0v9hdC5IRYgAkGEMWPG4JFHHsGaNWtw9uxZTJ48GXK5HFeuXMEvv/yCDz/8EHfddRf8/PzwzDPPYM2aNbj99tuRkJCAM2fOYMeOHWbWDFMkEgnWrVuH6dOnIyYmBg899BA0Gg1SU1Nx8eJF7Ny5EwAwaNAgAMCyZcswZcoUSKVSzJ07t1XKyGfOnDn46KOPsGLFCvTr10/wpQ4AkydPhlqtRmxsLAICAnDp0iV8/PHHmDZtmsXFsDk5Odi/fz+WLVsmel6pVGLKlCn45Zdf8L///Q/jxo3D/fffj//973+4cuUK4uPjYTAYcPjwYYwbNw5Lly7l2mzPnj14//33ERgYiLCwMAwbNgxz587F888/jzvuuAPLli1DdXU11q1bh169enELjNm6KBQKTJ8+HY888ggqKyvx5Zdfwt/fv0mWBlu8+eab2L9/P4YNG4ZFixYhKioKxcXFOH36NPbs2YPi4mIAzMLezz//HPPnz8epU6cQGhqKX3/9FUePHsXatWvN2jsiIgKjRo3C4sWLUVdXh7Vr18LHxwfPPfecxbKEh4dj9erVWL58OTIzMzFr1iy4ubkhIyMDW7ZswcMPPyzwASV2/aZNmzBnzhz06dMHDzzwAKKjo1FfX4+///6b27YPAAMGDMCDDz6IL774AqWlpRgzZgxOnDiBb7/9FrNmzcK4ceO4fBcuXIhHH30Us2fPxqRJk3Du3Dns3LnTob5syqBBg7Bu3TqsXr0aERER8Pf353yGEToxbbH1jEBoadgtsP/884/VdA8++CDt4uJi8fwXX3xBDxo0iHZycqLd3Nzofv360c899xydk5PDpdHr9fSqVatojUZDOzk50WPHjqWTk5PNtuWaboNnOXLkCD1p0iTazc2NdnFxofv3709/9NFH3HmdTkc/9thjtJ+fH01RlNl27eYsozUMBgMdHBxMA6BXr15tdv7zzz+n4+LiaB8fH1qpVNLh4eH0s88+S5eVlVnM87333qMB0Hv37rWYZv369TQA+o8//uDa45133qEjIyNphUJB+/n50VOnTqVPnTrFXZOamkrHxcXRTk5OZlv9d+3aRUdHR9MKhYLu3bs3vXHjRtFt8H/++Sfdv39/WqVS0aGhofRbb71Ff/311zQAOiMjg0vnyDb4adOm2Ux369YtesmSJXRwcDAtl8tptVpNT5gwgf7iiy/M0j300EO0r68vrVAo6H79+tHffPONIA27Df6dd96h33vvPTo4OJhWKpX06NGj6XPnzgnSirUBTdP0b7/9Ro8aNYp2cXGhXVxc6MjISHrJkiV0WlqazbrQNE1fvnyZXrRoER0aGkorFArazc2Njo2NpT/66CO6traWS6fVaulVq1bRYWFhtFwup4ODg+nly5cL0tA005eff/552tfXl3Z2dqanTJlCX7161eI2eFMZIDYO8/Ly6GnTptFubm40ALIlvotA0TRZCUYgEAidkczMTISFheGdd96xaq0hELoiZA0QgUAgEAiELgdRgAgEAoFAIHQ5iAJEIBAIBAKhy0HWABEIBAKBQOhyEAsQgUAgEAiELgdRgAgEAoFAIHQ5iCNEEQwGA3JycuDm5kZcpBMIBAKB0EGgaRoVFRUIDAw0i/FoClGARMjJyUFwcHBbF4NAIBAIBEIjuHHjBoKCgqymIQqQCKwb+Rs3bsDd3b1Z89Zqtdi1axcXtqAz0hXqCHSNenaFOgKknp2JrlBHoGvUszF1LC8vR3BwsMXwO3yIAiQCO+3l7u7eIgqQs7Mz3N3dO3Wn7ex1BLpGPbtCHQFSz85EV6gj0DXq2ZQ62rN8pU0XQa9ZswZDhgyBm5sb/P39MWvWLKSlpXHnMzMzQVGU6L9ffvnFYr7z5883Sx8fH98aVSIQCAQCgdABaFMF6ODBg1iyZAmOHTuG3bt3Q6vVYvLkyaiqqgIABAcHIzc3V/Bv1apVcHV1xdSpU63mHR8fL7juhx9+aI0qEQgEAoFA6AC06RRYYmKi4Pf69evh7++PU6dOIS4uDlKpFGq1WpBmy5YtuPvuu+Hq6mo1b6VSaXYtgUAgEAgEAtDO/ACVlZUBALy9vUXPnzp1CmfPnsWCBQts5nXgwAH4+/ujd+/eWLx4MYqKipq1rAQCgUAgEDou7WYRtMFgwBNPPIHY2FhER0eLpvnqq6/Qp08fjBw50mpe8fHxuPPOOxEWFob09HS8+OKLmDp1KpKSkiCVSs3S19XVoa6ujvtdXl4OgFmApdVqm1Arc9j8mjvf9kRXqCPQNerZFeoIkHp2JrpCHYGuUc/G1NGRtO0mFtjixYuxY8cOHDlyRHTvfk1NDTQaDV5++WU8/fTTDuV97do1hIeHY8+ePZgwYYLZ+ZUrV2LVqlVmxzdt2gRnZ2eH7kUgEAgEAqFtqK6uxr333ouysjKbu7jbhQK0dOlS/PHHHzh06BDCwsJE02zYsAELFizAzZs34efn5/A9/Pz8sHr1ajzyyCNm58QsQMHBwSgsLGyRbfC7d+/GpEmTOvXWxc5eR6Br1LMr1BEg9exMdIU6Al2jno2pY3l5OXx9fe1SgNp0CoymaTz22GPYsmULDhw4YFH5AZjprxkzZjRK+cnOzkZRURE0Go3oeaVSCaVSaXZcLpe3WMdqybzbC12hjkDXqGdXqCNA6tmZ6Ap1BLpGPR2poyNt0aaLoJcsWYKNGzdi06ZNcHNzQ15eHvLy8lBTUyNId/XqVRw6dAgLFy4UzScyMhJbtmwBAFRWVuLZZ5/FsWPHkJmZib1792LmzJmIiIjAlClTWrxOBAKBQCAQ2j9tqgCtW7cOZWVlGDt2LDQaDffvp59+EqT7+uuvERQUhMmTJ4vmk5aWxu0gk0qlOH/+PGbMmIFevXphwYIFGDRoEA4fPixq5SEQCARC10BvoJGUXoQ/zt5EUnoR9IY2XwHSKPQGGsczinGqkMLxjOIOW4+2ps2nwOzhjTfewBtvvGFXPk5OTti5c2eTy0YgEAiEzkNici5WbU1Bblktd0zjocKK6VGIjxZfHtEeEdZDiu+unOyQ9WgPtCs/QAQCgUAgNDeJyblYvPG0QPkBgLyyWizeeBqJybltVDLH6Cz1aC8QBYhAIBAInRa9gcaqrSkQm29gj63amtLup5E6Sz3aE0QBIhAIBEKn5URGsZnFhA8NILesFicyiluvUI2gs9SjPUEUIAKBQCB0WvIrLCsNjUnXVnSWerQniAJEIBAIhE6Lv5uqWdO1FZ2lHu0JogARCAQCodMyNMwbGg8VKAvnKTC7wYaGiQfhbi90lnq0J4gCRCAQCIROi1RCYcX0KNFzrDKxYnoUpBJLqkX7oLPUoz1BFCACgUAgdGriozVYN28gTHUDtYcK6+YN7DD+c9h6KKTCinS0erQX2tQRIoFAIBAIrUF8tAZeznIUVWkBAD8sGo6hYd4dzmISH61B/6BrOJlVCgDY+O/BGBHh3+Hq0R4gChCBQCAQugQU1TDpMSLcpw1L0jRo3kqgYR1QiWsvkCkwAoFAIHQJqE6iJ/i5kriWzQFRgAgEAoHQJdB4dI4t4n007gCA2ABDG5ekY0MUIAKBQCB0CZ6c2AsDgj3xUGxoWxelSegNjOJDZr6aBlkDRCAQCIQuwbhIf4yL9G/rYjQZmVQCF4UUMopYgJoCsQARCAQCgdCBuK27J6rq9UgrIyagpkAUIAKBQCB0CT7edwVj3tmPLw9da+uiNAmJcTU3ifveNIgCRCAQCIQuwZYzN5FVVI3Xt19q66I0CXY3G000oCZB1gB1IPQGGicyipFfUQt/N1WHdOJFIBBaF77c8HGWwdDJXpqmcvG2IDeLaWu1nWPNzLd/ZwIA8mqI/G8KRAHqICQm52LV1hTkltVyxzQeKqyYHkXcnxMIBFHE5IanQgp56C3cHhPUhiVrHsTqp3ZXIkFNIaENy9XSpBdUtXUROgVkCqwDkJici8UbTwsGOQDkldVi8cbTSEzObaOSEQiE9ooluVFaDzz247kOLzcs1e9WeR2+vizBzou32qhkLY+BzH01C0QBaufoDTRWbU0RXezGHlu1NQX6zmbXJhAIjcaa3GBjh3dkuWGPXHx9R2qHrZ8tiP7TPBAFqJ1zIqPY7AuHDw0gt6wWJzKKW69QBAKhXdPZ5Yat+gEUcsvqOmz9bOGqJKtXmgOiALVz8iusDXLH0xEIhM5PZ5cbja2fv3vniKHV3ccZADA7VN/GJenYEAWonePvZl/sGnvTEQiEzk9nlxuNrd/K6X3RK8AVk6ICWqJYrYZez8yBkU3ATYPY0do5Q8O8ofFQIa+sVnS+mwKg9mC2xBMIBALQ+eWGrfoBNDQi9RsQ7IldT45pjSK2KBIJIJdSkBIFqEkQC1A7RyqhsGJ6lOg5tu+vmB5F/AERCAQOvtwwlwyMytCR5YY9cvG/UyM7bP1s8dj4nqAoCjuzySu8KZDW6wDER2uwbt5AKGXCx6X2UGHdvIHEDxCBQDCDlRtqD+E0kKcC+GjugA4vN9j6yU3MIGoPJf7dy4Apfc2nud5KTEX82kPYcia7tYrZYtTrDNCR3WBNgihAHYT4aA0Gdvfkfv+waDiOPD++wwsxAoHQcsRHa3Dk+fGIDfdBoKcTXpzaCysG6kWVg45IfLQGfQPdud8/LBqO/U/FYYCPuGawPzUfqXkVePKnc61VxBaBtWyR7fBNgyhAHYiR4b4AgIl9/DEi3KfTmncJBELzIZVQqKjTIae0BqE+Lp1u4axU0vAasyUX63SdIxTG24mpAIBKXSd7mK0MUYA6EFKjqdfbRdHGJSEQCB0JnXHXkKyzaT8AxvX2a+sitDqnskraugidAqIAdSDYrY/E8kMgEBwhJbccAHD4alEbl6T5iQn2AgBEqi0HQWXpLJKzkzq4bnWIAtSBuJxfCQD44cSNNi4JgUDoiGQVVbd1EZod9oNQ14W0AhILrHkgfoA6EDdLOp/wIhAIrUdnNB7ToDE0zBv9unnYTtxJ6q+QMrYLGUUUoaZALEAdCB/XzuHGnUAgtA2STqgBHb5SiBMZxXZZRXw6yfpJdh3oo306x6LutoIoQB2IBaPCAADhfi5tXBICgdARkUs7n8hnFR8pZVu5+2BODIK8nOxaL9SeYaPcS4gFqEmQKbAOgN5A40RGMZKuMQsYyfwvgUCwBisz8itq4e+mwl2DuuHXUzcRGeAKVFlONzTMu1k2WbRUvmLU1jMBQTMKq7h7Xymj8Me5HJTV6OHtqoTanSlDkJczjjw/vkXK0VroDTQq63QAgOxKCn+nF6G0Vi9o53qdARuSMpFVXI0Qb2fcPyIUClnnU36bSpsqQGvWrMHmzZuRmpoKJycnjBw5Em+99RZ69+7NpRk7diwOHjwouO6RRx7BZ599ZjFfmqaxYsUKfPnllygtLUVsbCzWrVuHnj17tlhdWorE5Fys2pqC3LKGqMbXi2uQmJxLnCASCAQzxGSGk1wKAIK4WWLpNB4qrJge1STZ0lL5WiK9gFF89qbmIzE5Fyv/vIi8cimQkixI15JlaC3Yts2vqAMAbM6SYvP6U9x5jYcK0d3csfdSvmCn2OvbL2HR6DAsTxAPH9JVaVOV8ODBg1iyZAmOHTuG3bt3Q6vVYvLkyaiqqhKkW7RoEXJzc7l/b7/9ttV83377bfzvf//DZ599huPHj8PFxQVTpkxBbW2t1evaG4nJuVi88bRAkADMF8DijaeRmJzbRiUjEAjtEUsyo0bLWEku32J2ku68eEs0XV5ZbZNki6X7NzVfa/BnvhZvPI288jrRdLlltXh042mMe3c/Dl0uaPZytDSW2pZPblktdqfkm22TN9DA54cysGZ7SguXsmPRpgpQYmIi5s+fj759+2LAgAFYv349rl+/jlOnTgnSOTs7Q61Wc//c3d0t5MhYf9auXYuXXnoJM2fORP/+/fHdd98hJycHv//+ewvXqPnQG2is2ppiIdIxw6qtKdxcMIFA6NrYIzOOZxZDZwBWb08VTccea4xssXb/puRrC4qnAdmTc0ZhNR74+kSzlqGlsefZ2sOXhzNQ30m8YTcH7WoNUFlZGQDA29tbcPz777/Hxo0boVarMX36dLz88stwdnYWzSMjIwN5eXmYOHEid8zDwwPDhg1DUlIS5s6da3ZNXV0d6uoavhrKyxmnYVqtFlqttsn14sPmZyvf4xnFVjV9Goy2n3Q1H8PCvC2mawvsrWNHpyvUsyvUEegc9bQlMwCgoKIeh/Moi1YSoPGypa1kFtXINZH19fUC5ak9Y8+ztQcDDaw/mo6HRoY2vVCtQGPGpSNp240CZDAY8MQTTyA2NhbR0dHc8XvvvRchISEIDAzE+fPn8fzzzyMtLQ2bN28WzScvLw8AEBAgDPYXEBDAnTNlzZo1WLVqldnxXbt2WVS0msru3butnj9VSAGQ2sxn1+HjKLrUPq1AturYWegK9ewKdQQ6dj3tlRlFdfa99B2VLW0lswIN9t3XlG3bd3QYv0j2tq09HD6TioDSjjUV5si4rK62319eu1GAlixZguTkZBw5ckRw/OGHH+b+7tevHzQaDSZMmID09HSEh4c3y72XL1+Op556ivtdXl6O4OBgTJ482ep0W2PQarXYvXs3Jk2aBLlcbjGdT0Yxvrty0mZ+k0cPa5cWIHvq2NHpCvXsCnUEOkc97ZUZPkr7lA9HZUtbyazBFXX44e2DthOaMCU+vsO4BbC3be1h9G2RSOhAFiBHxyU7g2MP7UIBWrp0Kf766y8cOnQIQUFBVtMOGzYMAHD16lVRBUitVgMAbt26BY2mYbX/rVu3EBMTI5qnUqmEUmnuZFAul7eYMLSV94gIf2g8VMgrqxWd96UAqD1UGBHh325jg7Vk+7UnukI9u0IdgY5dT1syAwCcFVKMVutwrESJW+V1zSpb2kpmqRSNW9MikcoglzePVaWlsefZ2oOEAubHhkPewbbEOzIuHRm/bdoKNE1j6dKl2LJlC/bt24ewsDCb15w9exYABMoNn7CwMKjVauzdu5c7Vl5ejuPHj2PEiBHNUu7WQCqhsGK69S2LK6ZHtVvlh0AgtC58mWFJKgwJ9YJMAryUECmajv3dGNliTWY1JV9bFFTWYWiYN4aH+TgU6aIj+VOz59naw6LRYcQfEI82bYklS5Zg48aN2LRpE9zc3JCXl4e8vDzU1NQAANLT0/Haa6/h1KlTyMzMxJ9//okHHngAcXFx6N+/P5dPZGQktmzZAoDZEfDEE09g9erV+PPPP3HhwgU88MADCAwMxKxZs9qimo0mPlqDdfMGws/V3H37unkDO7Q/CwKB0PywMkPtoRI9H+bDrGmc0jdANJ3aQ9Uk2cLe30UptKw0NV9rfHYgHScyijGhjz/WzRsIlYUXvMZDhQg/V+53R9tAa+vZAkwdJ0X5m61tklDAI3HED5ApbToFtm7dOgCMs0M+33zzDebPnw+FQoE9e/Zg7dq1qKqqQnBwMGbPno2XXnpJkD4tLY3bQQYAzz33HKqqqvDwww+jtLQUo0aNQmJiIlQqyx2nvRIfrUEPP1dM/uAQd8zTSUaUHwKBIEp8tAaTotScJ2Y3lRz/Xv8PAEBCUdxecTZd+IvbAQBjevni6/lDm2yhiY/W4I3tl1BVx3zI/rBoeIt6gmYVGYmEQny0BpOjcvDneeGGl7dm98Ndg4KhN9AY+eZeUBQFugNZgFhMn9ldoXr8mskom5/PG4iJUWriCdoB2lQBstUBg4ODzbxA25MPRVF49dVX8eqrrzapfO0FmYngoDtLSGMCgdAiSCUURoT7cL//HRuGr49mMIt+dcJ0LP5uqmZTUpwVDa8WfjlaAr1R/meXVENvoEXXt/RWu0MqoSCVUDj50qQWLU9Lw39EvTwb3n23hXhxz08hk8BAA1fzKzEoxIsoPxYgrdIB6Uhz1wQCoW34cM8VhL6wDff93zHOW3JryY4hocwur2UTWj78kMFoAvrmaCZKq+tFd3Z1Nud/516ZDBelFB9fbJhqNH20V/Mr8Xd6EbJLalq5dB0HogB1QCpqdbYTEQiELs0Hey4DAI5eLeJsxtbUH2dF8+2I0hmVElPrdUvAV+r0BhqjIxosTn00jBuTOh0TCmT55vO47/+O4UJ2GToqFEXBTSVDVZ0e5dqG9uV72P71VDZ+OnnD7DhBCFGACAQCoRPC1z3+ySrBgGBPLBnbwyzdnbd1AwB083JqtnuzVpnW2KWq5xl3dAYag7p7cr/ZqZ86LZPozPVSHL1ahOkfH0FRpWVv2O0dMQfWfEVHy2sUHVGALEIUoA5AsLczjr4wHu4qZl79ReMWVgKBQLCETNIg3s/dKMWVWxVwVZov+xwX6Y9HxvRA/yDPZrv3jRLGG+87O9OaLU9L0CYWIKVcCo0TjRBvZ5y7UQoAqDNOgfGtRXUddFqsTqfHc7+eNzvOnwITWsU6Zj1bA6IAdQDkUgm6eTohyIvZwtpb3bzeqQkEQufD1PpiyRozfUAglk/tg+E9mm+xMt8C0dLMiAnk/tYZaJTXaDEnXI//jG3wK+ekYF51fGNIR50a0upp/HIq2+y4nqf0GHh1IxYgyxAFqIPw3q40pOQyLr5bY16dQCB0bEzlREWtDokXb5mlG/jabvRbsRM5pc23WHb+yAblo6W3m8+M6QZPZ8b7r95gwK+nb2JtsgyfH8oAAPQKcMX4SCY2JN8y0lH3klhS3Fx4a7gEip6+g1a0FSAKUAcgv7wWH+27yv3+mPc3gUAgiCGVmn8oncwqMTtWXFWPijodymrsj6Jti9G9fLm/ta3wAmaVPb2h4eXPKjhS3lQgX+nRd1ANSEyhDHBXwt+9wc8dX0nqIAHv24R2EQuMYJ3CynrB76RrRdAbaBIGg0BoAnoDjWPpRUi6VgiDwQCqlMJEnQEnrxchv6IW/m6qZnPgx78XwPjoGd7DB1IJBb2B5pwWOnpP02sHhXjhn4xiJF0rRG293iz9zZIauFIU9OdzofF0wVBeUNKvDl/D7EHBNsvB1uVoegFySmvRzcsJI8N9uSm0ExnFyC6p4tI/uuEkRoT74sGRQmd8Tak3//qUnDJ4OSsQ4u2E7RdycSmH2eGVUcSsQ6qp1+GPszfh76aCTt/QJv935Brio9SQSCgUVtY16/NuScQsQFqdHu/uTAXbt3TGdT+zYgLx32lRZtc3pd07E0QB6gAcuVJgdiz2rX1YOT2KeIQmEBpBYnIuXth8AaXVfKuHFJ+u2iPYKq7xUGFFE8eZ2L0+3n8Vns5yzBkchD/P5SK3rNbheyYm52LV1hTBtRSsb3Xfk1qAPZACly4AANQ8q8G2C3n49fRNq+UQbzfgk/3pcFZIoZBJzM7tSyvAvrQCvLHjEh4ezYRjECu7I20tdj0AnLpuvr09s6gaj/941uz498eu4/tj1wXHmuN5tzR8y9X0YD223pCiuFqHj/enA2D6lotCip7+rojwdxVc29R272yQKbB2TmJyLt7YkWp2/FZZLRZvPI3E5Nw2KBWB0HFJTM7FoxtPm72oAXPlIa+J48zavUqrtfj8UIbZS9yeeyYm52LxxtNm1zo6qXOrvOH6Gq3QYmRaDmt1AYDqer3FcwAz/fT5oQws+u4f0bLb29aW6t4cNPV5twbspi4JBWy9If4Kr6rX40p+pUABstRuHaHOLQVRgNoxegONVVtTRM+xgm7V1pQOu5uBQGht9AYaK/+8aHf6powzR+9l7z1ZudAco95aHvxy1OsMjaqLGLtT8kXva09bN2fdxegIcpVdyG1P8R7/8Sy+OJRutd06Qp1bCqIAtWNOZBRb/cqhAeSW1eJERnHrFYpA6MCcyChGXrljDvAaO84acy977mlLLjQnbDk2JGU2ui6NuZ+ltm6Nurd3uRrgrsK6eQONv6yv3anTGXAwrYC8SyxAFKB2TH6FfQPd3nQEQlenKWPF0WubY1yK5dEW4z2ruLpV72epjq1Z9/YqV9lo7/ZSVa8n7xILEAWoHePvprKdyIF0BEJXpyljxdFrm2NciuXRFuM9xNu5Ve9nqY6tWff2LFcdKZtcSpF3iQWIAtSOGRrmDY2HyqKRkwKzgp+/lZVAIFhmaJg31O5Kh65p7DhrzL3suactudCcsOW4f0Roo+tiKV9r97PU1mzdW5L2LlfzK2qx/UKO3endVXLyLrEAUYDaMVIJhRXTGR8Oph2X/b1ielSX9eFAIDiKVEJh5Yy+dqdvyjhz9F723pMvF5qKtRrxy6GQSRpVFzEmRfmL3tuetmbr3lISryPI1dJqLTaYbN+3hoGmrfaZjlDnloIoQO2c+GgN1s0bCDeV0GWT2oNZCNcVfTcQCE0hPlqDz+YN5MIn8DEV/00dZ9bu5eUsxyNxYWYWDXvuycoFlVwowh19ffm5KeGqlMHPVWEWOsO0HGxdTGURi4tCKlpPrmwU8EhcGL58YAjWzRsIdSPqzZZj3byB8HZW2FNFh+gIctVghwdrJc/hJBsLzFKf6Qh1bimII8QOQB+NO8prddzv+OgAvPevGLiIRHYmEAi2iY/WYFKUGsfSi3DfV8cBAKEuBiQMCcenB5gYUj8sGt4sXnLZe/V9ZQdqdczL6PuFwzhP0M/F92mUZ974aA0Uv55HrdbAlTdK444Br+6yq1w/LBoOX1cFJn1wCJV15ufEyhEfrYHGwwkzPzkqOH734CCsubM/ACD8xe3c8QB3BW6V12NavwB8MGcg5wmabZPGeiSOj9ZAAgoPbzwFgFG+qur1iOvpi5sl1UgvrIarUorKOj1GhntjzpDu8HdTYeG3J1BV37CAeHCIJ05mlQIAHh0Tjmen9G73VhBrW9XlUgrrHxqKfam38NWRTLP08dEaTLmQiz/OMT5/mquPd1SIBagDcKNYGKQwMfmWQ7sACASCOVIJhd2XGoKDeiiBQd29uN8jwn2a7cUglVAY2zuA+x0b4cvlLZVQOJddihvF1YjSuDt0z/tHhAAAojTuGBHuA9pODzkB7kqMCLcc/d3Ruj8UGwaphDK7pn8Q056jevoLwmAATL2PXC3AuRtlCPV1drittbwXe99AD7gqZTh0pRDphcyOtco6xrGj2sMJM2O6YUS4DyhKWAZ/dxWcjUFE7xvWvUMoAtYMQHE9/RAb4QvWFvhwXA98v3CYII1C1hA0tTn7eEeEKEAdADGTpz1mUAKBYJ31f2dyf3spAR8XZlqFHyKiuXhtVjQA8eCUb+5Ixbu7LiO9sNKhPLt5Mruzunk5AWD8vvAZGuqNV243X/sxIdIPQMP0CJ/RPX3NjvERu4Y/fRapdgPALKqtMcYjsySvPtmfjq+PZiAlp9zqPcWo0zV4rj6RWYy5Q4JF020+fRNvbL8kWo7BId5cfTqKIsBadAI9VHiol9B79/tzYgAwbT8gyAPBXk6gTDrcwtE9AAAKKXn9kxboAIgrQG1QEAKhE8NfGmGvJcURWCWBpgGDhQF8KdcxRYB9h7H51WmFCpBcRsFJITW9jIuQLjadorMRvV3sGr7yEObrAoBxrGegafTr5gEvG+t1fjmZbfW8GKbKnlZv2SqeVcQEZ72wcgoGhTRY+Qw0zdXHdA1Ue4WNBSaRUGbvAbYOC0f3wB9LR+H+EaFm17somf5AosQTBahDIPbxRBMLEIHQrBhoIKeUcQR3qwW8HkulDW8cMSsKAFAOLmM+mVkCADh2rQgAUK83jwA/Z3Awnp3SW3Ds+LVii+WorNOZHePDRhrnc+RqIfc3/4Pt5dujsPWxUUjoZ32BbWOsL17OcgwI9uR+l9VYjkPG6kZSCYVfHx2BO2/rxpWVVYC2XegYsbBY2S+hAA+F8Pnx2zElpxyP/XAGb5rEklQap8DqdIYu/x4hClAHgFiACISWR2sALuU5PhVjL1PXHub+trSQ1dGv8v1pBQAYb78AEOHvhourpnDnj14twv1fH8fBywWC6y7nVxrLYa7MXLhpHlGdj1jZy3nKR2FlPfe3NasK3womaYQCFB+twR9LYhFg9E/0+1nLvnH4MpSiKGw+w0S9zyis4o7XajvGusq+gR44+OxYuKlk+C1DaN0b+84B7u+iqjpsPZdj9uz/Tm9QVuutWM26AmQbUQdATFaSNUAEQvMyxM+AetvJGo1x1gmLRodBJm2e+Qcxham8VmgJOXq1yKLzQJXcfHrMFsPCzBdP89eZTO+vwaksxjJlzbLDf/k2ZfrJ2jt8aJg3TmQUc0rbsh/OCCY3Az2cGn3ftkIllyLExwW1WgNuVgvbraqesd6t2X4Jnx+6BsBcyeUrfV0dYgHqAJBF0ARCyxPswgSabCnY6a34aA3kvAWo/GkIR9WAGOMUUHQ3d+7YJ/uvmqXLLavFgyNC8PK0SMHxvoEe+Hr+YMGxlTacLJru5gKEfmeiu3lwf7+xPRWj3tqHH0+YO+7jr1dq7ALkp346i0LTPfwAvJVMm7K5svLyr/M52HquwVI0LtKf+7ujrYlhm4zfdKxVrbiqQZU3neaUGit6z9Du3HRYV4UoQB2A4T18BFsZv/v3UPi6Np9begKBwLwA2S3RI61sEW8s7MJq0xdtU6azg72YXWCjezK7us5nl2KjBS/BNVo9hocxC4DZ3W4AEOjphLsGBXG/5SIKji34zhH5L9XyWi2yS2pQUWu+roi/i6sxfLD7MjeVZYqTlGnnm6WMCxFWATJta1elDDNjAgF0nEXQ1woqsWbHJVzJZyw5/Dqxyo6ep1SbTlmyPztIdVsUMgXWAfBwkiNK0/CFNzLcBzILWxj1BppzLubrogQooLCyziFHY82RB6EBfnuSNmxf3BETiC3GtSOHcikMC2QXmFp/PnoDjWPpRUi6VgiAwohwH86xoWk69tnXGP3SfHEoHRMjA9DNyxlDw7whoRgHdlo9DWcHnZsaeAtiASDbStR2Zm0OxZWLrcPR9ALo9AaEejshs7gGmYWV2HI6G8VV9fB2VULtLuyzySJrhHTG/E5kFGPjsUzueLVxQbWYxdrDSY7JUQHYlXILabnl2HLmJncvAIIxExPsiU3Hs5BVXI1gLyf08nfDnpQ8i3WNUxtwg/LDkXRmsbeLXIqjVwrM0ukMBq5e1hwMNpbGjH1LfUtvoLEhKRN/XyvC3kv5Fq/VG2jcKmuI6l5QXoevDl/D/SNCoZBJuEXsJ7NKcOhyPmIj/LqsPCIKUAfht9MN20QtddbE5Fys2pqCXF7n56PxUGHF9CirLs+bIw9CA2LtSdqwfZCYnIt9aQ0vxd8ypdidx+yY4e9qErvuhc0XUFrdsNbm4/1X4eksx5t39uOeq6WxlJh8C4nJjANGti98cu9AFFTWISbI06E6FFQw0z8nM0uQmJyLZ349bzHtvtR8HDYqAaU1WgxavVtQB5YvD2eaHeP32c2nzbesr/4rBe/sTDPLL9no3+dSboXguGnbXMgpx5M/nQUALpyGWNns5YdrUgDF3O/dl/KxS0RpePn3iwj2ZtYB6Zt5WUFjxr6lvqWQSaDVG6w6QQQYRTT2rX3I492zWqvHa9su4fXtlzChjz+S0pkdg2l5FXjg63+6tDwiU2AdgCu3KrB62yXu94ZjWSgzEQ6JyblYvPG0RcUFAPLKarF442kkJotv92yOPAgNWGpP0oZtD/tsTLdOl4tM1Zhe9+jG06Iv59JqLR41Pld7xhLQ0BcMNI37hoWgu4+zQ/U4fZ1ZbHw8oxiPbjyN6nrr00pano8fRxSMXGM512xPwddHM83O12gNVvP7/exNrr/bapvSam2TlB8xLOkNSdeK8LPRB5EtX0WO0Jixb61v1etsKz/8e4hhoIHdKfmch2x7ytTZIQpQByDFxDnaK39cREFlQyfXG2is2ppi03Ube37V1hQzc29z5EFowFp7kjZsW+zt62JjZOWfF23mv/LPi1j5p+38gYa+8Nyv5/Hl4WvQObgtecGoMIfSNwUawJeHMxp9/aqtKajXGexq+9ZGJZPgnqHdmyWvxox9e/tWS9CV5RFRgDoAtvwAncgotvmlyUKD+Zo7kVEsON4ceRAasNWepA3bDnv7utgYybPDQWJeeR3yyu0bSwDTF8prdXh92yXcqnDMAWO4v6tD6ZtKU96PuWW12JCUabecaU2acwdYY8a+vX2rpeiq8ogoQB0AEV9lAqUov8JxgWJ6TXPkQWjA3rYhbdj6NPbZtMaz+tvK2iMxbC3Wbm9kWVmk3bY0Xzs2pn+1FznQXsrRWhAFqAMgagHiKUX+bo77LjG9pjnyIDRgb9uQNmx9Gvts2uOzOpnZsb7YQ7wdW+PUWtRo9aL+kxpDY/pXe+lb7aUcrQVRgDoAYovf+ErR0DBvaDxUdn3DUGB2IrBbTZszD0IDttqTtGHbYW9fFxsjanfb/rfU7szW8cbYFBydYfrDSviHlqCxu6XZ/n7/iFCLXqnbGjGHio2hMWPf3r7VUnRVeUQUoA6AmAWIf0gqobDC6L3Vmnxiz62YHmW2lb458iA0wG9PU0gbti3ss7GlbIiNkZUz+trMf+WMvlg5w/ZYEjvvaHDK1pwBo8CE8WjsLVdMj4JCJsGK6VHNOOHUfDTXAuDGjH17+1ZL0JXlEVGAOgD2xAKLj9Zg3byBUFv5ulJ7qLBu3kCL/h6aIw9CA2x7Kk0865I2bHviozV4a3Y/s+N8j8aWrvts3kB4Opmn83KW4zPjc7VnLAFMX3jjjmjut6Pv4O7GKaUojTtTLqMPHUt4OMl5f9vvBk5j7LPLE6Kwbt5AMyuOSi6B3MLLUyahMHtQENff2baxVFZPZzkUFhy92o99DfnStD7c36YhI5oCW0fT/mRt7FvrW0qZxG6l0VI6CQVMivLnvJ3bU6bOTps6QlyzZg02b96M1NRUODk5YeTIkXjrrbfQu3dvAEBxcTFWrFiBXbt24fr16/Dz88OsWbPw2muvwcPDw2K+8+fPx7fffis4NmXKFCQmJrZofVqKiX38oTP0xSt/MNskv54/GKG+Lmbp4qM1mBSlRvzag5yb9O8XDnPIizObR/iL2wEAdw8O4vxkvDazL+4dFtLlvhKaQny0BqMisrE3lXHC9sOi4cQTdDthbG8mDpSEAt69qx+uXTwL95BeeGPHZUwfEGjxuvhoDcb19kfvlxl5MjVajXnDQ8w8QbNjifUEvPy386jmxb/6bN5ATIpSI8cYrgFwPMafnxszbTIzJhDx0RoYDDR+OHEdSpkErio5KNDYcpbx7zJveHe8OKUXolbtAQDsfnIMrtyqxN7UPCQm30KOyM4lPzcFVk6PRny0mqsbW6//bDyFnSmMQ8cl4yJwJquEcyz58rQ+8HZVYvfFPGxPzjML3RMfrUGt1oAnjM4PAz1UeDY+kvME/d/fL+DHEzcAMGPm8NV8fLr/Gnqr3ZB+qwI6YzM5yyWICfZCWU09LvKcLaoooJZmwnzklNYg1NsJFEUho6gaTnIJaozPYeHoHqjTGfDOzjTo9c27BTw+WoOMwiq8lZjG1cPW2I+P1iAm2AvD1+wFACwdF8F5gt52LgfLjO0FAAtiu+Oro+ZhT1wUUlQa/UEFuCtxq7wOPf1csO3xOChkErz0+wVsPHYdU6ICMD82rEvLoza1AB08eBBLlizBsWPHsHv3bmi1WkyePBlVVczLOycnBzk5OXj33XeRnJyM9evXIzExEQsWLLCZd3x8PHJzc7l/P/zwQ0tXp8Xwd1dhUAgTw8fPTYnxkQGCLzk+UgmFxyb0AgAM7O6JS7nluFVei4EhnnZ3cn66EJ8GRSu6m0eXHShNgR8pe0S4ebgEQtvg46LA4efG4ZdHR8CJi4rOPBtbj0gpl3JjckdyHiQUJfpca7V6XMmvQEFFHWp1wu2ct3X3glRCwc9NyVkKHDZCcHGdmHun5Fbg8NUiBHm7YO3c2/DvUeFc0gg/V8hlElDGi8pqtEgvrER0N0/8vXwC5xGZT0FFPaK7uQvqduhyAd7ZmYbeGnfOmkBB2M/dVHIMDfNGkNFCJTa1N76PP5ZPZYKz5pTVwtdVwY0PvgVoRLgPaJrJOzbcF4FeDQupq7UGzI8NxdAewthtE4IMGNHDm1MuVQoZFMYYZd4uDcqYVm/gYoA1pwWIRSYR1sORsS+TUHhmSm/ERvgy15lcm1FYI3pdP5438X7dmL8DPJy4ILZsUF4fNyVu627/e6Ez0qYWIFOLzPr16+Hv749Tp04hLi4O0dHR+O2337jz4eHheP311zFv3jzodDrIZJaLr1QqoVarW6zsrc0+oxv3Ajv8hLBTLqevl+L09VIAwL8GBTcq8q+jaxII5qg9SODa9ohMKkGwtzOuFlRi8aazCHaRYE43RknZnXILNE0LXuqm8F8cBy7nY4RIANWbpTWc5dYUds2JSi7F+3fHIKuoCgO7ezpUB9Zz9amsEixCQzgHViHiR25f/3cm/skoBm18AWYby+bjosCdA4NQVSfuRdp0bcyJjGJ8djAd80eGYmZMN/xw4rqZ4vbcb+fxfw8M5tYoiVm23FVyTIoKwJodTPiRB74+gYw10wTlZ2EjxxtoGj39XXGdt51eQlFm6bfdkEIuZbxkfzBnAO64LQhj39kPQBi5/oXfLqCPxs1YT8ecUNpDY9ZosbG6TBUTZ7lQfltSXO4c2A1J15hwF05GBZUfeJZ9FpuOX8fIcB/c3t+ytbOz065igZWVMUH2vL0tr0QvKyuDu7u7VeUHAA4cOAB/f394eXlh/PjxWL16NXx8xCM819XVoa6uQbEoL2c8L2u1Wmi1zeuSnc3PkXxTcsvx3u7L3O8fj2cirqcvZ/42haLNB3JlbR1cFY6PRrVbg3t4vV5vV7kbU8eOiL317GEMb5AQHdDh2qQrPEvawLwcDDRQVs3Igep6PerqtRZfMmU1WoHTuMQLeXhmYoRZurp6y+1Wr9VCq2Xk2Nie3kBPRu450tbXCiqZ+1/Mg1arhY590dEGaLVaSNEgCzKLqpFZ1KA4VBjrqpBJUF9fj6o68TAgdfVCOVivY9JdyC7FKeMHFmgDJvbx46Z6AUBv0HMmLa1OXHYEezbIMJmE4tI4yRvavaa2DrXG4+v/zjTLg6b1gFHmTerjj0NXClHHs7YZ9Exb1GqZtlFIG/I+nlHExVn0dJI1ez+/LaghiLW9ebN9pk5nwMtbzuOV25l1SmN6euP1mVH47x8pTEILH6d8+d/TzxmPxoUh2MuJuz/f27hWq2vXY7sx8seRtBTdTj7xDQYDZsyYgdLSUhw5ckQ0TWFhIQYNGoR58+bh9ddft5jXjz/+CGdnZ4SFhSE9PR0vvvgiXF1dkZSUBKnU3AqycuVKrFq1yuz4pk2b4Ozc9n4rDuRS2JIpLPdjUTpEWFgGteKUFKX1QsH98m06+Dqw+/RSKQW9AejpQYOVJU6yxm+D7coczKWwOVOKgT4GPNir+b8yCY2jUgvszZEgq4JCegUFtRONueF6rE1mlJL3h+lgaS3uzSrg7fMNH2HeShorBppbULKrgHfOi3+ssWOySgucKaKglAJD/BwTx8fyKfyQzsiGD0fo8HumBPtzJRgfaMDMEANK64AVp83vH+VpQKyaxpepUrjLaZRrLQ/s5wfoEMgTg+w9nKQ0avQUd2+dAUjKp/BrBlOehyP1yKigsPumBHFqA2aHCft+ViVwqYTCjmwmvVxC491hTBuybyXWgrLpqgTHC8QfxqN99CirB9cOpjzYU4+BvjRe/EeKKh2FEFcaWZVMxmwdurvQeLq/9ThqjaFGB2zJlEBKAXPC7Rv7+TXA62eZZ9bNmcZzAxrKlV0FfJrC1CPGx4CMCgplPFkf5EJjcjcDvr7MtMWi3npEewv71I/pEiTlM215f4Qegx3sc+2d6upq3HvvvZyxxBrtxgK0ZMkSJCcnW1R+ysvLMW3aNERFRWHlypVW85o7dy73d79+/dC/f3+Eh4fjwIEDmDBhgln65cuX46mnnhLcKzg4GJMnT7bZgI6i1Wqxe/duTJo0CXK59R0bLHlHM4HMy4JjQ4cNx/Ae4payd1MPo7ReOD88IjYOPQPsd5ufYHdKcxpTx46IvfXsU1iF4TfKEOCuxEiRaZL2TGd+lukFVfjv/45yvw00cE/COKxNPgwAmBIfL5hC4nP2Rilw/gT3W6FUISFhjFm65JvlwPljAIAP7+6P70/cwInMEvxnTA/MGdsDSpkEaXkVePGTJADAo3fEIcDd/i+ViFsV+OHjJHi7yJGQMBlntqcCudcREd4DCZN7wWCgsbXoH5zMKhVc9/yMgaAlUnyZegre7i4oLxJ6aB4S6oV/MpkppFGjRiNS7cadO228B6v8AEBCAiMxZgBI+TQJKbkVGDpkMGTXy7D75jWEhIQgIaGP4B4bjl3HjgupDW0olyEhYYpoPXf/fB4oyBM9N3zYUMSG++D4h0dwrdDc0/S3V6QodlJj8Tg3VNTqIKGAdYeYmGYGSgrAAB9vTyQkDBPNv6nMdjD9lfxK4OzfAABnV1ckJMQKziuSsvD69jQEqtXwVOThQC7zHEZF+OCbBwfhwfUnATDWyVEjhprJnOFV9fjXF8dxvbgGAwYMQEJM+50Ca4z8YWdw7KFdKEBLly7FX3/9hUOHDiEoKMjsfEVFBeLj4+Hm5oYtW7Y4LIh79OgBX19fXL16VVQBUiqVUCrNp5PkcnmLCX1H8qYk5kJYIpVavF5MaOshcagu9ToDdAYD5FIJ5I3cktqS7deesFXP8joDntucjDBfF+x/ZmzrFawZ6YzP0tQabKAhqKNUJoNcLm5V0JvsH9GbXMtC8e6hoymcMCoV3yZl4bmpfczS7LhYgEVxPeyug8J4T67sFFMuuaxBPqjkItuqFXJUaZkvfxel+XlW+QEASiKUNbTIRmu5XI4bxdXQ6g1cRHq5XA4vFyUCPVTwdFGatQ9NCdtQJrEso7S8RUYKqQT1vGkchUwGuVwOa5u4kq6V4KN7BwEANiRlcsfZfORW5GlTuF5UjdPXSxDgrhJdIyYGJWnoD/x+9cfZm1h3IB3pxmlPqVQimAU7crWIaXNn5l02PtIfIyL8kV1aA72BRoQxblyApxyhvq64Xlxj9T3SnnBE/jhSnzbdBUbTNJYuXYotW7Zg3759CAszj2xcXl6OyZMnQ6FQ4M8//4RK5bgX0ezsbBQVFUGj6Zh+DuzxA8Snu4i7ef4iOHvo9dIORL2yE98lZSH0hW0IfWEbsoqqHMqDwMAupO1qkZbbO3qTMWQAkGlnH68z2dFl6dnyj/OvqdbyFqXysnJ0GzyrqJRWawXXS3mrbz+65zaBvxsAOH+zHMVV9QBg5hfGFNMFxmK7pX49lY1nfz2H8e8d5NYZUQAWxfXA38sn4OnJvc2uMV10LOetzfn+eIPcySurRZSmYb4/KrDBKh/k5QSVsfzWxhe/Xf81OBjPTGZ2yrKHT2QW479bLli8vrEczyjCEz+dxds7U+3eUKLxUOGeocEAhHUqrKxHal4FtPqGZ1wmstyFXbcWG+GLjMIqjHv3AOZ8niRII+EWpztao85Fm1qAlixZgk2bNuGPP/6Am5sb8vIYE6eHhwecnJw45ae6uhobN25EeXk5Z97y8/PjvuAiIyOxZs0a3HHHHaisrMSqVaswe/ZsqNVqpKen47nnnkNERASmTBE3r7Z3xITixZxyjAz3FV2kyW7pdVfJuF0iZ66XcttuAcbCsyEpE1nF1Qjxdsb9I0IhlVA4ll6EpGsNARmLeO7hD10ugLtTqd0+hfQGGifTi5BfUWv3NW2N3kBzfluaUmZ+Pik5TJ+9XlyNtxMvIae0Ft28nDAy3BdDQr1xKqukQ7VRZ8F000+lFnj1r0sN5628sGrrhR8UWp0eSelFguenN9C4kF3KpXmR94KlaWD7hVzUafW4cLOMO+7oVuzveNaMP87exLje/lgyLoKz6ugNNJ766SwOXCkQXPfGjjT068ZMa5XXaEFB3HVgbLg3evOmv/QGGrkl5tuvD6TlI7/cxI+QjaqY1rWmXo8tZ25C7a5CWl6DT5+Dl/MxONQLE/v4Yc+lAuSUMgqWr6scB58dB6mEwqcHriJbpFws1XVavLj5PKQSCtHdPPDurstmaf48exNVdTrMHhiEkcat53oDzZOJFOeTx94xyi68PnO9FBV1OrirLFsn+DKjb6AHgBvQ6Wnu+HleXwIAJ4UEWeXCcvRftRMSY7NeyimHp9G9QmWdjuuff53PwQGjv6Yrtyrwx9mbXVb2tOkiaEtbTL/55hvMnz8fBw4cwLhx40TTZGRkIDQ0lMuHvaampgazZs3CmTNnUFpaisDAQEyePBmvvfYaAgIC7CpXeXk5PDw87FpE5SharRbbt29HQkKC3aa6T/ZfxTs708yOazxUWDE9SuDBMzE5F0/8eNbM5wg//ZnrJfjycIZA+6fATJ2ZftkqRY5Zuje/jms27MD2PGfkldfZdU17IDE5F6u2piCX5xDOVj3FnqVYPpagKOFmjvbWRo3prx2F5JtluP0j8TWHALB2Tgxm3dbN7Hhici5e2HyBs7rwYZ8fALv7AB9XpQzv/qu/3c8/9s19uFkqfPE3tQymeDrL8ead/RzOz8NJjrdm97NYl2WbTuPP87mi5ywpZJbKdjW/UlSpaSwuCinmDe+On05mmz1n9p72PKONx7Lw0u/JAIAzL0+Cl4tCNJ0lmeGskMDDSdHkZ8ii8VChm6cTTmaViJ5rT7IHaJz8ceT93W52gbUn2psCZElQsOoj68Y8MTkXizeedjigYmMwvTefv85mY+mPZ2HqlN3aNW2NpbazVmaxZ9nUZ9De2qgzK0CfHUzHmztSracxeQ6tMcYo2Pf8E5Nz8ejG06LXtyehHuLjjLsGBuGxCT25Y5bK3lgi/FxwtaB1p+hN+4YYfAXon/9OFHVd0tpy29J92pvsAVpeASKxwNo5egONpGvFoufYjrxqawrqdQas2prSaoKPf2/+PLXeQGP1dvGXiqVr2hq9gbbYdo6U2Vo+9tJe26izoTfQ+OJgus10/OfQHM/XXmw9f7YsYrS3XpNVVC1YP2it7I2ltZUfwL4xyrcviE2ptmafAqz3ja4oe4gC1M45kVGMgkrL3p9pALlltdiQlNlsZlJ7Ye/Ndwh3IqPYOO0lPr0pdk1bcyKj2Grb2VtmW/nYS3tso87GiYxiFItMYZnCfw7N9XxtYc/zb62yNBf5PA/2Ha3slrBnjPIVCbH1Xe2tLbqa7CEKUDsnv8K+wZFVbO7/orXgl9He8tqbrjVorjI3d53aUxt1NhxpWzZtaz8Pa/fraH2jhrdovKOV3Rq26sLfmi8WbLW9tkV7LVdzQxSgdo6/m33b/kNEtr63Fvwy2ltee9O1Bs1V5uauU3tqo86GI23Lpm3t52Htfh2tb/B9k3W0slvDVl3G9PLj/taJxBprr23RXsvV3BAFqJ0zNMwbLkrLfjooMKv37x8RCo1H63Za9t5Dwxo8Ug8N84baXQlLs81i17Q1Q8O8ofFQWZi0s7/MtvKxl/bYRp2NoWHe8LWwI4cP/zmwz7elsef5t1ZZmgtvXlt3tLJbwp4xGuHvirlDgjErJhDOCnOvM80lM5qLriZ7iALUzpFKKMSG+4qeYwfNiulRUMgkWDE9qtUGEv/efN8RUgmFlxIiBWlsXdPWSCUUt23YFEfKzM+nsbVrr23U2ZBKKNw3PMRmOv5zYJ9vazwVW8/f3rI0d1kbmx//c8jaeGssE/v4N2t+9mDvGH1zdn+snXsb1CJKX3PIDEewdo+uKHuIAtQBCPN1ET2u9lAJtizGR2uwbt5AKCyErtB4qPDZvIF4JC7MLKgpBSYasyleznI8EhcGFxNvsab35jOlbwD+3csAf3el3de0NWzb+boKrQKOlpnNR0zYiWHqCqs9t1FnY2CIFwDLAX7FfL2wz9eSVZYdY5/NGwhXkRATtnBRSu1+/vHRGnwwJ0b03D1Dg/GZA/3QGq5KKVcnR/JzU8kwb1h3eDrLzbxNx0drEGslNIQj799VM/rik/sG2n+BHbgopXgkLgyezuZbr72c5XZtgQeA9IJK7LyYxzlDFcOWzFA7EBvOFmpj/xwmYuHpirKnXcQCI1hHbPvknCHBeOOOfmaaeny0BoNCMs22zt8zNBirZzHp46M1eHpypJkn6EOX87Hwu1MAGLf0Wj2N6QMC8bkxcCDLD4uG2/QaOsCHxnP3xeFMdkWH8XIcH61BN09nTP+YcY737b+HYFSEn8Nljo/WYFKUGuEvbgcg9MjNEu7rgldnRWNIqDd2XMhFfkUdega4YnRPx+9HaBwG466cKI07UvPKoTMAU/v6Y8fFfADA2N7iVoX4aA1OXS/Bl7xxIaGA7xcKx8WV/Eq8Z+KcLyE6ABP7qBHgrsJ9Xx03y/veod0degHxHeu9fVd//HjiBk5fL0H/IE+uH57IKMbBywX4jLftPzbcC8k3K1BWq8Psgd3wd3ohcsvqMHMAc+/DVwq5XXIf3B2DSX3VAIBJUWqMemsfcstq8fLtfVBZq8P+tAL08HXG5jM5grJ99++huK27F1bf0U+07BpPJwDAmF6+OHiZ8T7fR+2G/4yLQGpeOT7Znw43lQxLx0Xgz3M3cTGH8Q7t76ZAfgUTxsNNKcX4SH/BbqtnJ/XEL0lpyKwUfgg+OqYHZBIJhoV548z1Ery/5wp3LtTHCZlFjEPJ9fOHYHQvZhw+F98Hg1fvQkk1M36/mT8Ecb3sH6Pbzufi/d2XcdegILw9uz8kFq7jP6vkm2W4WlCJn/65AQDY+/QY9F2xk0t716BuULuroNPrkZeZjpFD+qOsRo/SGi0oUPj9zA1kl9bhP2PDERvuiwXf/oNanQEf3D0AM2K6QSqhsDslH8cziuEsl2BcpD9mxXTD+D4BXU72EAtQB0DMJUOAm9JiZ2WT8y1BQV7OgvQpueXQGmiM6+2PBaN7QCGTQMoLusrGm6nVmscQGxFunyt4qYRCfkUtKut06K126xCDi1/GoaH2u7y3lo+p8gMAvdRuiI3whUImwbGMYlwrrERMsGeHaKPOAhc3SyrhQkewyg//vCgmpyiKMhsXpjG0AGB78i3oaRqX8uyPWG2ND/c0KFjx0Wp88cAgHH5uHG7vzygyUglTrtgIobXlaHoJyoz9cmiYN3LLmG3qf5zLxfNT+3DKz1cPDuaUHzY/tl6DQ7yhkElx9kYpblWYu+qwFUSZVVqCeRs4LuVVwEDTOJ/NhAepqNUhwF2Fbcvi8OHcGABAoGdD+n9emoRgb2dsOXOTOzZ/ZAj6e5s/u+Sb5ZjaT43RvfzQL9hTcC6hX0NEdDYMBlvfecNDuXMDQ7wcGqNsHX89lY0zN8y9L/Nhn9WiuB5YOb0vd9y0JhH+bnhmSiSentQL47rRuCOmGxbFhcPLWYE9l24hu5R5FqN7+iG2py+UxtBI/YIY+bL5dDZ+O50NAKjWGnDmeikm9VV3SdlDFKAOgJggFgtP0ZCe+b+Pxg3eLgrMiglEfLRakOZERhHe3JGKV/5MRm4Z8+UjZoLVmWzd9BIxCVtjzfZU/HdLMnJKLcfpaa/QLeiejP/F+svJG/jhxA2rz5TQ/LDPQEIBT07saXbe2tNnfbrcPTgIgO0gpq/NbHihfXUkA6u3XRJN56j/OX44oZkfH4WvqxLB3s5wM4k5RVlY/TGtvwbDewiVI36YBKXMfKrv/x4cjN8Wj0CEvys3VVWrFfbdoaHe6Ga08FiCbcMANxXW3NlgJTLQtEDusOOQfUGfvVFqlgd/m71MQnFTywn9GuTekauFXFgLH5MF8PwpOtNn+dSkXlx+9Q6OUX5eprJUjHHvHkDoC9vw57kGhU5rck+xpQoAUFTFBEvl0hmDyzYEPmXuv/n0TcF11SIfuV0FogB1AMRkq7WXJet91MdViV8eHYG1c29DuJ+rIA0rOG4U12CbMcyG2FojU+ddt/cPNEtjico6HfKMARLr9R3v5d5UZ6iRxiCSbHBaPuxXGU3TXBtfvlVhlo7QcrDPV0pRGBbqJTjn6SyHu8ryCgFWefJ2UeLr+YPx9fwhVu81I6YhpphMavlL29Fo8PycMgqroLMwzvpo3PDuvwbgPmOUcZaqOh1CfITjnv+CVcrNXxF9NO4YFOINF6WMswbVmASHnXVbN3i5KLA/LR/3fHEMbyeae4dny+rpLMecwcG4rbsnAEBvEH4gsLvHA0TWwrC+dfjNJpE0qHumih+ryPQP8hQc5yuMps+Aoigojdv463SOKQv8vOzxrpxRyHi0fvn3i9wxrcn2eUuWGqVMIpqO/Z8tC/v/0nERAIDSai0qam07Be2MEAWoA/CvwUEYFcHsBOvm6YR37uovGqSRhYkkDOxLzcc/Fjx68p1ysS9gsS8L00FrOsisoeUJY0MHca0u572cxBQXR2BfdCreS2TH46Nx7pXJ+Oie2wAIlawrtyqbdD+CY7AvAglFobCyXnBu4agwMysKn9kDg9A/yAOfHUzHn2dzME5kvZCXM2NlCPVxFoREkEksj6GmRmb8+mgG3th+CRdzygTHfVyVuGtQEFZO74MYn4ZxyUYFZxf/yySU4AX7zs40HL1aaPF+FGcBEioGbNsWVNQh6VqRwDLBwsodiYRCSXU9zlwvBQDoDQaBz5zLtyrQf+VOvLQlGUFeQqvSneuOorS6XjDG+OWqMSmX2LQkwKypZDGVeSVV9ZyFy1ErLV8fFfMEbYl6vQFje/sh9bV4eDgJ+6ElC5DCRDaz6dg6s/Vinw3fwi0WHLUrQBSgDkDfQA9M6ctEsu8f5IF/DQ5GjMkcNp+VM/piWj9mDcDp6yX44+xNs10I/MHIDgyxAWrqvOuIFWFoCj+7jhJbJtzPFcmrpuDCyslNnhNnTd4y3lqIHn4u8OBNI4o5RyO0DiPDffD7klisviMaF0wUBsrCi5JlQLAn+nVjPjR+P5sjmubOgd2w68k4vDYrGou+O8kdt/QCAxy3AJmm/u3UTXxx6BrSrcTGMhX6xVX1eDGhDwBm/Qu/fCcyipHHC9VA0zQ+PXAVXx3JQK1Wz7WTqaKxO+UWKut03MtXrF7PTO6NTQuHIa6nH/ZcusW7h1BeVNfrUV6rQ0WtllNA2N1Z6QVV0BtobjH48B7M7qY4NQ0nuQT7UhvWdAGWFSD+WDcVVeymCACo0zZ+CsxRGejpJIdKLoVMIuE+mJiyir+2+dOVI8N9OAWerTNbFLYYfOXM0Xp1FogC1EFIyWW+oK7k22clYC01P5/MxuM/nsVf54VCWhCjxviiPi5iLTKdtxb7krME/6tX39RP21ZCIqHgqpRZ/fq3lzG9/NDDzwXFVfUW0xD9p+3wdFYgJtgTvQLc8PbOK4JzZ66XiG4A4MN/n/30z3WzF5xKLsWprBLc/9UJ/JPZ8IVtSbF2U8k4S6+9mCoWrCIiNXnRF1TU4ZP9V/H0LxeQVSk8l15QySkWSpnErHz8sVuvN+DtxDS89lcKtHoDt77EVAE6eLkAuaU1vPUn5mXvrXbDyAhfuKvkeP63C4L78T/G2LyVcinqjH///MgI7ryEaliYzY4nCdWgxCY+MRqBxvWNbHnOXBdaPKQUhf5BHhgQ7GnmmoLfxA5PgdmIBWYNVtGRSihMHxCImTGBcFfJLFrh2eNT+gZg06Lh3JIG9nmy/ZOVy/xdgY7Wq7NAtsF3AM7eKMUPJ64DAK7mV2Jf6i14OMkxKMSyt07TuXtTBURoAWKkhthXWri/K/byvqJMzbHW6IgWIJqm8fmha6Bp4KHYUKiaMA1WUafDNd6XeDdPJzzw1QlcL67GjAGBWJ7Qh1iA2il7LuUjp7QGPUzWzrGcu1GK3SkNVovnf7uAWbd1g1TS0F/qdQa8v/uy2bWWFKAnJvbC5L5q0XOWMB2yrLJgeotrBZV4Z2ea8ZfwpFIm4RQLhUxiNkXH/5DhTwEpZVJO8fB3U2J6/0BsOJbFnacovvXB8viXmqyJMhhogbxg68SujwGEO8wkvJ1pfBnG/u2ikEFuVA4oCwpZSm45/lw6SrR8bD7f/nsoZ/Wzl4T+GvzfEcZdgt7Bsf7b6WzQoPHC1Ei8tSMNuWW1+OHh4dwSB1Ma1ikJ7zMzJhBlNVrOG7eYKO6qGzCIAtQB+NGo/LD8e/1JjO7piw0Lhommn/tFEo6Z+AEylT/8wcgqQ6brdO4c2A0vJvTB/cNDkJpXgUXfnXTIRN8U829bcbO0Bm/uYBZszhkS3CQFyPQ1d7O0BjeNu+HOZZcC6Djt0hlJy6vAgbR8hPiIx9Gz9mS+PHwNhZXCrd+mQ+PwlQIUiGwPt6QA9TEumneEJeMiBNNrtcbFyKb+Ziz5nwEYReYNY59Py6uA6QyL2FQJRTHr5eYODcbsQUGQSykoZVKM7umLhzecMqaheAqHeWsmJueioLIeQ0OFH3Jhvq7Ytmw0tzD32LUibqMGC3+aTiqhUGB8FuxalrQyilu3I5VQ3P1Zq5Bpc1TWmbuqYGGv9XFRCKaz7WFgdy8sHhuO9PxK+LkpbV9gwubTN/FwXA9u23pJleXFym4qOQLclWYfqc/FRwp+O7qruDNDFKB2jt5AI6/MfAv5pZwyLPjmOIqrtais08LfzQkDgjwR29MXZdXmg6RGq8PRK4VIulYIA834CArydEJ2aQ3qdHocvVKI305lC65h1wUEejrhZCajUGn1BugNtF3rY/jjrFarxx9nb5o5RNQbaPx9pRC/nclGdb0eQ0K98eDIULMFfbbQG2jjeoUaFFfVw9tVCbW7+b3YNIWVdZzjsBHhPhjeg/HhUsprO0fXY5iyyai49gpwxfyRYVi19SInaFj9010lx4gePki6VoSjVwuQlF6IqlotKIkEzkophob6NKo9CLY5c6MEa3akoo9GXPHYfTEP+cFeGBTihVNZJQKHnmKKa73OIFCYxaaLv3pwMPzdVHgkTot5Jo4Qn/75LFbM6IvxkQH4J6MYSdcKAZP+acr4SOHi6wrji5wyKR7/ymAXA24f1APrDmUCAJKzSxGtccfpG6UY19sPASaBMK/kV3BjN8Do3V1KUTh2rRhDw7yhlFHQG2gkpRehRquHk1yCGq0BFBosQCVVWsH4B4APdl9G2q1KLBkXzt3LSS4BTdM4dq0IhZV18HdToV5kfcr4dw9wf9M0jduMayLdVDIczyhGAU9k/uf7U/BzVeKF+D7oZ7SeaE2n9nPLMSRU3FEr+2F46HIBKmp1ov3BkjzUG2jE9fRDpNoN9boGy5aprPJ3VVqMU/F/h65xfx+6kg+phBKN1TU+0h83isPwzs40bL+Qi7dm98dMo+NDPm/P7o/nfzuP08ZF5wDwx5ls1Gv1uH9E15I1FG3NNtlFKS8vh4eHB8rKyuDu7t6seWu1Wmzfvh0JCQmQy61PJyUm52LV1hTk8hYhtiafzWPcy5uWQeOhworpURY91rJ1jBk5DuPeP2xmcmWvB4Cnfj6HapMttBQFPDw6DMsT7IsXZK2d+Pey1paeznK8eWc/BHo6YcbHRwEAJ/47wWpUZFvPMvSFbQCACZH+OHylUOAKYHCIF35dPBIAMOn9g1bXdjnaHs2JI/21I5GYnIvnf7uAshrb238llHDaQOOhgkImQVZRtSBdgLsSq2b05cbFx/uu4F0TT9BfPjAYk6ICkJici0c3nha9HwVz6xPbP/ljLjE5Fy9sviBQ2llclFK8968BXPpP9l/BOzvNp+Psqa+1cxoPFWYM0OD3szm4VS60dr06oy+yS6rxxeEMs7oAEC23GGLtIcjPSQY9zThNZHGS0qjRm2sUbHm/P37DzOojoZgp/h2Px3E+0RKTc/Gf708L6izWBmLyMDE5Fy/9nizYYeho3S2h8VDhv1N7Q591CgkJCXh39xV8cSjDrJ1cFFK8NisaY3v7w1Up45Sb1X+lcFNzfCQUsKiNZI0YjZE/jry/iQWonZKYnIvFG0+3oCs+21gS0HlltVi88bTNuDEXbpaLbuvNK6u1mDfAWI7Y8Bu2BqKtdsq1cS+W0motHt14Gs/zzcXN1PgSCWXmB4ldk7Vme4rNhe2OtAfBNo6OLVNlwJISnV9eJxgXYkqE3kBz97eEWLnY/snGoLKmQAFAVZ2eSw/AbuUHsO7/SqwtTEPlsLzy50XR446+/G09p9Ia8+mrGgtreq2V10ADJdVa7Ll0C/OGh1jsJ6ZtICYPLV3bVMWHf8/HfjyHh3pRuJCYhv87miWarqpej6d+PgcA2LRwGEYaF9mfyBR3j2LoYrKm69i6OhB6A41VW1PaVPmxBluuVVtTLK5hMdDA6u2ponWwt15fHs6w6nm1Jdrp/w43mJuba3lOuoiCY6CZKZMvLAhjMWy1B8E2LTm2TMeF2K6fRzeewotbkht9/1VbU1CvM2ClBeXClJV/XsTKP1MaebeOTONdWHy49wrqdQa7+4npc28N+c3m/es1Cb6yoPyYwvpl+/Gf61yoEUt0FVlDFKB2yImM4jab9rIXGszX1AkLjhbTyynklZsvAHUEAw1sSMq0eL4l2qmIt2W9qWuAWK4VmvtkMRhobEjKdEhI2moPgm1aemzxxwV/owEbMkMmoay6RbBFblktNiRl2j228srrOG/sBPsoqKjDhqRMh/oJ/7m3lvymAZTrKLtlyCXjmrT3d9m2BnYVWUMUoHZIfkXHEViWylreTJ7Vs4qrLZ5r6XZqri+4SJHdPRLKet0s0ZhrCA201tjKr6gVWICmGUPINEe8SdIHWp7GtnF+RW27ld8lRsXbXstOV+hnZA1QO8Tawtv2hqWyujfTetkQb/Etytbu3VyYBkx0FIVUgnq9Aa7KhmH2yb0DEdfLF24qOb7iTbfZi7X2INimtcaWv5sKF4zTDKN7+kLDOeKztaTXNqQPtDyNbeP2LLvdjLHtROLbitIV+hmxALVDhoZ5cwKzvUKB2Ykgth0TAMLdaS6+UGORUMD9I0Itnm+JdlK7q3Bs+QScemlik3wAAQ1hLvieZfsGunNepu8fEerQSgVb7UGwTUuPLf64WDo+Alv+MxKPT+iJ93YxTghrdQazuFWOoPFQ4f4RoVC72+dTRu3OuINoBsNTl8HXVYH7R4RC42F/u/GfO9vHWrrNKQDuMtru+0QYnXq62+HlvqvIGqIAtUOkEgorpke1W6HFlmvF9CiL/i8kFPDwqFCr19ti0egwqz4pWqKdVs6IgtpDBR9Xx52WmTJ/ZBjC/VwEYRD4HroVMglmxlgOamuKrfYg2KYlx5bpuPB0VmB/aj7u+iwJOy82eI02jUTuCCumR0Ehk2DljL52pV85oy9Wzuj8u3nMabyVben4CChkEs59hi1Mnzvbx1oS9p539TBgQWyIYxfZiHMHdB1Z0/lr2EGJj9Zg3byBjfpaVcok9vRxu4jSmPtRUHuobG6BB4DhPXxEj6s9VPhs3kB8Nm8gnBXmVhaKAh6Js88XBdtObkrx2VwN717W2tLLWc5tMf7xxHV8+3emXT5irCGXUoKglJFqN7y/6zLu+PQoXvqdiX10/4juNvNxpD0ItnF0bJnq+BoPFWbGaLjQAix+bkqzcbHxuNCLOwAEezk+tcDvnwBTh8/mDbS4pshNJePSx0drOKem9mBtnZKpXPF0tmxNeGt2fzw2PsLsuKez3Op1jiKWn4eF7P3dlHgkLkz0/mwbzx8ZBqChn5hi2gZi8pC91svkPp7Ocrirmr7yRO2hwkdzB2CAD43n43vjkbgwUaXeRSnF9P4a3HlbN2g8nACYeyznI+lisoasAWrHxEdrMClKjRkfH8HFnHLMiglEbIQvfjhxnfPiGeiuRLVWz/nC+ODuAfjm70wUlNdiRkw3nL5egn8ySzC1rz92XMwXvc+QEE/8k1VqdnxAkAf+WDoKV/MrcSA1H6u3XwIA7Ht6LJxEFBdTxHZR/bBouMBz6qQoNf46exOrt19CQWU9YiN88M38oQ59fcRHa7D1XA62XcjDhEg/jAz3FfUEPSlKjfAXtwMA+mrccNEYYHZK3wB8et8gSCUUruZX4IXNjHIyuqevQ7HPzDCRSKl5FZx3YHYnkGmwWRaFlMKY3n7EE3QLER+tgb+bCn+dz4GzQgp3lRQnz1/CrpsN/XrZhJ4Y0cMHoGnc83+M1+aP77kNU/tpMPXDQyiuqsdLCX3w1s5UaPU0fnl0BEJ8XLjr/zqfI7rjSyyawpSoAMT300DtrkKgpwrHM4rw3K9MPwz0UOHw8+PNrK3x0Rq8Pbs/zmWXolZnwC8nGzy5b/j3MMR09+R+j+7lCzBdHyGuBmRVMoV4a3Y/BHk6AxQ4z8usp+NPD1zF4SuFmBUTiHGR/vB3U6Goog5LfzyDMF8XvHFHP/QP8kB1vR5SikLarQocvFzABdmc2Mcfl3Ir8BGuItjLCc9M6S3wBP3RvisoqKjD6AhfuChl+ObvDGQWVmNSlD+GhPkgq6gKancVDlwuwC8nszE+0g+x4b7wdFYgvaASnx5Ih5NcglMvTQLA7PDLr6iFj7MMh/4+ji9SmWf5w6JhmP/1CdTpafz08AiE+bngufg+OJZeZNPbdny0BjIJoDMwjh17Brghq7gKLxiDt375wCCMjwwQtYSz8vvtxFQcSCtAbIQP/jstChmFVZj4/kFB2jAfZ2SYONZkZZSTXMrFQ7tvWHfc3j8QQ8O8YdDrsN24A355QhSenhyJb//OwD+ZJXBRSHHnwCCMjPA1K5ul3a0PjgjBf6dFdSlZQxSgdo5UQsHFaN2YFKXGtP4a1Gr1nAK0eFwEEvppMGj1HgDAbd298GZiKm6V12FGTCC6eTnhn8wSUBIJAj1UyBHZnlmrEx8Q78+JAQBE+LsiwF3JKUD2WpfExtmIcKFVSCqhMHNgEM5kl2H935m4LdirUQOwoo4REAn9AqHVG7Dij2RMjAoQ3E8qoTAy3Ad/pxchyNuZU4CenRLJCYnskgYf+k3xA1SvM2BDEiOdgrycMH9kKFZvu8TLm8l8QLAn7h4chJ9PCsOQ1OtpeDopsCiuR+MLQbDK4SuF+PpoJu4b1h2Pjw+HW2EK7hp3Gx7eeAYAsC/1FhaPCcdpXuTwoT0YhZr1f9UvyANyqQRavZ4L+8CyL9X8g+O1WdG4LdgTE/sE4MmfzqLK6AV9UKgXYiN8oJBKsHrbJfzKC0vjpJBanGq+a3Aw7hocjPJaLa7mV+KMUS7IZcL0FE8bj1PTuGvycEgkMkQFuovmPSLcBzsv5uHwlUJ083LC7f0DoTfQ2HOJmcrzdVVwY4uVTyNcfTAszJtTgCiK4qxJN0pqkFNaiwFBntz9fjmZjZulNZgzJBj9gzwxupefaB3ZKeQ+GncsGM2Mh/uNYURqtAYuP7Y8Wq0Wf+xvuP54RjEmR2uwcFQYuhvjvkklFGJ7+iK2p6/oPfnQRl/U8dFq+LurEBXozilA/Xn1EUMqobA8oQ+WCyxw5oLFy0VhrgB188DF3ApO+QEYecHW02Di7FEhk2BRXDgWxVmvzwdzYvD+rss4crUQcwYH48yNEly+VYkp0eoupfwAZAqsQ8AKW3agKXnL+JUyKXxclZxZVU/T3ItbQvGiJBuYaMZ8pvXT4LHxEZgcFWB2TwkFhPMiYT/2wxnub3vd4zjiR0csmrMj1OsYaaCUS2CggfJaHSprzT3EdjfubOCvyeAvShXevvEaUI1Wz4X4GNfbHz+fvCE4z7qIUcmlgojjfQMbphwTk/Nw7FpRo8tAsA7rjZvte84yYFxvP273X/LNctRq9agz9q0BQR7cLh92TMqk4pHI+Wn4GAw0ort5YHJfNaf8AMC2C3kY+vpePPXzObPAlPYMCXeVHFv+Ewtf49o1U2WM/1MuYaa2+wV52Hx5A8An+9MR/uJ2PLyhIRiyaf51Oj1q6vUCj+cSqiH4KAC8lZgq8HpuKS9T2HRSXpRWR6ant57LwdZzOYylykp9H/rmBMa/d4DbvWd6/zcTU7E/NR8eTnJu6r5OJE4Zn8u3KnAqq1gQOFfMQaZcxCwopow89+t55DnoY0irN6BWq4fO+GwGdvdCrNEjtIGmje+JBpnUlSAWoA4AJ2xZBYj3wlbKJTh0uQDlxpc9TdOgeYKFFS56mhYII4BZo/L05N5IL6jEe7uFzrFkEglCX9iGnv6uZqEa7FVSogPdcXn1VDz9yzlsPZcjmqZWq8c7O9Pw9dEMrpyNgY1DlF9eh1f/YjzfXsorN0snJgBlPMHKr1tTLED8l5+Egpkyxj8/Y0AgBnb3gr+bEgaaxvj3GPN4RZ0OG5KyLK6lIjQNmhZ+WABAVlG1mTNM9iXH//DQGRpeyg0Rz4X5iylAljyns2PbQNPILhFaAvoFeVisw9kbpajXGRAV6A5XpYynLJhagITkV9TBSUmbrWPiY5pHrVZv9jGWlleB749n4TujtfP+4Q0LcilQGN7DG988NAQPffMPAHDKJFtXwNyiXKvV45U/krEjOQ8zYwJxOa8SvQPc4MfbVSqmMPDhtzJbVlthL7OKq3GtoEpgcWHkKfP35tM34eemxLhIfyhlElTX6wX1EeP1bZdw8HIB3v3XANw1iHGGKTbtzW+DD+fGID2/EkFezgDM15DZuqcpi747iQNpwjJIeH12x+Ojzd4NXQViAeoAcEJHynRSBW/wK2USPLrxFC8teBaghvUGNE2bLW78/WwOcstqRL9i2C+5DDEvxnYqKRIJhYzCKng7y9GvmwdWiuyMqKzT4SteUD5DI7UOtpzv8xQ503rp9AZ8L7IodfuFXO5vftWa4ghax/ucunyr0mzqkW3Dy7cq8F1SFq7kVyDU1wXB3s4Ci5ypNYDQfLDjipX99Xpg4tojwjQ0zT0D/ocH/6PEEQvQq3+l4Hx2KbacaZjiCvJyQnxftTEPoNzEuhHgbnmx9n82nsLdnydx4VY2LBiK35fEcpZOFv4L7lQhhdi3D2Lga7st5gsAz07pjdTX4gXHTK02N0urOeUHADYeb/ibkjD31fL6MH9M8i3VABMdPmz5Njz/23n8fDIbFbU6bDx2HaN6+mLnk3GCbdn9jUrh4rENkeT5KHhvNjb/Z389b9VyxH0smjy3hH5q7m+aBpLSi1BijOlla3yy7fXML+ew6LuTAIBunk54YEQI5g1v2ABxz9DuuGdod3x630DMjOmGpyb3xgBjhHtTrFmxrNWLla2/nLyBTScYOfjb6WxuOq8rQhSgDoDOigVIJZcKoqnrDTTvy4rCoBBvrJ4VjXGR/pxlgc+287lIL7AcjNPUXPvAiBCH5ol/OXkD3yZlITbCF/Njw8zOmwqQpsbfkksbhINpVrUWhNX57FLe/WnRvx2FL0STRKax2LyvFVTis4Pp2HL6JgDmy9af5+PF0a89gv2w1kap8QUhNptB0w3P4PCVQqTkMFZFHc8Swr6PTC0M/LHT05+Z5vR2UWDz6Zt48qdz3LmB3b3g66YQzWPTomG4b5jlnYL81CPW7MX8b/5BqI+zmQ8r/ge+vWNMLpWYfQSM6OGLr+cPxlOTexnzFb6MlTKJ2d/8Mc7/mzZRpphj5p6KxcYha42z5NWYdcQa3c2dp6zVWB1PbD/gPwOKovDpfYPw6BhG0dIbaPydXsirj/XxyS87awX2clHg1ZnRuGdow3Md3dMPr87si/d2pSHqlUSk5JRb3I3Ht1jbg6mC/s7ONGTx1hvxp+e6Gg4rQN999x3q6swbrL6+Ht99912zFIoghI0pxGr+rko5unk6YXykP8b29hekNdA0p+lLKGYB87zhIRgWJj6NsnrbJcH6Hlv8OzZMMBVgjfSCKvyf0bqjtzDBXKcVChBLUwT2IrNiGje9Fwv/RcW/fVMUIL6ZO7qbuSsB9j7skomTWSUIfWEbFqz/R/CVTCxALQf7eNlxJeafUG+gBcoEa9njW4BWzYzGe/8aAD8TL8D8vhwfzVgRVDKJ2Rf8S9P6cC8pmhYqFQUVdXCy4pCTP+WVV16Lgoo6aEWmWPzclBgZ7oP+3dzh44BnDdMXvNpDhfGRARjY3QuA+dQa21azBwZBKZMio7BKIF+EU2DM/2xzsO2i1dv+KGKVK0sKEDctaRBaTKytN2JPiU3Ds2LFQNOCe9paA8TvA6ZtmZicB4BZ3O2qlEFvoJFeUIXqej0WfXcSCpkEC0aFYVp/obsRxy1AxrIY68UWaf7IUADA3tR8PLLhJP6xECG+M+OwAvTQQw+hrKzM7HhFRQUeeuihZikUQciyCT3x2sy+6OHLfEUODfPG0RfG4+v5Q8zSRvi7IsLfFb0CXAWWGnbw+bsp0a+bcE2BXEqJvqTFcGTw8b8svjycgWUiihb/Bf/F/YMEX0WNwZrOYo8ywf/6M51GcARW8LkqZQLPq49P6Ilzr0zG8RcnABBOlQFAea0Wv/B2ABEFqOVomAJj+rSYYVNvoDEzphvXF1hl+enJvfDStD7wc1NixoBAzB4UZOYygU17z9BgDArx4u5lOoa+OHSN8xdlqnQ//uNZXLhpLm9Z2JcZRTVYiD89cBXltcKpHneVHJsWDcdvjw6Hu9w+xT4xOReLN55uuJdIVzRVKFjrBDuOTKec+P2Zb6kGGmSLaZ//394rmPDeAfx+5iZ37GYps1tzw7EsiMGWymAy9W9NerH35yst7JpK/jQSWz4/N6VgA4MY/DZjryuqrMPD353ER/uuAgBG9PDBrfJazP3imKB+l3Ir8PLtUXhyYk9BnjIHFSC2XuyHMfts+LJu58VbyCmtMb+4k+PwImhaZDEtAGRnZ8PDw/JiPULjud0YSNEWFMV8gW3+Tyx3rLCyDml5Fdw0l1Iuwdq5MZjAmw6L8HfDVw8OwbA39tq8x6msEgS4q+yaBjNVRv48l4P/3XOb4BgrFLp5OmFyXzUay4sJkXhjeyq6eao4xes2kzl0e5SJMb39cOjZcZDLKC5kRWPgT5HwX2rDenjDg+cczdTiZbq405LVitB05g4JxshwH4QYt0aLvVfYRyczeTneNyzEPLEJb9wRjRvFNfB0luMb4yL/m6U1ZkrD/x3JwJS+zLovA03jX4OCsGZHKnc+Kb0IE/qY79Tkl09iVKy0ehrfHM3EwtE97Ap5YI3UvArB9G2dTo/0gkqczipBkJczRoT7mNWFbcNT10tgMJivO+RbTN6a3R/1OgMCjFO+bFamFiCAsSZX1DVsJOBPdYvhYlTyrhdXc9OPTPls73rjy60arR5Rr+zkfhtoQKdnxuSDI0KgtuFMkz/2WfmTkluOXSkNu1BlUgof7LmMszdKBdeyfc7XVYmXpvXh3GhIHLUAcQvszcvEp6nW946I3QrQbbfdBoqiQFEUJkyYAJms4VK9Xo+MjAzEx8dbycGcNWvWYPPmzUhNTYWTkxNGjhyJt956C7179+bS1NbW4umnn8aPP/6Iuro6TJkyBZ9++ikCAsQFAsAoaStWrMCXX36J0tJSxMbGYt26dejZs6fFa9ojegPNOfdiHYixPkj+9VkSqup1+M+YhkWANA0cvVrIOTQbGuaNY9eKsHRTg+XlRnENvjqSLrhPcWUtfjxhvjhYjCd+OovYCF/4udkOFSE20Op1BpzKKkF+RS18XZRIyWG+bqvqdDh6tVDUGZkt9AYapcZFiVm8RdtKGYXHf2C+YGmaRlax+YJuAMgsqkJSehEGhXjh3I0yrr393VSQSiijT59MZBVXI8TbGfcOC8HZG6XILa3CtTLmefBfNXoDjazCKsQEe+B6cTWOXWswLWcUVGFYmA/3HC/lCneqldfUc47XAOZrMSm9SPDsxfoEwXF6BrihZ4AbAMZ3jKn8d5Yz67GS0otQVcf0r32XbuHs9RKU1mhBGR3osVaBIWHenBWoXmfAjgu5+OZopojvLfNx0d3bGWONQXIlFGOaZ9WAn05koaCiFjdLaxHk5YQ7YrpBIqFwPKOhXAaaFpjzz14vgdpdxfWNqjodnvv1HOp1BpTxNpnx+5YppuuRaNDYeCwL3xzNxJS+Rh9bJmlYdxRZRdWo1xsEU8HOcglclFIcvVIIUMxuL383FZwVzLuEXYNjaVqLb/mYOaAbfjhxA/5uSvE6sNObFIWFo3tw03DWFCB/NxWCvOoFH3emIqxOr0eKcZv8r6eyUV2nZxRBCSWQu6zcyClrsKrklVXj7cRUFFUJl5CsP5oh6nEfYBRmmqZx37AQTgFy1ALEX9xdrzOgxrhm9Fve4nVAfHt+Z4eibe0NNLJq1Sru/6effhqurg1atUKhQGhoKGbPng2Fwv4AmPHx8Zg7dy6GDBkCnU6HF198EcnJyUhJSYGLC+NRdfHixdi2bRvWr18PDw8PLF26FBKJBEePHrWY71tvvYU1a9bg22+/RVhYGF5++WVcuHABKSkpUKlsT4CXl5fDw8MDZWVlcHe3b2rIXrRaLbZv346EhATI5Za/0BKTc7FqawpyecIzwF2JWTGB2HImB/kVtheuaTxU8HNV4PxN8+3gTeHEixPgb2VnClvHy8pe+OSAMOK5hLK+CNNVKcO7/+pvM8wGi1g7NRbTsvm7KTEg2AN7L+VbLbPaXYmVM/oiPlqDxORcvLD5AqeQiaGUSRDi7Yz8yjqr6fhoPFSYMUCDP8/lCuqq8VBhxfQou9vLUeztrx2dv85m46XNZ1Fa3/BykUsZJ6S2nhFFMS/KrUtHoV+QB9ZsT8EXhzIsepFyVUpRWSe07LkopAK/QI7iJJegxmQ9Cts3AODl3y+iwMJiV7E+tGZ7Cj4/lCGaHgAGdvfEw3E98OKWZIG3a7mU4tYgLRgVhm+OZthcdM3eP7ukBqu3XUJ0N3cki8ist+/qj7sHByMxOdfsvvw6/HU2Gy/8dhaVWnNF4fzKyQ5Zxipqtei3chcA4M7bumHLmZs2vYNpPFSI7uZuU27Y4v4RIdiQlAW5lMKK6X1x5EohpvXX4Pb+GmZ3nZ1j8/8OX8PJzBLQoLE75ZbFMq25s1+TlyA0N42RP468v+1WgFi+/fZbzJkzxy5FwlEKCgrg7++PgwcPIi4uDmVlZfDz88OmTZtw1113AQBSU1PRp08fJCUlYfjw4WZ50DSNwMBAPP3003jmmWcAAGVlZQgICMD69esxd+5cm+VoawWInXtvr/r4seUTrJp+tVot1mzYga8vNz6a+md2xBprL+3EitmH48KsvjRa8t72xGZrDJ1ZATqVVYyMwmqUVtfj9W2XQIOG/aF6zXkhPhIl1XWt3gcsQcE+V56mfciW8tPcNIyfHriUV4FhYd741+AgFFbUw0khxeM/nsH57DK8f/cAOCukomOePwYZ5VP8WX4wJwZ33GZ/AOKyGi0GrNrVmGo1K2G+LsgorMIzk3th6XhmJsORsWnPM31tVrTAj1N7oKUVIIfXAD344IMAmF1f+fn5MJisjOvevfEaJLu42tubiRVz6tQpaLVaTJw4kUsTGRmJ7t27W1SAMjIykJeXJ7jGw8MDw4YNQ1JSkl0KUFuiN9BYtTWlzV/q1hCbo+ejN9DYnNk0DwurtqZgUpTa4vROe2ontgxftMGLjxXzttqLYM4vJ7Px4z834KqUGZ9h09ru84NXuZh87QF7xwa/D43p5d/q/Zi9/5/ncnCEF/OM9brtZvRyz5ZRrF7ssS8PZ1h9lm8npmLGgEC7x4mD9oEWg/VzZkP0ilKvM+DLw7afaZ22/fTd1sJhBejKlSv497//jb///ltwnF0crdc3zoxrMBjwxBNPIDY2FtHR0QCAvLw8KBQKeHp6CtIGBAQgLy9PNB/2uOkaIWvX1NXVCbb2l5cz5letVguttmkRwU1h87OU7/GM4maZzmlJTmYWQu1m2dpwLL1AMJXQGHLLapF0NR/DjIETTWmP7dRWopKG7fZqLLb6a0dGa5RVlXXNI/hL2pHy4yhsH1r9V3Kb9GNrfZh1pHitoMLmmLc15WRtnKzYmoJz2WV4emJPjDbGCKurb1/9/oM9l/GfMaEA7B+b6//OtGsq7lh6ER4c3v6mwPj/O3KNPTisAM2fPx8ymQx//fUXNBpNs7nQXrJkCZKTk3HkyBHbiZuZNWvWcGuc+OzatQvOzo3fCm2N3bvFvbCeKqQANH7qqDU4fPwsJDcs+w5qrjrsOnwcRZfER25HaKfWxlp7NRVL/bUjc+OGBMQXrJCTadfRlm2y6/BxpJ2hcSBXgpwqCmHuNM7lUvBRAilpV5ulbJbGyck0CS6XSbD/739QcYU5X6EF2lvEqO3btwt+2xqbX5+1r5/Xltwyy7u94Ij8qa6utp3IiMNP9uzZszh16hQiIyMdvdQiS5cuxV9//YVDhw4hKCiIO65Wq1FfX4/S0lKBFejWrVtQq8W3TLPHb926BY1GI7gmJiZG9Jrly5fjqaee4n6Xl5cjODgYkydPbpE1QLt378akSZNE5zR9Morx3ZWTzXrP5mbk4AFIiLG8Nd/jSj6+u3K2yfeZPHqYRYtGR2in1sZaezUWW/21I7Pv1wtAQa7thF2Iwb27I+1Etu2ELcTPGXK4qWQoqGQWOKdXUJg/ojv+mxCJ4xnF2Pt108e8pXHyS8EpXC4rQv8BDfKtrEaLbzKPI73Q/pdqS5OQkADA/rG5PvsY8m7Y3ggTNzASCUbniO2FxsgfdgbHHhxWgKKiolBYWGg7oR3QNI3HHnsMW7ZswYEDBxAWJgyVMGjQIMjlcuzduxezZ88GAKSlpeH69esYMWKEaJ5hYWFQq9XYu3cvp/CUl5fj+PHjWLx4seg1SqUSSqX5tm65XN5iQt9S3iMi/KHxUCGvrLZdrG8xxVUpxbg+aqvtMjzcD54KGmX1VKProPFQYUSEv8W5erad2tM0mL2LTlvivmob7dVUWnIstBlG67WbSobKWl2Tn52XkwylNU3Ppy1g+9BLt0dj04nsVq8DBcDdSY6yGi0okx1yoCSQy+V2yUaJcUeepfPW5ArrRZ6SSLm+7iuXY8cTY9DrpR2Nq1gTsCRPTMehrbHZJ9ADZ2woQBIKmB8bDrkDYY5aE0fkjyNyyuHavvXWW3juuedw4MABFBUVoby8XPDPEZYsWYKNGzdi06ZNcHNzQ15eHvLy8lBTw/hO8PDwwIIFC/DUU09h//79OHXqFB566CGMGDFCsAA6MjISW7ZsAcB4FX3iiSewevVq/Pnnn7hw4QIeeOABBAYGYtasWY5Wt9WRSihu62p7ZM2d/eDjat0HkFRC4c5QQ5OE6IrpUVZf5mw7tYclv5Tx38Nx5rHOWuPegO32IpjDOn6bGs1ak5v22n9uap826QOWoCz8bSndiulRcFJIm6UOXs72v4TY+880Wl0sbbLgy0bT+rBjcNFotuziz/KV2y2PE9OgoSwKmQSjIsRDCbU0o3v6WvQRZC8Kqe2lAj38XLHn0i2b6TobDitAEydOxLFjxzBhwgT4+/vDy8sLXl5e8PT0hJeXl0N5rVu3DmVlZRg7diw0Gg3376effuLSfPDBB7j99tsxe/ZsxMXFQa1WY/PmzYJ80tLSBOE5nnvuOTz22GN4+OGHMWTIEFRWViIxMbFFtu63BPHRGqybN1AQWBAA1O4qPBIXBo0N76P89JOi/G0ndICpdm61HuBDY0Gs+ZZKW69oN6XMri3wQEM7+bra73vKGqZlC3BX2tV+ag8l1s0biOUJUfhs3kB42hD+Ae5KPDgyBB4q+w2wGg/xZ6/2ULXYFvjODuuoM7qbBz6aOwCeIt3IVWn7GXk5y/HZvIG4Z2h3LE+IwiNWFAhvZwXcTZ67k1xi132s4ayQmvVftYcKn80biM/mDbTqtsK0D7F1sDRW2fp+Nm8g/EzGnsoos3qr3fBIXJjFgJ58/N2Z8RNj9Nxu6pBv/d+ZuP2jwzifXcqNedP6sHVYnhBl8VkCwNR+lscJ5zBQZOdXQj/7vPEDzFidFOXf5I+zFTOisGHBMLw2qy93zJZsEYOtV0yw5UgNV/MruUC/XQmHR93+/fub7eb2bDFUqVT45JNP8Mknn9idD0VRePXVV/Hqq682uYxtRXy0BhMic7DdGDDvh0XDOQ+jz8X34bwB+7ooAYoJebHtfA52peQL0tdo9Ri5Zg/Ka/WICnRDb383jIzwBU0DZbX1eH0b43L/5Wl98HbiJdTpgefje6NWq8eHe6+alSsltxy9AtzMok2LYRpzDABG9/TBoSuMe/1v5g/GQ+uZOf2H43pgTC8/hz1Bx0drMKaXP97fncZt9QxwUyDE2xkXc8pRZeIcblCIJwwGGmduCOMr/bBoGM7eKMVbiWkAgP/NjcG0/sx22cUbT2JHMvN1dO/QYDwxsReGGsOGTA/W452FcVApFVx5JkWpMefzv5FdUotJUf7Yk3ILueXMLsN/DQrCm7P7QyqhsGRsBJcPy+Qofzw4Mgw3Sqrxwm8XAADf/nsIRkX4cc8+/EVmoeLdg4KwxpgXwXEWjOqBqdEaRHfzQJCHAtpMPfyihuPHkzfx13lmbdAX9w8CRVFYvvk8MouE60CWjgvHiHBfsz67PCEKT0+OxLd/Z+CfzBK4KKSo0emRmHwLxdX1WHNnNJZvTubS12gNWDunP5746SwA4LZgD7P+qXZTwEUph1RC4XJ+pVlddj0Zh1FvNchmvrwAgElRapzIKEZuaRWuJp/FsGFDUVqrt+hNnF+HpPRC7Etjlj2snB4FHxclgr2d0TfQA70D3DHuvQPcdaN7+mL3pXyk5lXgx4dH4OnJkdiQlIn9afk4crUIEX4uWDUjGjRNY1tyLtxVcjw+sSecFTJBrC9Tkm+Wcx6M2TFmySP6lL4B3LMsqtZh3f50pN6qsJg3Cz/gKcvN0hpMfO8gakxC0gR5qhDq44L+QZ4YEe6D+78+AYBRDtmt/J8dvIo3d6Qh1McJvq5KnMwqFb3vfcO6I/lmKc5lCxWQ8b2ZnczdPJ1xe38N/jqfC5Wdgaj5sI92WA8fuCplOHK1CLERPqBp4O/0hlAnXdETtMMK0JgxY1qiHAQRpLy4UCPCG0ywUgkl+M1yjic0h4V5QyKhkJZXgfJaZvA+PDocEgkFmqYxNVqD8lotpwD9e1QYXjO6Wr+aX4VXbo8SVYBmfHwUiU+MRqTatllWLBRGTHdvHLpShPuHh2AoL0L9U5N62aVUieGkkGJ8ZACnAM2P7YHFY8ORXVIteCmo5BL8tjgWP564jjM3LgjyGBjihYu8L6AZMQ3O0viyb1KUWhCLJ8jVPECsVELh18WxOHO9BAfSCjjlBwD6B3ty6cV2UAZ5uSA2whc19XpOARoc0iDc+bfq4e9KlJ8mMCjEiwtSqtVqIaGYcbMvjXkpRKrdMCDYEy5KGTycFYCJAvTkpN6QSiiczy5FZa0OfTTu8HJhFGGFTIJFceFYFMekvWtdg9sQuciUhKezHNP6aaCUSfDe3QNw12dJOJVVwp3Pq6jHPX0C8MOJG6J1YYOQspjKB1ZmaLXu2J59BiPDfWyulWDr8ODIMMz/5gSkEgpZxdVYuTUF80eGou8MDyjkwvuWGoOfst6zFTIJFozugdsHBCIlpxxeLgrEBHvinZ2pkEkkeCg2jAuFYSvGlYwX/8uSDGRhn6VcLkd3b2fc8enfFtOyuKnk8HFRQMGTu3o9bab8AMC0AYFYPrWP2XEXpYwbk05yGVyVMgzv4Yvobh4WFaDMoipcE1lkLZVSKKmqh1xKYcGoMPx1PrdR450fDJX10h3o4SQIugwAerFot50chxWgQ4cOWT0fFxfX6MIQhATyzLxnrpcgJtjTotuBv87n4GtjwMUFo8I4YcIfMHKpBEs2MbGxxr7iL4gpww+EpzMYoJRL0MPXBdd4sbVY7B0nYh8U7CCTSihIKAqzBwZBbzCgoKIOF3PK4O2ixNBG7GRiq9LDzwWLxzLx0ZQmX0v/GRuByjodQn1dsHZODHxdlZj31XEATKBCL+cGu/nWczkYFuYNf3cV6ozxje4ZGozbunsKQha4WYmsfe5GKT7ce4X7fdegIKhkEizffAE0TePhuB5m17DtI5dSWHNnP0goYYBU/leaaeBUQvPwzd/MOArzdYGLUoZXt6bgnEmgSgC4lFuO6G4eeHHLBSTfLMc3Dw3BuN7MlGmtVg+KAhRSiTGGYsN1YrGcPJ0V+OS+gdxvsfccq/yMDPcRfLlbSt9cKGQSbFrErLlcs4P5SGLlCr8uY3r5WZzKC3BXIcAYPufcjVJ8sp+JRzh3aDA3nSW14VJFKmlcf2fzV9gYL+/+a4DZMf5H3O9LYvHerjQcvlIIpUyK+786jsLKenxy721cGv6YfHBkKB407qqyFmvx6NUi0eMyCYXbXmO2f79+RzTi+6oxvIfjsrGHnwvievmhh58r/slklGoxqUUsQHYwduxYs2P8l3JjHSESzOEPpjs+/RvX3kiAJRnx0z8NX4ZfHcnAiYxi/LZ4pEAwBnk5cX+/sysVi0Y3vICjVjREPA70dIJKLsW+Z8aiXmfAhZtlyC+vxeLvGeXJUjRhM0TS8YMjOimkeO9uRuj8fuYmnvjpLEZF+GLjwmH25W/kRnE1vk3KBADMHsi4USiqrMMPPKFze38Nlk3oib2XbmHBt+Zbaeu0BowyOj8DgMd+OINvHhpiVIAYpWR0Tz94OitQXMVMQbipZOjmYtn5namy+uupbGw5c5NTNheO7oGZMYHQG2huyoUVQjKpRDQuD7/tFe10x0ZH4URGMQor69A/yAMBrg3WkFERvjh8pRBT+jKLo6/ki0+f3PXZ30h9bSq3xoI/Ff/0z+ew7UIuVs3oiwdHhgr6gthXPHuoTqdHdZ0eH869DSPf3Cd6X1PlBwCcm7iGyF7YKrJ18HZRIPGJ0ZBSFHoGuCExOQ/bLlh3LVDFczy5PzUfkWp3SCUUvF0UGBLqhVAfFywdH4HSai3kUgkS/ncYgONBQFnY93pjXNax481NJUNMsCemRmvgJJeip78rfvrnOm6V16Ga90HE9hlTxvfxx2+LmZ3Ls9cl2XVv5iORKf9P/9zA+ewyeDdiveOcId0xZwgjS85nl0EmoQTBrGUSCjoDTaLB20NJSYngt1arxZkzZ/Dyyy/j9ddfb7aCEYQaOUVZNxGbvmwv3CxjrjEeV7ur0D+oYU3OxmPXBS/Yep0BKrkEtVoDfFwaBplCJuGmCQI9VMgpqxXTa0QRG0+7jTsN1v+diZUzGhb3sXVrzCDMKa3B9gt5CPdzwZJxEQCAgso6vL/7MpeGzVXs5XPk+XHwdlGgpLpecJx9obEKEPsFyf42XaTOZ+SavYIo4HcYAylKKQo0RcNAA+5OMnw4l/l6/Ov8NgC2lUulTIo/l8aipFqL3sZI5oTG8fH+qzh0uQDv/WsAZvQPMDv/4d4rGBDsabFPUhBOZfIto6zVkO0jk/oE4ERGMe64rRsGBHnitZl98dWRDG5dkYRipqb3XsrHf74/jQHGBcH24OOigKtSxo3floRtC1bcyKUSwXR4pJrpk24mClleWS0OXSmAu0ouGDfv7rqMhaN7QCqRYkS4D34JH8mdCzHOcPm6KlFYWdfo6d5zN0oxfUBgo3ZysY+elaP3DuuOe4cxcvPNHczyAb2BxodzY1BSVY+E/uKLrP3dVFxoD3uRSShIJRQMehrnjRHoTXeoOcqaO/sBAPakMHI4JtgT43r744M9l7ukBcjhT0gPDw/BP19fX0yaNInbHk9oPsJ8G7xQ21I6pCKyQUJRgp0NpqZ4J7kU9wwN5n7LjSZmU0FTWFmHZT+c4V7o9lqAxNLxDxkMNKrrdajT6bkvYLutSzxYoZxeUIUBq3bhvV1pZtNfk6MCkF5QabZWAgCCvJwhlVDwclbgvmENSiFblO8eGorXZkXjSn4lruZXIsTHGb88OgIfzTU3mbPwI2/H91UjzNcFAFCvN/C225pf58aLVH34SgEOpOVzL1OW/kGeGNPLz+rOHoJt2JeJaX9nFeGMwipcK6i02CdN12Xx03FKsnGNDDvu9AYa3X2cMba3v2BRtVRCIeqVnfiP0cpqTbm2BPtyG82zZDYXQ1/fg34rduJmCeOixNJ0FdcGJqev5FfguV/PY+2ey2b92ZZlhp0WbqwF6EBaPraey0FhZb3VdJ8euIq7P0vCH2cbFmOzH0FlNVp8fjBdcI59/nqaxsyYbpgfGyZQcv44exP3f3UcXx8RxuFaavxIs4VUQpl92P74j/gaMEdhxSBN09zaKr2+6ylAzWY3DQgIQFpaWnNlRwBw16BgPP/bBdsJ0fCFIjzGG6RGYS+hKG6bp1IuxZo7++NkZgmu5FeiwmiaLjfGNJrzeRKOZxSb5WuvkjI1OgBjIgOQ8OFhlBgXRdImOyxGv70fTnIp3jdOhTVGAeJ/uZTVaFGvM5hNDz3+41k4yaX4ev4Qi/nsTsnD98cbps3YbD2c5didcguHLhcgwF2JCP8grNl+Caevl2JhbwoJNspEgxbEm5IY7do6gwH1OgMkFLPbSEJRGMn7Sn3w6xMw0MCJFyfA351R6PQGmqsfWQDdNNi+ZmpZTb7ZsBheb6AtrnljtyRzCi2v69ZpWSsh89y4hajGe5p2cwlFQSGTcAtuT4iMO0sUVdVDb6B592z+qdHKOh2q6/WoN/roYeus1Rvw6f50fLDnMmQSCv+d1odLz4cvh1jlkMVUdp25XoKdF2+hul4HfzclSqq18HVVNHrNG38RsDWuFVThRGYxxkU2uL7gX7JmRyoGh3hhpnGDhIxXp9LqehRU1MFVJYPGg1lqcL2oGoevFCLIyxmZhVXYm5qP4qo6QWBS1qpuyr3DujNjvBlCTX1+MB0f7r2Cfw0KwqqZTJxNitdnH4oNxb1Duzd6E0pHxmEF6Pz584LfNE0jNzcXb775psVQE4TG4cgLTmx6jKIobmtncVU9ruZXQEIB7PcXO4BNBVJqHvMCuFEs7v7dXkups0IGd2cZIvyZxXdfPTgYN0tr8MofF6GSSzilTCahuPI3xgprOkUhlVCiLwED72uHzxvbL+H+4SGoNPFAy1fW2Layx0xsMNCCF1xWUbXgWbJ/phdUYdRb++HhJMe5FZPN8mHN33y/JFfzKzFlLbMRYfeTcehJpsEaTcNHgeU0Bpq2qJTLTCxAtMACJJwCO2tcRP3X+Vy8NrMeBy7nC/Lq5uXUJMWlolaLMb39sP6hIYLF/M0F23/rjbJCwlPoPtjDTDXrDDSOX2MUN9MmYy2v1hSgv9MLseyHsyjkWU8BZl0fu1awMZRUMR9f/9t3BY9N6GkxnZQSKqkAYyUfFubNfQiezCpB+IvbsXZODNcmOj2Nx388i4OXCzCtn4ZbzN4wfQak5lXgtb9SBPdbOCoMzkoZ/mfcKDEpKgCzYrohNsIHnsZn2BwfOToDjep6PWq1Box6ax/qdQYsM7bDhZtl2HY+F/8aHGwjl86JwwpQTEwMKON8NZ/hw4fj66+/braCdRX0BlrUn4XeQOOYyWLHo1cLLfrJEROdR68WItzPlfudklMOmvcCP3O9BIO6e+NmqVDRYa0MYu/6JePCkV1cjf2ptwAwW1Gt+e7RG2hu54FWb0AP41RQsJczp0xIpQ1TdaXV9dhyOhuFlXUordGC4t0DgGhbmSolMgklai6naVrUzPvFoWuortOZeaC9lFuBqjodfj51A0npjABMyyvHl4fScfp6KQDgZhVTR/6GYtPypOZVIDWvYSEtW4bkm0weFGgkpReJ+jQBgJ0X89A7wB0xwZ748UQWd/zdnamI7xcItbu4LxdHqdcZ8O3fzAL66jodfN1U0HgoIS2lMMWkjmLw+7KvixIGmsbxjCLY008ag6WxYy/cgl7+Jg6TZ3csvQilNeJTJ6buDFLzKlCr1aOwso77eLh6qxJje/tjSKg3/jibAz83JX45lY03tl/i8hnd0xdOcin0BvMNJNGB7hjewwens0pwWmQnGr+cWy/k4ExWKWYPCkJ0N49mbWt2PPUNdEd3byeo3ZXQG2izKWUf3iLdpPQi7pmwZdHqDUjNFfq7YYtZrzWYKT8AcOFmCd7dmdboPlRea4wobmWKR2+guWnrrMIq6A00pBIK3X2c8dMjI7A75RYWfXeSS3swLR9soJ9arR4HLxcAAJJvluCJH8+gul6P6nqdsX7i8ijpWhHqtUwaP1cFQn2c8cXBK3h/VxpG9/TFpL5qiO3XYtvVXliF7tDlfM4lx42Sht29287nQO2uQnF1vcCvnKUxxcoJ1sfVnQODMDKCmXZtynhsCyjaHm+EPLKysgS/JRIJ/Pz8OoyXZXsoLy+Hh4cHysrKWiQY6vbt25GQkIC9aYVYtTVFEM9K46HCjAEa/HQym/OlwcfTWY437+wn8PybmJyLx344IzrAKUr4NUbBPof/7O4Dsfublsu0TGwds5x747PDmYJdEt4uChRX1SPczwWf3jcIU9Yegq+rAnOGBHNbY8VwVkihkEkE99Z4qDjX+I9uPM0dv72/BkeuFHI+SfjYW39HULsrsXJGX67+NfV69HklEUBDfa1hWia2D3x+KMPSJWawbdFYj9Brtqfgi0MZFtvG00mON2f3s5h/YnKuWV82y0Ok7zYWsfs52gaz1/2NU1kl+GzeIEzo7YM1G3Zge54z8srNX8JiqGQSpK6eitf+SsHPJ2+golZ8RyDrpZnvPoFFQgEfzInB8s0XBOOkqVhqC778cSRmUr+VO83qp/FQ4ZXbo7jdoQDjOZs//cWWQ+PhhJmfHBWVK5/NYywmL25JtjlW7OlDpnW87/+OcVvNM9+cZpbenr70yIaT2HnRPFSEQkrBRSnjpvjF6KtxxzPxvfHQN/9YrZsYCpkEEgC1JlYzjYcK/53aG/qsU1af5ZrtKQ7JEVNM28GSnFDKJHBSSEXlc1PGe2P6qyPvb4cVoK5AayhA0pBBeOzHc41+GbPhIhKTcwUv/7aELZNWq8WaDTvw9WXrc8rblo3CtP8dgYeTDGU1lreTW4L9tlgwOgz/d7jxg7w5oAAunEBFrRb9Vu5q0zI4giNCUixMSWJyLhZvPG13X7Y31IklLN2P7Q/2tsGsT47i7I1SfPnAYNTVa7H0x7MwW71rg0fiwqwqjm2FpbZozAvFkoxh70FZ+Fjip7njtm7YbMXTs6NY60OOKED29KUz10uapEQAwMDunpzVuDlgy/dQLz2W3z9V9Fk2Vfnh36cx7eDoeBSjpRWgRk06Hzx4ENOnT0dERAQiIiIwY8YMHD58uDFZdUkMNLB6e2qThOaqrSmo1xmw8s+LzVauprJqawr0Rn8SmzNtdy12PYGlL2dbsO3317kcfHLPbVbTtgb8+svFtuW1YhnspV5nwBcOCDXT/PUGGqu2pjjUlx0tIx9r92OP2Zv/sgkReHt2f/RWu2H19tRGlefLw+1P+QEcbwtLsO1t7R7WsqeN/34/23zKD+BYvSgLSq09fenFzeebrEQAaFblB2go3+ZMiWg7ODqubd1nxR/JDufXXH2wJXFYAdq4cSMmTpwIZ2dnLFu2DMuWLYOTkxMmTJiATZs2tUQZOx3p5ZTdZnZL5JbVYkNSZpPzaU5yy2pxIqMYJ7NKUFpvWwG4cNPo26IJY4MGkFdeB20bu3Gn0VD/S7kVVtcbtEYZ7GVDUqZDL3DT/E9kFFud9rInD0ewdT9H2mB8ZADuHhKMmyU1xnHkuNLaTuU6gMb1B1PsaW97aO52cqRe843emE2xp27F1Y37OGsNaACl9RRO8kKmsDg6rm3d51ZFfaPya44+2JI4vAj69ddfx9tvv40nn3ySO7Zs2TK8//77eO2113Dvvfc2awE7I+WWp4sdIsvCLq22JL+i1m5v4HVaA2KCPbkdMk2B3enR1uRXOKYMtHUZGtOH+Pk3tr4tfZ0j+beHZ9aSNKV+7blt7C0b6y9LY+I3qz3XzRHyK8w/gtvbu6G9trXDFqBr165h+vTpZsdnzJiBjIy2XYfRUXC3f+2hVUK8nW0namUYj6dK2wkBRHfzwPPxkc1y3+OZRXCSN7//E0dpjMfXliiDvTSmD/Hzb2xdW/o6e9Idu1aE/an5cO7k/k+a0h/bui9bw96ycf6eTHzqtOe6OYKYvG1v74b22tYOvzGCg4Oxd+9es+N79uxBcHDX9CXgKOHuNNTuykYY3BvQeKhw/4hQqN3tUzZaA40Hs/VxcIgXPBW2DaZDw7wxNMzb7MvMESgAHk5yJCbfYrwjt1F7UGiof6CnqkWDU9pTBnu5f0SoQ/3QNH/2+TUlD0ewdT9H2uDl35Px0Pp/4KSQGvuN40b+9rzLtzH9wRR72lvt/v/snXlYVGX7x79ndtZhhwERkEVFFHfF3dyQUrPNLMus18pfvdWrttimtpetb4uWmZa22JuZWkiZuaKAihvigiwCArLvDAwz5/fHzDlzzsyZlQEGPJ/r8pKZec6zn+fc537u576lCPI0Pwcc3U+2tKuuRYU58cFYMj6c9b01bfN26ZoYa/ZAAPCSkBipC1XExNb72lI5gR4Su/JzxBzsTGwWgFasWIGnnnoKy5Ytw9atW7F161Y8/vjjeOaZZ7By5crOqGOvQ0AALydpNR/2TtLVc2IhEQlY8bS6m9VzYmmfH3eEW7bJERDaf9RRdluh+m7WIG0cp5QLN4yOi3YlVPvVGrLbbEOoOliLRCTAo5Mi7M5fKCDo8bO2VFvryMRcedRna/OnHEyKhQL6frSVpROt77uuxNa+MAXV31zTmcp1zdxBWDPX9JgQAO7nCOzbEWxp16lrNdhztgQFVU2s762ZS0sm9IMjmBEb4DCBBNDX745wDWc/2HpfWypn7bw4m/Nz1BzsTGwWgJYtW4affvoJ58+fxzPPPINnnnkGWVlZ2L59Ox577LHOqGOvZNagQKxfNNwonpNCLsNjZiaat6uYdQQ0MU6BDYuGm4wMbsmTuql5act8NawTAMT7knj3jjj4m4le/M+lckSsSsaGQ3kWt8LcJEK4SthbFUFyGdYvGo4Yhjfk2mYVFieE0WEKDHGAZ3kjFHIp66inLScevFzFRnWl5oAtY6DQ9YU9x01XJcWanXNUPU0dPU6MU3DOZUO45ok9UOUFGpQXZGMfUA5ABAICswYF4uEYjU0axLgQT6xKikU8I8gwF24SodEY+xrcF64Sx27f2toX5kiMUyDc13hLhSqjtlmFx3VHyf3cpZxpnpkRYzL/DYuGY8Oi4VZpgu2ZQ3Q8RI53I1Nzl6r3yHBj7YohnjLzWqJhoV54/+6huG9MX7jYuN1qag0Iksvw6b3xiPc1vdZQ93VHljzmPDK3TkhFAshdxCavdVbs0u/Nnz8f8+fPd3RdbjoS4xSYERuEyBeTAQB9vGU49OwtEAoIfHf8Glp0sX1uHxqMEG8XjIv04/SEmhinwIKRldiaVoiRfb3Qx8eVTj8q3AenrtXQ3jkXbkyjr/tx6ViIhQTu2nAccpkIT02Lho+7Vp09Iswby38+g9/PlZqs/4zYADw0LsKkd9Y7hgXjrpF9kZFfhdyKJvi5ayOur/o1CwA7FMGEKD+8C8DXTYyXb41FQVUTrte0wE0qwvSBgWY9jX55iO1AcWhfL7w6ZxDScqtwPK8Sn+kcLEpFBM6vScTW4wXIr2oCSZJoVKqx62yJ2XF65daBOJpbiQOXKox+m6pQY/3jkyCT6h9ohp6gAzykePKWKKjaNfByleDTf3JQUNWMqTH+OJRTgViFJ9bfP8KoXb+fK8X1WiUWjArF3PhgpFwoxdbjhfBxFUMhl+FCqda79KcLhyFpsKJDb1mrkmLRP9ATy/93FgAQLJeipE5rXDkuQI1vnpjBaqMh1FwesuZPNLWpMTrcC54yMf6+VAEXsRD/XTgUtwwIdNibYGKcAtMGBCL65b0AgLVzY7FobLhN+TPj4wFaof25+yfhdHED1u7JwqWyRlZ6N6kQTYxwKVTMJ4XcBWd10boN+WrRCEyL1Wooqbnr4ypBVkkd3k3Rx07MfGUmTuRVY8fpYjS3qVHeoMSZIu48AcBdIkBjmwah3jLMG9oHYyJ8IBAQZj34dgQ/dykreOujkyLwfOJACAUEJq87QH//w9IxqGxsM5rLtc16B4cJkb44zvByTz0gI/zc8cCmdNqoN8hDgrKGNoT7uuC2ISF2e4Iuq9ca4P6YUUgHjGVCzd3nfjmLHZnXMX1gAL58YCSEAgJni2oxpI8ctc0qFOoMi0eGeWN2XBBOFlRj74UbeHBcOPLKG5GcVcZZ/sQYf1Q3tbHiDM4YGIAguQztGhInC6qRU67VTr135xAUVjeB8p6+elcWrlZofxsU7IlHJ/Wj+1WjbkfyNa4S9axKisWKmQPw6T85+PSfqwCAMB8XvDY3DlfKG1FU04xQbxcMCPKkPUFXN7ehuqkV4X5umBDlz+pvw3UCADYtHokp/QNQ0dCKsW9rzWNenzcI940Jc1rND4XVAlBNTQ22bduGxYsXGzkXqqurw3fffcf5G495mBMkKsCD/iwRCWkB6ON7Lfu4EemCfo2J9MWzs9jalIRIX65LkBDpi2O5lQAAT1cxHpnIVvdSEcyZLBzdFz9maG/kmbFBGB9lPvK0UEAgIdIPCZHadAWV2pvZQypixAIT0JoZgUCAxDgFHt16EkdyKvHeXUMwMcYfgDae0rWqJgxQaMNCUBgKHAS023Djo/0wPtqPFoAIXcBJZjs/2nfFbP0B4EZDKzLyuI9x+rsYx+sx1ACVN7TireSLuPT6bADA7+dKUFDVDDeZCBpSe0SYa4yo4I/peVV4fHIkhIT2c3WzCtUMj6vxfbwcstAIGb6LXCQiAK0m28h5vYDA3SNDseVYAeJDvZGhC4Hy6cJhmK4TAhwJM/5dXIjtfUCNk+GWXkKkr679WgI8pChvaIWLmC0A0bHAzChvEqL0D2xqjMvrlXjgmww6zUCFJ2RiISb298fE/tq5/vJv53GmqA7BchkenxKJ9Lxq/HFe/zIid5Wisa0F/YPkWDmrv03ttgdmH/l7SHH3iFD6O+ZvYqGAcy4z03hIuR87JEjWiSaFtyvKGtrQz9+jQ20sqW2xmEYoIBDuq13v/D1kdH3jQ72w+8kJyLpeh9s+PQoAuH1YCBaNDaOF3qM5lWZPsgoI40j2g/t40fG49pwtwcYjeZgU7Y97RrHtaIWMyeXlKqYDsQIAR+QUTiQiAR4eH0ELQHJXCSYPCMBkRtBXCpIk8equCxAKCNzFGGMmhMF8HxfppwtJpFexxQY7NhRLZ2G13vWzzz7D4cOHOQUcuVyOI0eO4NNPP3Vo5W4W+uu2cJYyHsxMR3oHLpcbXWOIUhdF+vMDuUZx2phQNgvU5LxvYzoAoKjaeJHgCs64imEr8ewv53DlRoNRGorjeVV4/8/L+Dtb70KeVkeTpD4WGCNWUEVDKwa+moIjOVrBjLlw7M0qxQu/nscf59gaG0OBw5ZtLqkVJ8e+OpzHGcYAMA76COgFMplYgDdu10ZfpqKCM/+mxszUQkE94AuqmlHR0GoyKGe7g3wgMbPPrWgyndAM1FYsM16gOQGhIwgFBHzctFopS9sQXOhPBxn/1s7w4yQWCiAUEEZxr6gYd7cODjZbR3PfuUmE+P5fY0xeHx3ogfvHhGGwwTbbdd1Dvam1a/zUMOv86MR+rCC8IgMBkgtm3zG3SiSMCO+Gp7Rkuvvkn0vluFFv/zFqa5cDOsArxxY2s27UuugqEbJe5EzmSxBG/cL8PCc+GLufnMAp5E2I1r9gGvaPLTDXOcNciqqb8cbv2fj8wFVoSGBr2jVsOVZgFBuRgnlvhHi5gNRZiDGD3PaUABNWL007duzA448/bvL3xx57DL/88otDKnWzQT3AmDcFcy/dmsk0m7HPSpi5UebGa98gDI9OyjgEAeZDm8IwmGi6GQdXJwpq8NmBqzh4pRyrd2Xh5d/OY49OeGluU+s1QEICgZ4yLOQwlFyz+wKqdEEKj+nc2W80CHthTYR2U3C10Ra4SqbaFegpw/C+3rpy9P376pxYHFw5BXPitQ9OUy9KSobQ1a7RmFxoHeVllTRxCsoWu3K9vYU+irq5+dhRqL6zpwtMHY8GwFr8U1+4BblvJWFQMPvlj9JC3jpEgSk6zQ2TEWHenAIBUxhoalPjWG6l0UNX1a79fOhKBVrb1Xh8ciTG9jM+STN3qGnhy5Ew22H40sDUUghMTGbm9S/fFovkpyYCAOQM2yjDS5lrUkcc6Vk7/wQc0eAp2O3Xrhnv3DkE59fOwoJR5k8/c2mADD8rVWq0tWuM1vpXbovFh/fE29QOLpiCpiE36pX4+mg+/neyiPUylWZC602tN9MHBiD1hVvgqtOWertKjNI4O1YLQLm5uYiOjjb5e3R0NHJzTQez5DGNfitIP8EHBevf+IRWvEKH6vw+mFIvU/Tzd8OOZQn44n5tAMJROiO/j+4ZapSWy7C6qIbtYIsryjEFbWRKENiadg3b0gqx7k+t3YNUJGBpgHzcJLh/jLEAVK9sR50uqKmpt8CFo0Pxw1L9W7QtCwVTMIlnbKutMGO0yYRLNpWKBIgOcEeYrxta27VCDPOhEezlgnA/N3rhMPXQaFbpBSBzJ8s6IgAyCfFyReKgIKPvVRrr+3PjkTwAQHp+Fai1dMnmEw5xdskFwRC4bGXlzP5YO3cQp/Ets0+vlmttgUYYGMTePkwvfDw9zXht/OahUZwCttAgTMqTP5w2SsOcwqPe+Bsf7buCN+cb26+MssJI1xEw7/NXd11gRW1n/mZqOWCmUWtIBHhK8cLsAXhyahT9veF968I49GBunXEUVBFqxk197Golxr/zD5ZtO0V/Z6gZb7XwhkAQhNE9bigYj3lrP2Je3ou8SmPNa1SAO5ZOjMDsOON701pEZgQgqi7tujA+FBdKuG3Q2hmmC0x83CSIDnAH4Nwe0plYLQAJhUKUlJg2Fi0pKYGgs3TdvRzKuHDVr+fp7ybF6FWf1tz8XA9aLi7faEBLmwb9/LQTlTn5DeHaApv7WSrrsznllIYhAFFvV+46AW3rI2Og1j0hqfZRbTDOR5uRqaIUcheMDNO/HbtLrdfqUG0UCggMYKj1owM98Fxif8QqzNu0cS19cSFy7Fs+GW/Mi6ODtHJq0zSmNRAAu2/bNSSnap6ZT0cZHeGDDQ+MMDrJY4sGiKrLtapm1pt0Wye4J1Cq1KjQ2Yw0t9m+FXT3yFAsHhcOX3fjk18PjA2j/6a82P7flCjcObwP/T3V1tK6FoiFAvz+7wn4celY+ndT48V1Pxs+IJlToqlNjS8P5+Jcca3RdY4Sfi0R5su2B2QaMbNsqEzMZYGAwLq7huCjBfFwlQiRnlcNpUqNYX299GlMbIEZlmErlFDPpeVmQpfB6NLmNjWu17awBD5jAch43XpzfhxCvLRG8oQFDVBaXhX9kse1FgwOkePFpIGcGnJ7cDfYLqYEGbWGZM0nU3Nr1qAg7Fg2DitnGb8kxgR5YEgfudGJXWfFaoll2LBh+O2330z+vnPnTgwbZtlYl8c01U36kxLzhoYg0l+76Fhz82deqwUAVDa2mU238uezWLQpHZd1tjvMyW+I4Y1C8fjkSPpvU3YpgH7rjiD0C3qbWr/dF+gpw9T+/ogLkUOpUuNoThVnPlTVzAlbzC6itp0oqCPIU2KMjf4odfaYCB/0ZRz1Tc+vwvxhIbh/rHbRiQpwx3qd1oyJ3PTBKFwsq6cNV5mL5uErFXgv5RL+vqi1jTL10Fg0Vr/gqdUkxkX54qFx4RgQpBfUxvbzQaS/u+lK2EEbY0GP9HfDnDD7hBfmeJkSbjsCc+45WuXOnAtP/nAaS787ifJ6JZ6d1Z8+ylyrM0Rf9+dl3PbpURzLrWQJYqbuDXse5kqVBv/Zrj15Mz5Kb2RMaac6mzVzB7HmHbNtzIe52Iym4e6RoZg/rA9e+z0bT/yQiY//zmGdnjPaAmNqgDoQXDhA59ogKsD8ffLIhAgUvHMrPlwwlP6OamewTpgB9C8z29Ku4YFN6dh23Pgo1ogwbxx8dgouvZ6IpRP7GdsAMfqJKSgbrgV3bziGiFXJ+IthR2kvL8zW2m9SpxfpMpkaILXle8rfQ4oRYd547pdzmPvZUfq5Vdvchn9NiMDHC4aytOnOjNWWg08++STuvfde9OnTB8uWLYNQqJ0EarUaX3zxBT766CM+GKqdjInwQXp+NctXSH5lE22Iao0G6Pdz5o9yU5TUaY0nd56+jtERPjh6VWts/MquLNw+LISV9rYhwZgQ5YcTBTUoqGzCh/uuoEWlxgbGsXNzAhBTA6RVb5NoZwhAU/oHYEp/rVBSVN2Mj/7mPpFF3YimbKFSr1Yiu6QeIV4uGBnubaTuPfPqTJN1pASTY7lVLI+qm1MLsDm1AEGe2u2RgQpPzB7M9mfxQmIMFHXckbIBtrEhczsxLa8KXxzMxaBgT0yM9mP5MWJy5/A++Fx3gk1Nkpg3NATzhobg7b0XcalMK8Dm3GhkbRV0BI2GxKnCGtQr9Q/x3IomCKLMXGQGplajVeV4DRBzOvSxw/V/Rn41NCSJoaFeMOxBZn2rm9qwL/sGXrk1Fn19XdGi25p8Z+8lLB4XTr+1r/vzMivw5sT3DiD7tUSjcq25nx8aF4EfM4o4f7vBCID8a+Z13Daka+yAmDCD/a6eMwiNre2ICXSHt5uZNwIdeRV6oe1iaT39t1goQD9/NxRVN+OnR8fCy1WCH3RHx60xAzAFcyveHFxb59Qa5i4V4dCzU9DY2k5rw/Irm+jDGob8c6kcA4I8Qbn9IQBsWDQC2SV1GKDwRBzDxIFloGyiikXVzahqbOXUVlqL3EWMmEB3BBts+VLCpaEGyJLW9mxxHdQakraXO1FQg6XfncSwvl7Y+X/j7a5nV2K1AHTnnXfiueeew1NPPYWXXnoJ/fppTyzl5eWhsbERzz77LO66665Oq2hv5l8T+yE9vxoeMr0A1KDUH3O25o2x3cro40rdwm7oE6NByb2F4OUqwQzdEeajVytx6ArbF465N2/mKRuC/k77/+2fp+Lqm7NpYcWUHQyzDFMlpWSVYWvaNTw1LRrLrbTdoRgT4QNXiRDNbWocuGzs54fyIcI8+dHcZv701rHcSqzedQFljEjTMxjHwKk3yPhQL7zFYddBwexb5t9zhgRDoyGx8Ui+2X6zlf+dKsLzO85bTmiGPt4uKK5pwbIpkfi/KVFY8OVxpOdXW7STsAem8O1rxYPXkIe3nEBjazsOrpyCEANVHtdW8tPbT+N0Ya3R99QQqNQky0DfVJsJgsBTt0ThpxNFnIEsAcDPjANRptanIyeDbOWjBUMx+5MjANhG4oYn1Exx+EoFlCo16lv0a80P6YX0PRDs5YJ/VkxhXTMgyAOXyho6ZAPk6SLC3Phg2j7FFkiGobzhNiBVp7gQT8yMDcKWYwW0NuTY1SqMCvfBqHDt1rxIKEBiXBASOex4pGa2+qjxfeOPi0jLq8bXi0fa3AaKBSNDMX9YiFFf0hogNfugRZuJU2CnC2tw6loNnZb6nzbDMOGU1xmx6ezom2++iXnz5uH777/H1atXQZIkJk+ejPvuuw+jR4/urDr2esS6CVher8SXh67iYmkD/rmkV3nmVjRiiAVfL22MCOzHc6uscoSm1pCQigRobdfAz10CtYZkXdPWrsHW4wU4ea0aueWNuFJubKCXV9FkdJ1aQ+JyLYGMBu0pgpLaFs6jqDsyi9GobIePuxQigwSTY/xwrrgONc0q+g3ukQkRWPfnZXoLQq0hkZZbhVOF2uPI/92fgx8zrmHlzP60Dwu1hsSBy+UoqW1BH29XTI5hO/bykIlpgeZaVSP83SWoMNhGHNLHExIhgff2XqLTLhwdiikxfshON25XbZMKOYyHVD8/V4R4udDjItY1NrOgBu//edmkgzfmg85dKsSPGdcgd5FgUrQ/5g0NwcYj+ahoaEVRdTNtBM+FWkNyOpA0xJQyb91ZAS6KczAxJoCzntQ4HM+rhFq3aIb7uEKtIektofPXa+EpEyE9vwrtGhKNynYQBIFwX1c8kBBu0pM5M2/KORxVB2Z1k8+VQuHlYrJtVB+U1WntOaqb29CsO0J+urAGQYPY26OHOIRhwqCDhALtPVJhQogxtbWp1pCQiAiW8JN6tZLVt9bu6NW1tBndf45GrSHx9E+ncYjhjuNyWT394DM1PoZ5LNt2Ck1tariascUxnKsqhsbYXnJuNGL32RIMCvbEyHAfk3PkSE4Fvk8rRHyoF5ZNiYRaQyJbp6HKr2zEv3/IhLtMhLnxIRgd4UOfmqxvViG/ohExAa5Iy9euHUevVuLo1UpMiPLDIxMiMCnGH8dyKmlHl6PCfbB4nHbeMwWSM0W1CPSU0WsX88WUsCNWHYVaQ2Lyun9QXKPEy0kDsWRCBN0HVPlqDQk/dwkWjg7FjxlFuHqjkV6zAND3z64z13Hwil7zRb2ItOjWxrS8anx1OBcPjYtgOeF1tHNOR0CQPeXAfhdSX18PuVyOuro6hzt2VKlUSE5ORlJSEsRiMVKySvHsL+dMamAoFHIZVs+J5XQrnpJVihX/O2vgpZY7ffgLf7DSlDK0FMxr3k7OxsYj+VYtxMzrUrJK8cKOc6htcZx/kucTB2DZlEgczanE4s0ZiFV44ompkXjh1/O0HQZXnebGK7D7bKnJNqZklWLN7mxay2MLIgEBmViIGYpWvPfIbIjFWu1dis5Xkal6ebmK0dyqNnq78nIV4507BrPGa+ArKfR2CxNPmQj/NzUK7+y9BADY+shoTIw2PoZN1WftnmyTfcDkpZ3nWd5qTdWfWU9T7ZWKBHCRCE32AxMBofVPtSqJHRPOVN5UHZpa1VjB8Ehrqm1cfWDULhcx7ghVYtUDs7H/ciWe/umMVVorgjBvm1bwzq1WtYnZrsQ4BQ5cLseSzScslg+YXxsMMVx/LGGuvpSha7OBjyyuOWKu/6k+4konEQoQGeCGLUtGI9DTuqDJzDbuv1yJ53ecp42MAdP99WNGIVb9eh7TBwbirhEhZu9jpibYEi5iAdSk8ZYSQWiPkp8prEMFw8ja1NolFQnwyb1D6XpbO5aW1oC2dg0Kq5sgEghwqawez/1yjrUNTplmmOqL1+fFwd9Dgud+OY96xs6FgGAL8rbMUwpb5ytg2/ObF4A46CoBaP/lSizTxdCxBgIwiq2SklXKmQclZxumZwpAXPkDwPTYAOzLtux80fDaRydF4MvD+RbT2gMz/k9KVike35ZpVz5UGx+dFIGvDud34J1Ky3BfNbY/M5sWZm0ZTy6Y7Zy87gCuVTVbuALYvGQUpvY3NvC2ZW7Y2qcbFmkNwu0dBy4em6QXguwdY8O22TYmJP41PhxfpxobtdqLPfN2w6LhSD5fit1nTYehYWLqXufClgdKR+4zQD9HLPV/wTu3WizLlvhfVBuFYSPw75/OWr02/nyiCM/tOIe4EE9kXa+HM8J8BlgzlrauAR1dvyzV3bBMS3S2ANRzNut6GWoNibV7sm2ebGv3ZLP2Xk3lQXKktwSp+2er8ENd+1UnCT+Ath2pOZXYmVmMl3dm2Z0P1caNRzou/ABAdq0Aap3/DHvG0xBqvNQaEqW11mmmuOy/bJkbVFpbWLP7AlbvumDTNZbYeCQfbe1aO4Q1u+3Lm9m2tnaNzWOyyYHCD1UPqo+tbdOa3RfwD0fcOVPYc69boiNjQLFm9wWs2W25/6lxMoetbdOQwBvJl2xaG6kdy8tlpr3bOwPW9oU9a0BnakM6Y552FLuCofJ0nJPXasyq5LkgAZTWKZGRX42ESF9k5FebzcMwPQDE95GbDNzYUTpzSpfWKbHur0tmA0TagqPuP6WawMlrNRAKRTaPJxfUeAGmjRANUXOEwrBlblDl2kJZPbfdS0fQkMDW4wWIDZZ3KH+qbVuPF9jYro5YWXDD7GNr22RP27nu9Y6QkV/d4TG29nprxsnWtuXWE2bL5+ovyj5FZeWBku6AWe+Rfc1rN6xdA45ercCu09cdsn4xGYYrGCLIRRRxHeEohT/qIIUKaARaP5DCVeYGuHgBbgFA4CAgahrQt2ttiXkBqJswdfrDumuVrP+tTQ9onfR1lgDU2VizHdQdlDe0Qih0nM2TteNKweWwzJ654Qxcq26Gn4f9R30N83IGurKPHVVWV9bZ2nGypU71lk3PjPJ0NgNdc2jrbV4Asra/SuuU+PW0dW5UrGUYruBX6RrTcRmbdP8oLu8BDr8DPLyvS4Ugu7bA2tvb8ffff+PLL79EQ4NWXVhSUoLGxq5xytUbMIzFZdu1Mtb/1qYHgAkWorc7M0wjb2ciwENq9VhYl5/Mpvy41Mm2zA1H1r2jhPm4Oqw+YXb4BuoMurKPHVVOV84Ja8fJljp5WmcuwsqzM2PWORpr+sLa/gqy0rjcFkIF5TYFpaapLXB0VcxiswB07do1DB48GPPmzcMTTzyBigrtXvW7776LlStXOryCvZWRYd6cMYjMQUBrSU8dSxwd4QOFXGYy2rFhegAI93ODr5vE6gjJttavs1DIZSAIx6mmHfWyJxWSGBnmbXEsrIUaL+aYWYLLBsiWuUGltYUgTykCHaSpoRAQwAMJ4Rgd4YMgT/vzptr2QEK4je0iHT6HmX1sbZuCPKU2hxLgutc7QkfHANC2I8jT/D3h6yahx8lcugAPqU1ti/QkEeQptWltpNwWWIiY0a3YMs72PB9uNmwe6qeffhojR45ETU0NXFz0LrXnz5+P/fv3O7RyvRmhgMDqObE2L7ir58TSqloqD8BY+CA40gPAq7uyUNXUBtLENQSAGbHGJ4osQZ0C6yy07ez444lq49KJEQ552A3z0UAoIMyOhS1Q4yUUEBge5mUx/YzYQEzmiETOrI8hhnPDnrm4Zu4grJ03yIYrLLN0YgQkIgGEAgJr5tqXN7NtEpHA5nY9Mj7MciIbYPaxtW1aM3cQxtjwUDJ1r3eEjowBxZq5g7Bmrvl7YmS4Nz1O5nhqWrRNbRMQwMtJAzjLNtVfswYF4uJrifhwwTCry+lKbB1na58PXHEKO4o3esZukM0C0JEjR/Dyyy9DImF7Kg0PD8f169cdVrGbgcQ4BT65d6hVb3sKuYzz+GBinALrFw1HkMGbbpCJ9NQJh8kx/iav2fjgKDw2KcJqLQlVt1VJsdiwaLjDPYE+MTUSiXEKloHqhkXDzXqHVchleGxShJEGIIhR1/WLhtus+WDVa3IEFkbpa2VqLJh4uYo5gzJ6u4qNjvo+OjHSKB2g9QNEUVanNApealgff4PfueYGldZSfzDrmRinoI86c2Ht40pAsI/AU/XZsGg4KzyMYR3enB9n9Jth2+gxsaDm93IV4+EYDZ5P7G+yXC7MqfkVnjKjPjaXN7NvH53EPfaAsfbS1L3eUSzV100i5Fy7DOeIuXuCih2WGKfAx/cONbnmTBto+0vZrEGBNq2NIqHWd9Wc+GBsWDTc7Lpsi4bOy1XM6eiTILQvm4b3nKm1K9DT9nG25vnA7PNHJhi/xHq5is3eD8/N6s/qr2BU4iXx91bXsTux2Qhao9FArTa2xSguLoaHB3dMI1McPnwY69atw6lTp1BaWoqdO3fi9ttvp383tSf73nvv4dlnn+X8bc2aNVi7di3ru/79++PSpUs21a2rmDs0BJP7ByB+7V8AgJWzonEyvwY36pXo4+2KGYOCEOrtataLZmKcAjNig6zy9ks5uDqWW4lLr882ec2qpFismDkAW48XIL+qCSRJwkMqxqajeVBpgEg/V+RWNuO2IQp8cu8w+rrEOAX+NaEGnx/UH4lfPC4MyedKjTwsA8CLSQPg7yFDgLsUGpJEclYJfswoZqUZGuqt/YMhASXGKTB94HWkXNB7zJ4br8DUAYEI8tS35bnEgSbbSPXbr5nFePaXc3Q+ccGeyCrR+gEZGeYNHzcJRoR5I1bhiQe+yaDTjY7wQe1l47HIr2zCLyeL4eUmxildkNqHx4djRmwQRkf4ILeiETM/Okxf88X9wzFrUBCn91xDtj48Gl6uEnz89xXsv1RuMRRGYpwCkf7umKEr74N74nH70BDOuVFSq0RlQysmRfth/rAQVDa2oqKhBZkX8zEyNpLTE3RinAIEjE8Arp0biwWj+uKFHefw25kSTBvgj3PFtaho1Fqn3j86FAKBwKwnaGp8Il9MBgBIhAQ2LxlN16FIZzwrFhJ4/+54k/M+MU6B0RG+GP76PqMyZsUG4MFxERgR6ok/U/ayyr1r/TGcLqql0z6YEIYf0wsxvK8XRkX4IiHSF6PCffBuykVsOlpglLeQI4AnlXdabhVScytQUqtEiLcLxkX6sfqWCoXh5SLC+kUj8X36Nfx+TusXSEMCW5aMQl2LqtM97FqqL2DZEzSVx/YThbhe20LHtwOA38+V4rP7tH/PGxqC24YEs+7X+zamgYT9Bsq2rI1c1z39YyZ+P1+G+D6euG1ICPw8pPT6otaQmPTuPyhraIWHVIhWlRptGuBfE8PRrtaul2P6+SAhUmt3acoTtClP7c8lDsSKn8/gtzNaA+Vxkb52CbmW+oAgCIgEBNo1JCvgbbBchg/uGUpvkVH3oSFj+vlgRJgPDl2pwI8ZRbg1SgJJsXPaaxpiswA0c+ZMfPzxx/jqq68AaDuvsbERq1evRlJSkk15NTU1IT4+Hg8//DDuuOMOo99LS9mOwPbu3YtHHnkEd955p9l8Bw0ahL///pv+LBI592E3psbkoXH9UF5/CQevVOJiWSMWjulr1dFPoYCw6fgrQRAWr5GIBHhkYj/WdxsO5wEAciu1D58gndt21nVC9ttRTKAH/hRwRzNeNDYMrhL9+MQEeaC4Rgm5ixgltS3ILKylXa0/O6s/3ky+SKcVG6hupw0MxLyh7ICultqo3WryZn03tK8XLQA9ND4ctw0JhlKlxrFcvfv3F2YPQFSAO04aCEAAUFzTgtzKJoyTa8vt5++GV+fotxMM3x7jQ7nDnJTqAtcyiQxwR4CHFAtGhWL/pXKcLapF1vU6xIWYjsfEfJEYGORpcvFXa0ioNCR83CSYP7wP8iub8Mm+y6hXATMGBmBEhAkDeg4JKD7UGzKxkI7AHeApg7+HCyoaVVgyPhwSoQCjwn0wnREjjQuhgECEnxvyK5vg7SbBeA4jfpWaxBcHcrFyVn+TbTMVluKukX0xPsoPKhX72JBQQNBRxJnNVGlInL1eh0/vG44AOlAud9+brIuAwPhoP4yPNn0ggZJ9hQIBEiJ9cbqohhaAAG1E7ikczi87A0v1tdQWKo+dp6/jREGNxXTU/arRkPS0EnUgGKq1a+PF0npsPJyHPt4uWD6zPzILa/D7+TIAwMToACydxF4LhQICCm8XlDW04sMFw/Dhviu4WFqP8ZH+WLJF68U7r0oBD5kY8aFemNjfHxNNbFdz1U8oINDP35312V6sWQfbNdrAwK/eFovXfs+Gu0xkVb9Rc5VyqXwstwpwrHlgp2HzrPrggw+QmpqK2NhYKJVK3HffffT217vvvmtTXrNnz8Ybb7yB+fPnc/4eFBTE+rdr1y5MnTqVDsRqCpFIxLrOz895Tz61tWuQy4iO/Mbv2fjuuN4ZW2edTHDEC+NLSQMxbaDxA0zEePP9celYzBgYaHKrIG71n9h/US8cBXrKsPWRMfjsvuF0IECN7g6bOkC74MtdtOpYmYHWwN7AkIZbaYcZcW6o3+qVKjy85ST9fU1zGxZ8lY6UIuMyqRAKMioUtIFwwNxznxkbiBAvF3Dxxh8Xjb4b984/2H+pnOXHKC2vivN6Cqazd64gn3Q6XUWpOVfR0IrfzpbiSp0Ad36ZjpJaY4EMAO4d1dfoO0rgoDRU7WqSFmRPF9biy8N5+Nd3J3HgkmWnm1SwTGawYIAdDPXyjQbUNBtrGLnSMjG3XWsUmFL3WanSoMQgRAEX1jqy5KJSFxrB10RQ1I4IBN2FNQ/wumYVvjtegJ9PFqGysRVxIZ4YHe5js1G4PdyoV+LX09exXzcn6xihH0yNsYie3xpsWDQce5+eiDH99PZbf5wr7ZA7BqZmtDMPqe1YNg5/PDUBYb5uGKjQHq831ECH+nCvU1Q6Lncczo7NqpE+ffrg7Nmz+Omnn3Du3Dk0NjbikUcewf33388yinY0N27cwB9//IFvv/3WYtqcnBwEBwdDJpMhISEBb7/9Nvr2NV6kKVpbW9HaqvfLU1+vfftXqVRGb4YdhcqP+r+ouhm3/vco/fuOTPb2D6lRO7wOgFZY6Ei+EpEADyWEAoBRPiLGaa3BCjdIxUJsWTwCFY2tuFreiDW/67cjNSSgUrWz8iBJEi0qNV6bOxAgtfvVKpUKoXIJLqyeDgGhLbOPF3tf296+IjVsdW1VE8NHk0YDlUoFAcl2Nrjvwg0U1yrRT2bcjy26AKBSnSDYolKjtbWNfoAKoS/vr+wbePuPbKycGW1Ur/GRvkjNrcLt8QrsvXCDFqxKa5tZ3mrb2tvNtrtN95uvmwR9vaQm07ZTW9ukts0aNdu30fXqRvi7GS8Z84YE4scMdgyxv7NL8e2xfPySeR2h3i4I8ZIhUxe0limQ1TQpLY6ZRtOu+1/DSqtSset34XotVPHG0bYBfR8AwIrpUfjg76sAACGhYd3nrLoYCk3Mz4y5JjJxOrFNrbH7HrterXWSEuQp1Y0Fe/7ZO9c529lFmNLCUXXRaEiMf/cAGlvbIRQQ2LJ4BLKu1yPK3w1CaKBSWecY1N42kjqHomrduL3F0DZ7yISc+VEyXerVCiz7PhMiAYGLa2ew4mCRavvXcNbcIkmD+e+4sewfoHNFQKoxINAVOx8fC5lYwMr7rmEh+Gj/VaNrqfVb1d6xbS8SQLtHH6CDbbQlrV17QyKRCIsWLbLnUrv59ttv4eHhwblVxmTMmDHYsmUL+vfvj9LSUqxduxYTJ05EVlaWSRult99+28huCAD++usvuLp2ji+Rffu09gjlLQA1DH4yElVK9vmskxkn0HDFkZK1tix1ezuSk7n3dM1xexiB364JEelu+vrSSgKBLgLEyEns3/cn6zdvRh0ozp4+hdZ8fRtb1cBzGdo0741uR47u5e9iLYF2jfaIq6sIuFREANC/GZ45fRpkoe19VdvKrhPZ3g5qDDIztXXTxj3Up8mr1D6gSOjHkqKwWABAgMryUgAClNYpsWpzCiYrqDcldl4XruQiuT3HqF5t9dp8fjOICfXzkQvIrtW/GWZfvITkemNtEcX1Jm15qrZWs2N+8bq2P69fv47k5CLkN7DrefjoMZRw7PYUNerT+UpJVLUS+C3jKkqbAYDAkvAG+DZfQk29EADBcsSZefoMhMWnTdaJJIELNdp61Tc2sepfwbh3ACAvvwDJyXmc+WhNj7RpL1y6DGrenEpPQyUjCgNzLBOkQI6nADn12r4uyM8HpTQ/lnoU19y06S7WsuchE3vuMQA4V6HN80Z5BZKTk3HpOruMo4cP4XIH3jcN52xXUF2lnc+GUH1EkkBjq2590pBIT08HIERDY6Nd/WhrGy/Xafu4rr4BycnJaG3WzlcA8K48j+Tk80bX1FRr27QtvUhXbw2Sk5NBQH/tmTOngSL71vCcG/pxLyoqQnLyNaM0jhzLkmbgXBUBXxkwyp/EFWZdrnPP8+Np6ai+RKKomHt8TdEg9oNS5IU2sRz1LqGo8ByMmnMVwDnjsbaljc3N1mvcrBKAdu/ebXWGc+fOtTqtLXzzzTe4//77IZOZP80xe/Zs+u8hQ4ZgzJgxCAsLw88//4xHHnmE85pVq1Zh+fLl9Of6+nqEhoZi5syZnRIMdd++fZgxYwbEYjFyyhuBM8fg7SrG8VVTMeadA6hu0kuwCWPHYCxDpdpR1l08jOJaJYaG+SApaZTN19efKMZv17IhcvOCYvAA+LhJjByZzVCpMGzfPqhD4lHR3I4pMf4I89Wnef38QVQyDKInjBuD0eHaNmo0JPqv1k/2pNmJtPr5vQ8O43qtEjseG4MhfeRQnytFy9lSHNRtWY0cMcKuI/yVja1YnXmI/iyTSdCsG4OxY0ZhYpQfNBoSz2YY34QkCXosKXZUngJqqjBtxACcSNEuIUPiBiFpTF/dNSRWpOvzUrn6co7F4Z1ZOFFh7KE1OCgQ2bX6WFGRUTFImmr61FBuRRN+KTkNb1cJkpJMe1ktOpyPPYU56NOnD5KS4nC6qBYfZ+mNvoeNHI2JHLYef5wvA85rjcirWrWLvq+PN2601gMaDW65ZSpCvFzwVtYhoJXtAX3IkHgkDQs2Waem1nY888Y/AAChWIakpMms3/fVnUB6vlazFBYWhqSkgZz5VDW24qWT2jGOjo5GSrFWUJo6eSIGBHkY3ZcUr7zyF/13ZGQ/HCgtAABMmTwJ0Tr7pgEVTdhwMZWzXFvtIilaMq8DVy9AJfZAUtJ4lKUW4PdC/eNo2i1T0cfbdgnIVDu7gl3Vp3GRMW8BINBTiqSkmfTnZ9K0/U0QwKjRo4HsU7jRQmD27NlWmwPY20bf/Gp8kX0Sru7uSEoaj02FabjerN0NMDWORN8yPLVdf4CCBIFh42+B5ORRtOg0ViOGD8esQeZt3UzheqUC2/O0LwhhYX2RxDgp6cix3JpWiAZlO2RyAfaevYJx/XywOmkkK82BX84DheyXMZlYgNFjRmB8pC/21p8FqrhtPbmQPbAdMkU8ACAAQBRHGnvaSO3gWINVAhDzZJY5CILgPCHWUY4cOYLLly9j+/btNl/r5eWFmJgYXL1qrLqjkEqlkEqNrbbEYnGnLRJU3oRAK1ELBQKIxWIjrbtELHJoHW6ND8aXh/IwpI+XffnqFqHz1+txz1cZWDg6FG/fMYQz6Q8nruPktVqEeLshNa8G2SX1GNxHzhJ+AMBNJjVZly+PFCAxLgiDgvXXvbDzAvYtn4xb40PwPePEmL19JZOwO31sP18k64wfPVz0dZMIBUbxuUgYz5M2nWPCEG83zIwNxF/ZNyAxSPN/UyLxxUHtaZjqJhVnvXPKm4y+AwCJmP0WRhICs+0eEOyF6EAPHMutwt+XKjF7MPdJEkJnVyISavMTGxweaCcJznLW/WWsvdKQ+i0Aqu2cJ9YE5utOMHa5nkscYJRWyLSFIbjrBwACkX5d+vSAVvjxkIng7sKee6bu+duGKCBiGPfLJPp0/YO9oJDLjGIpyV3sXz+uVmjfYvMqmyAWizErLhjfHi+kbY9k0o6tTZ25tpksU/ci8+b8OLhLRXj6pzOICnDnrAcBoKVdf1+KRCbmj7nybGwjNd9JUnuthGGrZyqfucNC8dofl2mbLQCoVap1Nloa3bX2r+EzBgXj6WmN+GR/Dn1fGtXbAWP51ZEClNUrsWR8OADgWF41fjhxHYvHhdNpknUnbt2lIjS2tuPjBUNx+zD9oZNZcUGsU7mWEItEgJX1tqWNtvSFVfoqjUZj1b/OEH4AYNOmTRgxYgTi4+NtvraxsRG5ublQKBzrI8NRUAZklDGdoR2ZrTe9Je4a3gdfPjACd47oY9f1m48VsD6biur79hkhTuqOgAsFBLYcK8D2k0V4+TfjSO7mDFE//ecqsnUnsigbmJxyrdG4SCDAqWvat//37hyCIaGmT0KZQ+4iRuYrM+jPY/v5ouCdW1Hwzq0YFa7XvnEFJ+WyrXWXiuDlKoarRGg0vhTPJQ6g/zZlPHjORMw2oYEBLFcwVENaVBo0KNvR3Gb6Hu3j7YJxkb70yS1Do3Kq/w0hOTqhsrGV/n7cO/9g+c9ncOyFW4zSaSwYTjLn13zGYkvBrKMJO2cAgKeBAbVEJMD5NbMQ4edm8prk8/q33ZdvjWUZgRoaIX/5wAhMN/BV8/GCoaYrZAFDZUe4nxv2Lddrv3pS3CoKqs/UGhKR/u54dFI/JJkQxgH2WujodZALqk/VuolE+SgCwDoBaojh/UeAYLlAsPdwBsVAhSfuGB6idwfSCVBtZ97j6w/mstJQa1hjK3fcw/nD+uDeUaGoIT3QLuA23tdnJgVcOx60t6N06/nwxsZGlmYmPz8fZ86cgY+PD220XF9fj//973/44IMPOPOYNm0a5s+fjyeffBIAsHLlSsyZMwdhYWEoKSnB6tWrIRQKsXDhws5vkB1QD7+yeiWSPjmCuhb99ldfH1f4ulmYSDbiKhWhr48rAu2M9ZNXwdZKcD2/dmReR1mL/qYXCQmzTvEsOU40dYJHKCAgFhJQqUlMjPGzO36RQEDAh9HPtkSD5kr59WLtdlZdswqPfHuSrqsp2kwIFqYQG+RlzekLqo9NCTGA1g8L042A4bpt6lqu7+tbVKy5UdPUBoIgQBAGtsQWqt6ue7gQhPFDsKi6GUev6h9M7lLTy5lMLISXqxi1upM91jjrPHRZv10jFBC4f0wYXtuTjdZ2DZjyj1pDItjLBc9Mj8HwMG+8l3JZ1zb7bfe4tnuYWgZzbXVW5g8LwbC+XhgR5g0CBEK9XRDmwy2AEgRh8uWqsxDQL6E6AYgxR1pMvDgUVDahppltdEsQwJNTo+hTnB2V3RLjgpAYx23c7yiok7utDENzw/lreJ9HMo7oU3i7SUB4hWLnyF0IkbbgzeSL8HGT4JMFQ1lrLFx9Aa9QB7bAPuy6i/bv34+PPvoIFy9qB3jgwIF45plnMH36dJvyOXnyJKZOnUp/puxwFi9ejC1btgAAfvrpJ5AkaVKAyc3NRWWlfhEsLi7GwoULUVVVBX9/f0yYMAFpaWnw9zf2v9BdaEggPb8aFY0qnC7S+8XILtXvXR5cOQXhZt5O7UGtIfHMT6dxoqAGD48Px0u32u46f84QBfacK4WXixi1LSqo1RqoNSTLGVpZPVtIIkCAJE0/eLNL6hHm6wahgHvRU6lJo++P5lRgc2o+Layk5VZhrgkHf5ZQa0jc8sEB+vPJ/EqU1bWgtlmFAUEeeCAhHEIBgbtGhOCXU3pv50IB4C4yzotyONak1L8pMV0DqDUkXtmlN6hsalVBrSGN6s50yAgAQkLrmNHXQ7+QTIjyg7+7FMdzq0w6eMsuqce+bK1q+ttj+TiRX4U7hvfBuCg/s/3VP8gDPz0yCvdu0vo0+f3cdSjkMpajO7WGRB3H8XMNSbIW0MrGVuw6c512GRTi5YKKxla4SPRagYz8apTVtaC6qQ1erhLUNutPzpEkkJ5XhZHhPvRcq2pil7tobBiO51YZOXuj8m5jnFJpULZjxocHsWZuHO3QzxxPfJ+J/8yIwZaHRkEDsLxvF9c0Y/K6gxASQF+GrVurGW2bJZh9dzy3CmIhgce+0wnThNaVgKHDQWdnemwg6lpUWPR1Gs5fpxyNan1gGc5dAtqj5RTm5rejGBwix6mXp0Ok0/z4uum1hrkVTZjS3/geff8vY0dg56/XYsn4CNw+LARt7Rr2g99GThZUY8nmDMgkQiwY2ZfT0WRHUWtItKq0c/VMUTX9vVKlhlqjXXu/Sc0zWoPfTM6GVCTAv2+JxshwH5TVKXHf6L54bFI//O9kEb49fR0XyAigEbh3TwtWz+3ndHOWILn012b44osv8PTTT+Ouu+5CQkICACAtLQ2//PILPvroIzzxxBOdUtGupL6+HnK5HHV1dQ43gv79TDFe/vUMatu4J4GbVIiXb43F3SP60DeiI0jJKsXaPdksOwWFXIbVc2Kt9i6aklWK/2w/ixaVfmEXCwmIhQKzWysykQBKC1oOL1cxFozsg+0ni+m3dAqJSABXidDoe0MCPKR4bd4gm7ylpmSV4oUd51HbYjpvQlcHLk2Hq4jEe3cNxW1D+3D2McVn9w3DbUOCteX9et6oLV6uYrxzx2C67ilZpfj3D6eh4hAIpSbqYmo8n/4pE7vOlBqld5MI8cE98Sb7S9s351DbwlZ5U3UFwNkWa3hzfhzuHxNGl2Oq35i4SgSQiLjngVQkgNxFjPIGvZZEIZdhbrwCu8+Wms3by1WMN+bGQn3tFJKSkmgbgvs2pmmdujEw7OOUrFK8uusCq1wmhiE+rMHUHOGqN3POWINKpUJycjKrnV2Fub6i+pVaXx5MCMMf50pZQq6165Uj2piSVYpnfzmHBsZLDFf5z/x0mvbUzNWejoQnSckqxcr/nTPacqLGfVp/P4e009xcc5UIza7tgDaG30u3xmLhV2k4bsEnma1z1p6xtOX5bbMA1KdPH7zwwgv0lhPF559/jrfeeqtXxAPrLAEoJasUy7Zl6hzOmZeCH50YgZmDgrTq4g7uIevLZUPlak18GVN5OBsErGsPoG3T49syO1iidiwfmxSBrw7nm+yfZ2fFINLf3WJ5VGwte+rFNZ5vJ2fjy8P5pi/SlZkYp8D6g7nYcCgXC0aFYnhfLwf0jXmotjrLvHo4Ro1VD8yGWCy2ODdsqbstQpA995lhDDlzdJcAZM29Rt27AHe/WrtedbSNtqyX936ZhrR80w99Q0NhW+pgqb8+uzfeSGh3dBnWsmHRcKzZnY2yeuucf1o7ZztbALJZxVBbW4vExESj72fOnIm6Om6jTR6tmnHtnmzK167F9F8dycddG47jEsPhXcfLZUN9t3ZPttn9dnN5OCOW2gNo27Rm9wUHlKYdy41HTAs/ALD1+DWs3mW5vDW7L+BVDkNxazAcz7Z2Db6yIPww07eo1KhrUaGptd1BfWOel3aex5rdzjOvfi0Q0Cr/tXuyzaZds/uC1XXfeCTfKjsve+8za+Z7d2JNf1KY61dr1yt7uVGvxIs7z2HFz2etKl+tIXG2uNZsns/+chY5N2xbw61dm95IvmTRhq6jZVjL6l1ZVgs/gPPMWZsFoLlz52Lnzp1G3+/atQu33XabQyrVG8nIr7ao4ueioycILJVLAiitUyIjv9pkGnvr3h1Y0x5A26ayeu5tC3uwdC+X1bfiholtEsN05RxBY62F2f6txwusepjS/aVTBlc0tDq0b0xR1aSyadHsbGrbCJy8VmPVfC+rb7W67hoS2Hq8wGI6e+8za+Z7d2Jtu0hY7ldr7297qGtR4Yf0IjSZ2fJhlp+RX80yB+BCpSZZxvTWYO3aVFbfitx6+54Pjl7/bjTYtmY5y5y12Qg6NjYWb775Jg4ePMiyAUpNTcWKFSvw3//+l0771FNPOa6mPZzyBvsW+o6aAVlbrrl09ta9O7FU557YJlsob1DaFIOovEFJC0tKC4t6b6a8oRVCIfcx345gzVh0ZE4683zujLp1Rp62vGzaUr45+8KO5l1vZxQMZ5gvzlAHmwWgTZs2wdvbG9nZ2cjO1qs1vby8sGnTJvozQRC8AMTA3iPaHbX/sbZcc+nsrXt3YqnOPbFNthDgITPy0G0p/RWdqt6lCwJPOisBHlIIhY4/Ym7NWHRkTjrzfO6MunVGnrYcTrKlfB832+xzbMnb004zLmeYL85QB5vv9Px8yzYFPMaMjvDh9BZrCVMBBG0tt6xOybkdQkAbbHR0hOlwG5bycCasaQ+gbVOQp9RhamCBzr+Nqf7xcRVDLBRY3AYL8pRCoyHt3gZjtn9EmDfe+OOixTFT6NIfydGq6oPkMof2jTkor7LOgJeExMgwb4jFYov3apCnFFqXD5bvZwEBPJAQbjGdvfeZwor53p1Yu/ZRLhIspbHm/rYH6ng2teJas15S7kDMERtsm4NWa9emIE8pIj25vcU7qgxrCfSQ2LQN5ixztkMbLCRJcnqB5TFGKCCwek6s7uayvs866jOBKhcwNr2mPq+eY94fkLk8nBFL7QG0bVozd5ADStOO5dKJEQBM98/DEyKwdp7l8tbMHYTXbo+zqyaG4ykRCfDopAiL11HpqVkpJAQO6hvLTOnv7zRz6o5wDYQCgjXfTbFm7iCsmRtrVd2XToyAxArHi/beZ9bM9+7Emv7kwt71yl6oLTCmzy5z5QsFBF66lTv2HBOxifxMYe3a9HLSALudLDpu/dP2y9p5cRgZ5mX1Nc4yZ+0SgL777jsMHjwYLi4ucHFxwZAhQ7B161ZH163XkRinwKf3xtuktuygAogud/2i4QiSs1WOQXKZ1UfGTeUhEhBwtbBl4iK2PM28XcV4bFIEvFw5Yt0ICXjKLCsrAz2lVrcH0LZpw6LhnGUyIWDac7CQ0B5HXZUUi/WLhiPQU2r0OwCMj/IzW563q5g+GkqlM9WvEhMLKtd4rkqKxWOTIjgfqG5SIes4arCXC4b19UIfbxckxinwugmBjarrhkXDrRoXc/Tzd8f6RcOhkJtXh4sEWlcDtpSnkMvw2KQIi47ovF3F+OzeeMT76l9MEuMUuF8XvJYLapzM1Z2A7X6ATN1nXOPHnDPOTmKcArcNMV1PhW7uUkiEgg6tV/ZAOd0kCALrFw03uue5yp/cn9vBLvMetceMwZq1wt4Aq9aUQWFpbVcw+uSXZeMxwoIQ5Gxz1ubV68MPP8Qrr7yCJ598EuPHjwcAHD16FI8//jgqKyvxn//8x+GV7E3MGhSI7LMafHFRCD93CeKCPelo5v383JBXyVZpukocY4+QGKfAjNgg2ksx01OuPXnszSrFd8evYXSEN7Y+MpblCbq8oRk/n9Q7B9v79CRMef8g/fn+MaHwkIpRVq9EiLcLxkX60R5Cn0scSOd18HIFskrq8fjkSMyMDcKcz47SeUT6uSGX0VdPTI3E8hn9bX6roNrErP+oMG9cKW9EUU0zwnxcaU/QablVSM2tQEmtErUtbTh4uRID5CS9EBn2sdxFjIc2a70oU3GQuMrj8u5KpTuWU4lfMotwvVaJ04U1UJPaOGKUm30AGN7XC8/OGmByPFclxWLFzAF49n9nsOtsKfzcJfjonqFGnqAfGBuGB8aG0Z8nxwQAYB+VfXZWDB6fHEVfF+HnhlkfH4FUSMDfQ4riWvPbHH5uElQynNuRJEm3ddoHB1FQxW0sHOnvhlVJsbh9WB+kXq3AG39cMlvOj0vH0v0xKToA929KZ/0+Y2AAYoI86LmnUbcj+Ro7D2ZYmk/uHQqSJPHM9rNwYzwUmGNeUtOMM8W1OHilAkXVLXh1biyWjLOsgTOE614dEeaNE/nVZueMs7NobBiiAtwh1Qk31U1t8HGXIsjTeC0SCggcff6WDq1XtkKZG2g02jmZ0K8QB69U4r7RoZgTH8JZfjljC+nHpWPpuuZVNuKlnVp3Fvae5LW0VqhUdlpAc5Rx94ZjyCysNfr99CszsOFwLj7al4NguQwkqUFpfRvuHB6Cu0aEGvVJ4iAFTuliQLpLBYgP8YKfhwx9fNjrvLNg89P1008/xfr16/Hggw/S382dOxeDBg3CmjVreAHICqj3zMrGNpwo0IfCYAo/59fMhIfMsY7KhALtDeSIPCobW/Hd8WvQkNrvnt5+GpWNbfjl8QTsOFXEukZqoAF6cz539Hgq//HRfhgf7Yd6ZTuySuq1bvENAg5OGRCA3KN6e7RwXSgNe9tElUkxeUCAUTpmmt1nS3C5rBHuYvYDm9nH+YzxNFzcDcszVa+J/f0xUfeW+cQPmWhVqeHpop8XC0f3xb2jQhEf6mUyn4z8aryVfJH2RxId4IGJMZZDwwTJZVh/31B8mZKJ620yTI8NxNT+gay2UHPZw0WCMf38UJxZbDZPF6kQaAJkYgHa2jWQ6SLbCwUEwnzdTApAl2804tS1anx3/Bp2cXjeNYQ5z0O8XYx+f+W2QaywFRqOg2/M3f15Q0PQ3NaOzQ8Za5P0Y+6LO0eG4onvM1FU3QJBBzb3uO5Va+aMMzO2ny+CPGV4K/ki/GqleGv+YJNpCcIx65Ut+LlLcPT5qbTAQurGb0SYj8l6bEvTS83MNAmRvpgU7Y82tQYhXsbzz1qsXSs6glBAINDThBaTIKDWhRuK8HdD6lWt08ehfb1xqawe29Ku4c4RIbhlQCAqGlpxx/AQhPq44PFtmYgO9MT3jyZ0Wr0dgc0CUGlpKcaNG2f0/bhx41Baauxun8cYZqxNQ58TT0+LxryhwQ7T/HQWAvptSetUq1JntHvXhuOYEMVeLOwVTKgy1CRp5EjOMMs/zpciabACbl0UJHJufDBmx/ojOTnZZBpmFU3ZFVhLeYMS94/uC08XMSsoplQkMCv8AEBtcxvOFNXSn0krbdAkIgGmDwxAW74GSUlTOD2xtusms1Bgna1DUXULAGDbI2MwMpxtBGkpeOiCL9Mw0YoHgcTAdwTXG7g1L+WG/eQqEWEqh2BsSB9d1PjThTVYPC7cckE3ETXNbfgr+wb6cAilgFYwVqo0eGpadBfXDBAJBejjrReKY4M90a7RIMBgW9taQm04hdndmFqjNSRJh90pYxixCwkCJwpr8cf5Ugzr64VbBgCJHx9GVVMbls+IAaCPHu/M2GwDFBUVhZ9//tno++3btyM6uusnbU+kleNtc4ruLT/UxxW+7lKcKKhGZmGNcUIngXrGaDiEE0M/MiKBfbb2+oCbxpGImQ90ADh4uYIlGHQXNU1tePCbDPzr25OsB29HBbODlytw39fp+OCvy4hgBMm15kFu6KTRlJzx8d9XMPat/fj8wFWr60V5cxUJBBAzBI//LhyG9BenYesjo62qEwCWY7RVswcY2eBoSNJoixgAYgLdUfDOrfRnQ1uTeqXxVoE1QrlhP+06cx0T3v0Hq349z32BDn93+x6YvZ2apjY64LOp/r/0+mwUvHMrHp8c2ZVV4+T5xAH4/l9jMTHatLaUqY1lUl6vRG5FI+rsiJPXHZgaD7VGLwAx3WMIBfprqPuk3eCmdqatLlPYvCqvXbsWCxYswOHDh2kboNTUVOzfv59TMOIxhksAEtEPew0uXK/DfV9rbRbOvDoDXq72RxPuLAiGdqa1nd0gw+B5zBvBlnuCSkuSJPr5u2H1nFjapT5z61CfvvtvuBaVGoevVEAiEtDCiYtY2CE1OKA3wm5t1yDM1w2PTe6HLw/l4Y9zpZgdpzB7pJQ6qSkWEpgRG4ioAA/OdHUtWs/M1LH0BqUKH/x5CeeuCDBoTDP8PV0hEQlYCyG16AkFBMtodG58MADjuQAAK2fG4OS1avT1cWUZujKFXKGAQHSAO+s6DcltDHzlRiPu25iGqAB3LBkfjin92Vqa0wbCMmDdXDFcwItrWlBc04IfMwrx9h2mt28oTZYzzEdnYvfZEqzWhV9wxr5RqtT44K/L0JBaAdyaYNTU1tG8ocGs71/ZlYU/L9yAr5sEe5+Z6BQ+b8xhTgN06xAF+vm7oaZJhazrWgGWIAiWhh7Qvwx9uO8KFHIZ/jWhXxfUvGPYLADdeeedSE9Px0cffYTffvsNADBw4EBkZGRg2LBhjq5fr4TrBZyaPG/vvYRIf/3CL3BSKbqfn/Yh3MfLxUg702Lw0GOeJPBxs/7tWEALhST6eLtiyfgIfPx3Dss4lUlXvnEculKBD/66BLlKgCTG93qNiL4ulrZ2rIESLo7lVqGysZV+6ypvaMWmo3lmBSDqxWx4X298cf8Ik+moPKmaN7epseV4IQABpn+sNUB/5bZYPDJBb9gb4CHFIxMiIHcR4+6RffD10XzWFpShGtzLVYxfThWjoKoZH+27gheTBmLJeGND4QWjQuEhE+Oh8RGobmrD8Nf3aetoou7HcqswKcafjjDP2TAdu58cb/FkGAAMDfXC7+dKcbvu4VZcY51nbSqCPKXt4NFizYtQUXUzzhXXIdBTarRF2tmo1BpsPKK1K3x2Vn+IrPAHSs1vQ+0HpfWuampDdVOb0wtASyf2w6+ZxoHMNRpgVLgPRoX7IPVqJf29kCDoMaTWPKad5shwH0yP7dgpta7ALr38iBEjsG3bNkfX5abmgC5eTG2zCqeu6bUbHXWE2FlEB3pg1WytD4xCA8NVZnycBxPCIBYK8Pu/J6BB2Y7oQPZbvTnuG90XU2ICEOylXzz++s8kEABGv7XfKH1XvlXWNrfhXHE9Ygx8nDE1IpQA5whPWcztJaVKjQsldfRnS3HI1DZqJKh0XKkNtX2hPq545TbtMW9KQGhTa/DzySJcLK1HbbMKXq5i1Oq2AkhS30cqNYkCji0tAJj3WSomRPtBJBBgyfhw+ntzwmRdcxsKKpsgEwtZmiXmFYGeUgzp42UyDyb6N1xd2ZbjmQLQblcC6HAg494GUxg29bIy7YNDaFNr0MfbBUefv6WrqgaAfX+QJPDQ5gxkXqvB+3fHY+agIM5rKO1qvcFLGVvYc841nMlABTtq+pYloyAgCLhK9VIgsxkC1haYtg+Y94fGCQKdWoNdAlBubi42b96MvLw8fPzxxwgICMDevXvRt29fDBrUNQ7UejKuNvR6T7h5DB+KIgEBNxGJFbMG4uGJ2r38uBDbvKECQJivG8J8tfYuZXVKFFY3w99Digg/N04PwnaaGtkFfVLE4D5X61YBkYCgBYi2dg0qG1vh1wHbEKYAlF1ST5/G4KqDIdQCRfUPSZKcvkko4YL6iStNq8q0FBDgIcPmJaOwZPMJPPfLOQDa7b/Tr87AgFdSAGi32ZgaPLWJyudVNtH2PovH6bU65oSQs8V1mPL+QYyL9MUPS8fS37sxDhTcqG9FaV0LFHLLW5K3xSswPMwb3jo/KY7Q5N3MWCMUtKm1A2xKy9uZMOunJkk0tbajXtluNmr5xVKtkHskp5L1vcjObX9nYUgfL1pLmnW9Do2t7ahp0o/JLQMCaTME3ZCxNEAHL5fjYmm9kWDlbNj8yDh06BAGDx6M9PR07NixA42NjQCAs2fPYvXq1Q6vYG9DrSEh41CtThvgj4cZb7oUJwqqzN6A3UVTazt+O12MTUfz8GtmMfzd9caAQZ4yjPYjcbqwBq/8loXUnEqkXq3ErjPXcTzX+vaoNSSO51ZhZ2YxVu/Kwj1fHsf/fX8KO09fRx8Om5ouFRZ1TahUEvjo7xwcuVKB1KuV2Jd9g64Lc+vv9LWaDo0jcxG9XMbeWlGrje1sqL7bdeY68iqa4CkTIS2vGuEv/IH5XxzjTF+q8+FzvaYZag3JuXD/ffEGNh3Jow3flSo1SmpbUN3UhtOFNVizO4uVniQ1+GT/FZPtyiyswXspl7DxcB7mDwvmTDN53UH672mxbPuemEA3GJJX0cjqa8PYZv/+4bSR0M7FtapmrNpxDi/uPI/juVVoV+sXeGvnsS3zvbfDnE8tbWqz/dIdMgNTvn3t9wu0Gwu12nQ9oxgabWqs1RoSFY36E1OnC2udfg6cNjhwszerBBsP5+Hl387jX9+ewL1fpWGHzsVFuK8r5C5ieox+P1uMGR8eYGmim9rUWLM7y+nbTZA2xrJISEjA3XffjeXLl8PDwwNnz55Fv379kJGRgTvuuAPFxeb9gPQE6uvrIZfLUVdXB09Px0mwKVmlWLP7gs3xVxRyGVbPiXUa75kpWaV4cWcWqpvsi1dlTXtSskrx0m9ZqLIQE2tAkAe91XD6lRnwtsK2o6OkZJVi+c9nOQ18KQgAcoM4QfaOY0pWKV7amYUqM/3N9DicklWKtXuyWbGXFHIZbh8agvWHchEf6oVdT4xn5c+VfvmMGDyr0+QYIiC0IR5GhfviX9+dRLivKyoaWo3cOnQXXq5ivHPHYCTGKbDnbAn+/eNp1u9Za2fBnXEyT6VSITk5GUlJSRCLxUjJKsWqX8+jxswpHq7xTMkqxePbMi2m6y4M29lVpGSV4oUd5y3eD+Ev/AEA8JSJcG7NLLvKsqeN2rU5mzO2G0EAj0409ujNtQ56uYrR1q4xWhuY89FROHIsH9lyAvsvlVtM5+cuwZO3RCHIU4blP59Bc5v5feGOzn172mjL89tmDdD58+cxf/58o+8DAgJQWVnJcQUPoL1Zlm3LtCv4XFmdEsu2ZSIlq/v9LFHtsFf4ASy3hyrDkvAD6O0sAjykrP3qzoJ6wJkTfgCtgsgwSKI940j3hYX+/vJwPt5OzqbTGwaeLKtTYv2hXF3l9O885tI/Z0L4AbR2R18ezsf2k1qnlwVVzU4j/ABaW7rHdX2tUhsv0ua2Jag+MSf8AMbjSV1nKd3NBtUvttwP9oSPsBf92sztxZwk9feX4TWG62Bts4pzbWDOR2cjJavUKuEH0DrvXbM7W7cGWjaKK3XyuW+zAOTl5cXp8PD06dMICQlxSKV6G2oNibV7su02hqWuW7snu1tVih1tB4W59thbxvzhIZBac2yjA6g1JNbsvmA5oQlsHUdb++Krw/lYs5s7PfM7DePYqqn8SVhnvE1t+Tkra/dkI5DjBI6p7VJb+pw5nm3tGrN9SaVz9i0BR2NpjgHd2y+2jPfGI/loa9d0aB10tjlAtaWzcbZ2U9gsAN177714/vnnUVZWBoIgoNFokJqaipUrV7LCY/DoycivNnrDthUSWmma6Syuq3FEOyhMtcfeMq7XtDikXubIyK+2S4PHxJZxtLUvSMDkWyyTBp3xuCPH01kprVOiua3d6HtTAtDJazU293lpnRJbjxeYvc4Z7t/uwNIcM9UvXaUAsuUe0JDA1uMFHbpvnG0OdMUa4Mxz32YB6K233sKAAQMQGhqKxsZGxMbGYtKkSRg3bhxefvnlzqhjj6e8wXETzJF5OUPZhnnaW8aJgupOf8Po6nHsrLFubyc7NX9no7LJWGg1dQy7vME+AfdatXU+gm6WPqewtr1UOhddbLh7RoZ2Wp24yrWWa9XNHR5DZ5oDXVkXZ2o3hc3H4CUSCTZu3IhXX30V58+fR2NjI4YNG8aHwTCDI51gdadDrc4o2zBPe8u4Ud8KtYbsVGeIXT2OnTXWVB85u3M2RyHj2Bo1NU0CPOxzVRBmZdynm6XPKaxtL5Uua+0sCIiuswGydTzCfFw7PIbONAe6si7O1G4KqzVAGo0G7777LsaPH49Ro0bh888/x9SpU3HPPffwwo8FRkf4QCGXdehoJwGtRb05j7+dDdUOR2CqPR0po7M9QY+O8EGQnYERKWwZR1vnDQGtCwJz6aUiASbG+NmYv/Pt3VuLQi4zcbKHu9Ujw7xt7nOFXIYHEsLNXucM9293YGmOGfaLUEB0qQG0LeuNgAAeSAjv0HrubHPAkWu6KZx57lstAL355pt48cUX4e7ujpCQEHzyySd44oknOrNuvQahgMDqObGWE5qAutFWz4nt1gBzVDs6WgNz7elIGZ3dNUIBgTVz7Xf0aes4MueNNU17dFIE1sw1n/6Te4fijdsHG+XPVVeC9YmbuUMUmBBlOUJ7d7F6TqzRA3X7o2NNpLatz5njKREJTF7nLPdvd2BpjgHsfsmraMSBS+W4cqNrvGjbst4snRgBiUhg833JxNnmQEefTdbibO2msFoA+u677/DFF1/gzz//xG+//YY9e/bg+++/h8Za//A3OYlxCqxfNBy+dvipCZLLsH7RcKfwI0K1oyNvDZbaQ5Vhy3YE0UVq88Q4BTYsGg4PmfndY6FA6/uDiT3jSPVFkIX+pvwAUekDOTRVI8K8jMqm0huuTUFyGf67cKjJ8gSEtsz/3jcc2/41BhsWDTdqb3fi7SrGBl1fMz2dBctlGNPP1+y1pvqcq4+Y42nqOme6f7sDU2sfV79M+/AQlmw5gf9sP9Pl9TO1plFznekHyNRYe7mKWQ5QKZjz0dmg1jRbWD4jBhKh5fVW4eRz32oboMLCQiQl6cM+Tp8+HQRBoKSkBH369OmUyvU2EuMUOFVQjY1HC1jfPzapH/zcJfjjfCnOFGljPH3/rzGobGxFgIdWdehM0nNinAIzYoOQkV+NIznl+OJgHgAgzMcFQR5SpF+rBQDcHh+EyQOCEOAuBQjY1B5mGWV1Lbha3giJSAABQaCPj6vRAtmVMdMS4xToH+iJqR8cpL/774KheIpRp+F9vfHTownIyK9GeYOyQ+PI7IvyBiV8XCS4dKMBR69W4NCVSozoKzdanJnpTxXU4Lu0awjx4rZTSYxTsLy43j8mFK/NG6wzKte2aURfOSoa2lBY04I7hgfjnTviIWFEf6fKTMutwmPbTqKxVesLReEpxft3D0VqbgVKapUoqm7CqcI6WEuUvysWjg7Dm8kXWXWcG69AS5sa+y4a+y8J9XbBwWen0n3NDOpdUqdEUXUzQi3Y7Bj2YYCHDCPCvHHqWo3Z8eS6ztnu3+4gMU6BQE8Z7YV8aKgcO5aNN+oXSli9YcVpRkfXb0ZsEKa+fxCF1c2YNsAfGQXVaFCqse3hMRgXbazlNDXWAJCWW4XjeZUACCRE+mJsP1+nngOzGLHO3rg9DiV1zfjigHZddxUL8OikSIT5uuI/P58FACwZH44guYz2FRbqJYOLVIggTxkO52jD9Hy2cBhmD1Y4dbutFoDa29shk7GlXbFYDJWq62O29GTkLsZvyZNj/DEuyg+T+wdg5keH4esmwXgn3lagiApwxzep+fTne0b1xW1DFPgtsxjl1y5jzV1DOuShVCjQLh4AsGzbKezNKsPr8wZh/rAQrNl9gRUvqKtjphmGVxgbxdYqiIUCVv07imFeE/v7I9THBYeuVAKEsSJXKNCG4gj0lCFQLoNEJMDpohoMeGUvIv3d8cdTE02WFe7rDqGAANNJvEAgQKivKwprWjA5JoAWflra1GhtV0MqEsJFIsT4aD8EeMjQ2KoNIyASCTA+2g/jdQ+Qqe8fNCrv9XmD8Moubv9KVyua8fofF+nP944KRYCnDE9Pi4ZaQ+LW/x5BTnkj6xpXichs3KknfzzN8oRtCq7xs2Y8HTnuvQlmPDs/d6nTPRiFAgI+bhIUVjdj/6UK+nuJ2PRGiamxZs75nkABI6D1rYMV+IfhGLFZpcHH+3NwYOUUAIBEJICHTEyf2Evo54sfddvKV8sbMf3DQwCAnPJG3OZkY2yI1QIQSZJ46KGHIJXqVetKpRKPP/443Nz08Xh+/fVXx9awl2G4TXDHsBCE+Wn7Tx+M0rknDQBUNLRi7Nv6iOwrZ8bgialRAID/m9IPycmXOlxGdVMbDlwqh1gkoCOI779UjpI6JS38PDa5H748lEcHUewqpAztx7hIH6MTDl2xuBN0QFZuI+X/+z4T12tb8NsT4/HE1Cik5VXh3q/SoFQZe6pdMj4cm1MLdPlqvzMUHIS6aKrtjNhI36TmY92fl3HPyD547654AGBphgzzoGKIMRke5m2umfr2TInEY5MjIXcRY/3BXHx5OJeOMs/EMMCqYRDTs0W1VpXH41hEui0TkYDARwuGWkjdPWsg876m6AnrcUdJvaqP4iAUEthr4LmZIIBgLxl+/b9xtLZ9+sBAnHhpOutlkNl/IicXfgAbBKDFixcbfbdo0SKHVuZmwNBXzcMTIhCiC+yZqds6alA6v1bN8AFPbXk4kuKaZqz431kEy2UYoIsqnHq1Egcv69/OSmq7x7eElOOtkBmXrCtufqoELvdHN+qVuF6rdQ5JRain0nOJSwOD9DFzPGVaId1w3afaxJzD1N+UcAQAUrF+QTQUgNo5bAat8eD9zPRoPDM9hv7c2q7mFH4AY4Gni2VjHhNQ88ddJoKHzLxmuLtkDubcpegBz3GHIhIQOH+dvU0tFQkgFQlxoaQeLW3tCPZygb+HFBfL6lHR0IpYhSdCfVxZApCgB3Sc1QLQ5s2bO7MeNw3MxXnh6L6I9NdHE35x53kAQCvHW7KzYfiA33AoFy/MHoDWdjUe/OYELhYL0WdIHUZE2K8Gph6Mre0aWgPkKhGxtr72nC0BAEwfGGCcQSciERoLQJQwsHnJKCRYMLR1BJRwwSXQMDUtlMaGWpC4FEbUb1P6++OeUVondIZvvpTQ284QgKi/mfOBuQgaPsjaOSJrbzqaj/g+cpwtNm0bJBIQUKk1yK1ohEhAmN3y1BhIhENDvUym5ek6vFwlWJwQBlepze7nugwuDVBXb693B1Rg4HBfV8hEQrhJRAD0TkGptfjzf66irF6JcZF+8PeQ4usjeUg+rzVNeCAhvNPDETkamz1B83QM5sMjt6IRF8vqOV31OztCjhMAu85cR2mtEun5NahXEahutj9gKqBfjFrbNbQWw02nbp0bH8xK297FcWZEDAHoWG41judW0UEQBQQBGcebpKMZoPDAm/PjsGxypNFvzP7YdbYEj2w5ge+OXwPAvWWWklUGwDikyL+n9kOgC4nEQYF4547BSFs1DbcP0/e9htYAcQtAhg+PuBC5Udk/ZhQaBco0pKROiRP51Uj8+Ahmf3LE7Baj4VQY28/5/I/cjPi5SzFzUBBqm1XYfqLQbNruEjlWzR5g5K/mZhCAqO3JQE8ZBALCSHsjFQmgVKlZPrWu17Yg+XyZ7nfteufpIsJtQ7QnvrpiDewovADUxTCfPRn51bjji2MoqNQaoIX7ak+mrJwZw3WpU8G1xdPUqmbZf3T0ZBa1zdTWrqE1B9R+s+FW4smCmg6VZQ9P3aIXPJTtanrL6esjeV1Sfh9vV9w/JgyJcUFGv6kZW01Xyxux/1I5LpfVA+DeMvv7ojaoaW4F26D4qVui8OJQNR4c2xe+7lIEyWVwlejf4Lk1QMwtMHY5vu7ao9CGc3xStL/JdgLAD+mFuO/rdF2ehNktEsO5cTPYcPQULpbW48eMQhzLreL83UOniZjWxRpdin7+7ogKcGd95yLp/Y9Jw+3tq7qDBSN09nkSkQCtKvbORC3jBZda9wmCoDXSPcEGqPePrJNBCTlMKOnbU3dCbFCw8Vuys8H1Bq7dJ3bclKIepG1qDVQ6Qw433QKZlsdeQBtbu16LNophvNuq0uDpaVqP6EdyKvFDuvk33M6GqQGi+o6y0yE5Ns360Yb4wO/nSqwuhxK0mBrBe0b2wbOz+uPjBUPx+X1s/yL0th0JvJg0gP5+a9o1Vrrf/z0BzycOABcCgr0FNn1gIJ6d1Z/+PMdAO1jd1DFNJI9j0GhI+ni7qZejjJem48LaWXhtXlxXVo0F80G/cHQoogI8uq0uXUWTzobz5DX2i+Qp3WepSGB02JT5osNc99VqY62ws+K8m7G9lKn9jd909f5KjG0snBWRwFjQEYsELCNCw9M4tsK8qebEB2NcpB8qG1txrrgOVU7wUBvbzwfRnhrk1AvQ2q5mvfGcvFaN+8b07dTya5vbkHW9Hq5SIYb3ZZ+kYtraUAKQp0yE0RE+CPQ0dvjGtDurYfTt5mPXkFlEYExjK04UViCzsAa3DAjARJ3GhksDNHNQEGaacJg9Nz4YnjIxogLcMXuwAicKarAv+4ZRugAPKYb04X4REAoIlmZJQACHdIbxzyX2x/9NiWKl38xw1cDTfdS2qLDxiG4sTDwbDd1LdDXHc6uwI7OY/sxls9YbaeY4GUqxcHRfDFR4GAmtzPWZeSjkWK72RFkQxzrjbPACUBfDFbH8fHEtwn3dUNmoNTrbfqIIM2IDu7pqNiEggLtG9EFLWzv+0O0DX73RgGkD9Krr7JJ63DLQfkdYzIfq4SsVGBfpB7mb6Sl7PLeqy5zOqTUkHtt2Cjn12hv/v/tzWAbuJTUtnV6f89fr8MCmDAwI8kDKM5Og1pC0U7ZGpV4jRp3qkruIsX7RCLo+VPqyuhbUMCKmMxXdb+29DECI6u3nEOHnju0ni+DnLsXEaH+oNSRcxEKMDPOCSCCgg9G2tWvw7bF8nCiogZtEiDuG98E4nV+rA5fLsTm1AL+fu44tqflIN7F1+cn+KxAQArxy60A8kBCOhLf/RlWT1k5Io9HA313vjqOwuok+DUiQMAqKa3jP/bB0jI09zeMIWPcBh1yh1pDYefo6Ciqb0D/IA0nd4ETv70tlrM+qdsefbnVGohmHcVJzKlm/7ThVhEcnRSKNsW15rrgWk2L0L/NXy5swOYY9qNVNbZ0eoLqjEKQpJyJdwOHDh7Fu3TqcOnUKpaWl2LlzJ26//Xb694ceegjffvst65pZs2YhJSXFbL6ff/451q1bh7KyMsTHx+PTTz/F6NGjra5XfX095HI56urq4OnpafkCK0nJKsWa3RdQVt9q9JtCLsONeiVtn1Hwzq0OK7ez0LYnm2UYJyDYNiYKuQyr58Ta7Ao9JasUy38+SxsWW4u95dlCSlYpXvj1vMlj2F1Vn9Srlbj/63QMCPLAM9OjsXZPNkrr2GMhIAiWRpGqDwCj9BSeMhHeu2sIEuMUCH/hDwDA6HBvRAV64If0Qvxnegz6B7kbXa+QyxAX4om/s8uNnm9SkQAuEqFVfWYIAePnpUIuQz8/N6Ry2JLIXcR4987BdJ+/vfcivjyktcsK8pQh7cVpRteoVCokJycjKSmpQ847nZ3ubGdjazviVv8JALh9aDA+vncY/VtKVinnfLLn3rG3jW8nZ+Orw/lGc+3eUaF4584hNtWhK3DUWKZkleKV37JQ0WibVt1wrad83DHv8Y6uf/a00Zbnd7faADU1NSE+Ph6ff/65yTSJiYkoLS2l//34449m89y+fTuWL1+O1atXIzMzE/Hx8Zg1axbKy41d5nclKVmlWLYtk1P4AYDSOr3w0xNsNvXtYT9ADRVcZXVKLNuWiRQDx1qW8n58W6bNwg+g7Udby7MFqm7WPsjtab+1UPOkrkWFZdsyjYQZDWm8nVpWp8Tj2zLxOEd6inplO2edKY3c5bJ6zvJK65TYxyH8ANotNnuEH4D7mH9pnZJT+AG0/fE4o/7MV7yyeiUKGV5veboOpkaXOabUWmI4nzrz3jHk7eRsfMkh/ADATyeK8HZydqfXoTug+t5W4QcwXutrm1VG93hXjqE9dKsANHv2bLzxxhuYP3++yTRSqRRBQUH0P29v815jP/zwQyxduhRLlixBbGwsNmzYAFdXV3zzzTeOrr7VqDUk1u7J5ry5uIj0c7OcqBuxpT1UmrV7sjm3/7jyXr0rq0P1s6U8W1BrSKzZzR2ywRS2tmrp47oAAFltSURBVN8WCJ0hRXlDq9Vzy5YarN3DXvQpVfahnAqb8ukuqD437Pcnf8zsphrd3DC3Qiih1Nxa0pn3DpO2do3eNskEG4/kc3ox78nY+lyyh64aQ3txehuggwcPIiAgAN7e3rjlllvwxhtvwNeX28lcW1sbTp06hVWrVtHfCQQCTJ8+HcePHzdZRmtrK1pb9ZqZ+nrtcWGVSuWQWGfp+dUm37a5UKrUTh1jzdb2kNC+sR+/Wo4xEeZ9sqTnV+NGQ8cMnG0pzxbS86tNavC6oz4ajdbOpzMWFqrO9GeShEC3nDV1gtfvzoDq83Y1u77niuuM7i/qszPfd46gO9vJdFD55JQIqFQqi2uJPfeOrW3ccqyA0zUEEw0JbEnNxZJx4Vbl2RV0dCxtXcftpSPrnz1ttCWtUwtAiYmJuOOOOxAREYHc3Fy8+OKLmD17No4fPw6h0Pi0QGVlJdRqNQID2QbEgYGBuHTJdGyqt99+G2vXrjX6/q+//oKrq/mo0dZwqpIAYP3phoqGFiQnJ3e43M7C1vZQ/HUkHVUXza809uZtb3m20NG6Obo+ufVAV93CNTU1KFBVo6d5zvjrSDryGwgY1tvU/bVv374uqFX3013tJCAECQLpRw/hosT6e8qee8faNh7JF8CaeX3k9CUE1jrfVpi9Y+nItdYaOrL+2dLG5mbrt7idWgC699576b8HDx6MIUOGIDIyEgcPHsS0acaGjPayatUqLF++nP5cX1+P0NBQzJw50yFG0L751fgu56TV6VvVBJKSkjpcbmdha3soZk4cY/ENwN687S3PFjpaN0fX59S1Gvz3wgmH5WcOb29vxIR7Y39JzzpSPnPiGNQ0q3Dkp7Os7w3vL5VKhX379mHGjBm93gi6O9t5TKXdQp49MwZyF7HV95Qt946tbbxxrABH9l6xmG7isAFIcjINUEfG0pFrrTXYs/7Z00ZqB8canFoAMqRfv37w8/PD1atXOQUgPz8/CIVC3LjB9ity48YNBAUZe8ulkEqlrCj3FGKx2CGLREJUABRymU3qRmdehG1tDwEgSC5DQlSAxSORCVEBCPSQdGgbzJbybCEhKgBBnlKbt8E6qz4RAZ54MWkAPj+Qi/oWlUP38qk6T4nxw67TRZg1KBDzh4fijuGhuP/rdFTYYHfUXSgYff7ibxfQwHANYOr+ctQ97+x0VzunDQxCWl41zl5vwLSBgfRaUlan5JxPHbl3rG3jQ+Mj8U7KFbPbYAJCm07sQEevjsLesbTU947CEeufLW20pS+cbzTNUFxcjKqqKigU3EfqJBIJRowYgf3799PfaTQa7N+/HwkJCV1VTSOEAgKr58RaHd/m1sGdd4TbEVDtsQaqzavnxFo1+YUCAmsd4AXW2vJsQSggsGauCQ9/JrC1/bYQ6CnDo5Mi8e6dgx2aL8XqObF4bW4s3h6lxuKEMPi6SxEd6IHX5mn7wNkPKzL73J4ThTyOJz2/Gt+kan1EAey1xHA+dea9w0QiEmDpxAizaZZOjGCF+ekNmOt7R9FVY2gv3TqijY2NOHPmDM6cOQMAyM/Px5kzZ1BYWIjGxkY8++yzSEtLQ0FBAfbv34958+YhKioKs2bNovOYNm0aPvvsM/rz8uXLsXHjRnz77be4ePEili1bhqamJixZsqSrm8ciMU6B9YuGw1PGrXRTyGUYG6E17jblAdeZSIxTwF8X14mJ4RwPksuwftFwm/xAJMYpsGHRcLja4RVWYUd5tkDVjfJ5YQl72m9PnczNLUPcJEJsWDQcCjm3p1YfN4nZOlPlBRlcr5DLMCM2gHMxlYoEVveZNchdTOclERLYwKh/bXObU55AuRmhHHQyw7GYmk9dce9QrEqKxWOTIozWLwB4bFIEViVZ98LX0zDV99Zg2FdermKje7wrx9AeunUL7OTJk5g6dSr9mbLDWbx4MdavX49z587h22+/RW1tLYKDgzFz5ky8/vrrrO2q3NxcVFbqPVcuWLAAFRUVePXVV1FWVoahQ4ciJSXFyDC6O0iMU2BKtC8+256Cb66K0dymPVb549KxGB3hgxd/PY+0/KoeEQoDADxcxKhobIObRIinp8dgcIgcI8K8kZFXgb+OpGPmxDF2qz0T4xSYERuEYzmVWPP7BeRWNAEADj87FX9eKEVGfjVa2tSIC5HD110KPw8pgjxlXeIJmqpb6pUb2PpXBmS+ChzLrUEVwwfGfaNDMSc+pFPr09TajktlDRALCSTGKfDanmzU6x4wT0yNxOcHclnpJ0b5obalDXIXCd2GyBeNjYFfThpIL1i7zpQgvYzAmKY2FNc24ODlCgxQeOC2IcGYERuEO9en4kxRHR6b1A/PJQ6w6Ama8lTt5yYFCKCstgUv7cqCkhF/6YO7huBMcS1qm1XYc87Yf0iwXIZnZsTguV/OAQAmR/ticB8vAAQSIn0xtp8vq89f//0i63onfBG9adh+sggAkK+7nymo+UjNjwCPrrmXmaxKisWKmQOw9XgBUq9W4p/LFRgc7NFrhR8Kw76n7s3yeiUqG1tR26ICAQJjInwgEBCobGxFgIcMI8K8cepaDWu8AHTrGNpKtwpAU6ZMgTlH1H/++afFPAoKCoy+e/LJJ/Hkk092pGqdhlBAIFpO6gJTahf9hEit5qekThtN/K8LZXhiapSpLJyGqf0DEBfcin/fEoXoQH3AwDERPqi6SGJMBye/UEBgYn9/bPEfjcrGVijkLgiSy7B0UiSWToq0nEEnIhRoH7Y1YSSSkobiuV8vYOfp6/TvYyP96HHtLHIrGnHn+mNQyGU4vmoa4kO9UFJXhhUzYjjf6Ab3keM5RoBRoYCAWEhAZRDviBnYdOWOLABCFPx0FrMGBeGzA1cxb2gwbhsSDKGAwPSBgQjwkGFyjD891hKRQDdGxnXm6pMP/87B9doW+vOdI0Nx58hQAMCn92m/ozxSA4C7TARvV732MUjuipWzuAOnAmCFKAGA7/811mRanq6Ba9Wn7qnuRCIS4JGJ/RAZ4I5/LldA4/QbvY7B3r7nuqa7x9AWepQRdG+iXW3sVOtyWQMA4GxxXVdXxy5eua1r3oxCfVwR6tNxdwSdSX0L2/eEtAvsBZiR1Zn/e7lJ4CIRItTHBSP6euO3M9ro7iqDOafRkEbCjzkoT75MDeWTt0TbW30ajri6FuohwIzYQKycGYP3/7pCX0+SWqeHGhIQCwkQhD7mGYW/h7RHLdC9lW6MwGQVlL3PhZJ61LWozG658vRcepdVVw9gzZ6LWJkuRIvKWACawhEpnke7WBZVN6O0rsVpbTmYmhWgawQgKhQGpeFo1QVulAoFuG1IMI48dws+WjCUTm8o7LRxCOGAXrAyRCjUtknt4AjZlO2btVACj34q6A2do17ai5iX97K21JgaoIqGVj4UhhPg5PIPRoczjms7eV157IcXgLqY1nYNVBruB8zEaK0ANLaf43zFdCYkSWLImj/Rb9UfuFre2GnlXCipx8T3DiDh7X/QoHROT72GBttSUec7GKNCYVCCAHU8/40/tM7aqhpbsfxnvf+b/MomjH/nH0z/8BAAoJVDCAdMx6Lj0gA5AmagycEh+gMA5Q1KhL/wB2v7CwBmDNS6tHhgbBj2r5iM/0zXaqGYgpua8YQ13AJb9v0px1Wexy4Mx8TZYE5xgn9K9lr4oe1iDG/8AUEeRr+ZegN3Nu7ecBz1ynZoSHSqoduJgmr6b2c1qDPUTHXFkVn91pG2bGobjjKE/upIHssu6b4xfXG9tgUlOnsbSmNkCGHC7oHqe7VGLzgt+PI4Il9Mxt7z9gc71JgQVkzFXlo4JhSHrlTgzg3H8On+HAR4au2dmFtprDwNsrlQYr2jNB7H4q07JXS3zsbLWWHOn56yHvPYDi8AdTEagwflwtF96b8rGrRv8DfqOz8+iyNgCiOiThRMRKxynHPKHrxczvrcJVtgBhogJv87WYQvD+VxXket7a0MASMm0J3+WyTkHksuDRAVbLQjzwgBQdCaH+ZYM+dX0mC9I1O1hkRzazvyKppQUqu/V4SMSjDvM7WTaxtuJgJ1wqqnzLltapgabSd95+JxAM75NOnFUOvyvHgFNi8ZhWkDA+jfvj1eAAD0kW9nh/mg7EzNjJAh9Dip/IPz1/VahaPPT0U0Q6DoLKgupwxKH0wIo38rrmkxSu8i1m7LUW+3TEGmXWfX4yETYdYgbq/peg2QsXDRkbfkO9cfw/nrWsN/5gEApkCzZLzeUV1Nk4o2cM4oqMY/l24Y1YFZx4nRfnbXjcexTOkfgLnxwfDl8CHmTDAdZ/IaoN6Lkz5Oei/UAyPEywV9fVzphxLQ8240pmBys2uAmHXs4+3aJTZAvu5SLJ8Rg/+bonWZ8PAEvZDQ3NZulL5MF7qEEg0i/Nzwyb1DAQB5lVqh21BDOXuQ1n/WjIEBmBzjj9//PQFv36H3PE0l78jcNbXVRTDyZJ7C+de3J1hv5YevaP2ACRhfMpvxYEI4Qn1c7K4fj+OIDfZEXx9XtKic2zM3c371sGWZxwac82nSi6EeMD+eKMK0Dw7hPz+fod9Wx+mO5wZ4SHE8t8ppTzwB2jfs2mZ9TKxT12o6rb7MBSgj3zn7xdNV71Fi0KspSL1a2en19HGT4Klp0Xh4QgRScyrx0b7L9G//XCo3Sv/PZV2MPF211BoSeRVs43XDOv/33nh8ktCOJePC4CETo65ZhR8zruH+jWlY+t0JlOl8VzlKA+guFXLO/bvWp7LryPj5Rr1SvxWn++6Lg1eRerUSLW1qbDqSR28vUzj7/dUbUWtIfJ9WgM8OXMWesyU9pv9P5Ff3mLry2AbvB6iLIQhASJCo0XkNPnylEhPe/Qdz4xX4Xef1tryhFQs3pkEhl2H1nFincyOeklWKF349j1qG5+Nl32fCy1WMd+4YjGn9HbflkJJVijf/0HvyXbgx3en65c8LN/B9WiH9ualNjfu/Tqf7ozPryTUWAPc2akqWVgBq12hMXqfSkPjiwFX8n4Ejzj8v3MDLu7ON0lP8fLIQUwcEcP5miaomvXDS2KrGwo1p8HIVs45K1yv1GoPyhlb8539n6M97s8ow4o19aGvX0HLR5tQCbE4tMFmmM99fvZGUrFKs3ZNNB1DenFqAlKwyp+z/lKxSvPLbBfrzok0Z/FzppfAaoC4kJasUe7NuwNCNSmmdEl8ezmdFqwa0WxbLtmUiJcv+EzaOJiWrFI9vy+R8ENY2q/D4tkz8eeGGw8pati0TtQZOBp2pX85WEXjyp7OcwTap/uiseu45e93kWJhDQ8LkdWoNiff+vEzX+dCVCvxaoG2juXL2Zt3A28nZtjUA2jG+Ud9q9H1tswp1LdzlkQCaWtVG6W0NeOpM86g3Q93HlPBD4Yz9T9W1opE9J52xrjwdhxeAugi1hsTaPdm6N1TrtgsoOWntnmynUMGqNSTW7L5gMd0byZc4TybZWpa+v9g4S7+oNSR25Fu+hTqjnmoNibW7bRc4rIWq87+2nsahUuvsmTYeyTdpz8MFNcbdhbPMo95MT7iPKXpSXXkcAy8AdREZ+dVGb0DWQEKrIcrIr7aYtrPJyK+mne2Zo6y+Fbn1HbMJsdRfztAvJ6/VoE5luZ2dUc+M/GpUNrU5NE8m9tRZQwJbdScZrcHee8KRUPPo5LWabq1Hb6Un3McUPamuPI6BF4C6iPKGji30Hb3eEdhSh/oOOmy2tqzu7JfyBsvCoD6tY+vZFe22p4xr1daHmXCGOU1hy1jyWE9PuI9trYMz1JXHMfACUBcR4GEcnbsrr3cEttTBs4N+zqwtqzv7JcBDakNax9azK9ptTxlhNgStdYY5TWHLWPJYT0+4j22tgzPUlccx8AJQFzE6wgcKue03DgFAIZdhdET3xwcbHeGDIE/LD4ogTykiPTu2T071l6kNJmfol5Fh3pCLLbezM+o5OsIH/p3oTM6eOgsI4IGEcKvT23tPOBJqHo0M8+7WevRWesJ9TNGT6srjGHgBqIsQCgisnhNr0zXUjbh6TqxTxMASCgismTvIYrqXkwZ02H08s78Ms3KWfhEKCNwZYdnotzPqKRQQWDGzv0PzZGJPnZdOjLApBho1xt01gs4yj3ozPeE+puhJdeVxDLwA1IUkxikQ6e9m9L1CLsNjkyKM3oaD5DKsXzTcqXxPJMYpsGHRcHi5Gu9xebuKsWHRcMzSeQ92RFnrFw1HkBP3S7wvic/ujTfbH51Vz1sG2ud3BwA+u28YZCaElY8WDDWqc5S/Gzxkpt2G3TEsBKuSbBPwAe0Yjwz3NvK26+Uq5uxTAHCTCOEuFRmld5XY5n3bmeZRb6Yn3McUPamuPB2Hd4TYxXjpXPo/NTUSkYEeCPDQqlSFAgLPJQ5ERn41yhuUrO+djcQ4BWbEBiEttwrH8yoBEEiI9MXYfr4QCgioVB20gOYoy5n7ZdagQMweEmKyPzoLN4kIy6ZEYn/2DVzRBW/0lInoaPC+riIM6+sNEAQ8pCLMigvC49syAQAzY4Nw4TUFUnMq8ODmE6x8b2E4NBwb4Y20/BrcM7IPFo4Jw3spl7CV4fSR4pGJEUbfWYvcRev0cOnECMSFyOkxBnQnD+taUN3Uhtd1DjEJAN88NAr3fHkcAPDk1Ej8Z4ZWG/bV4Vy8m3IZfm4SfLJwGIb39cYP6dfw+cGrqG5SYeWMGIT6ujrlPOrN9IT7mKIn1ZWnY/ACUBdDBaIcqPDA7CEhrN+EAu2DsycgFBAYH+2H8V0QaLIn9EtX9geFm1SE5xMHYERfb/zru5MAgGAvF9SXNQAABgTL8fVDo+n0DUq9YKohSUgEAkzqb6xFIhkumLc+PArJyclIGhcGsViMu0aE0gLQjNhA7MvWOr3syMOB8qtCEATmDWXfE8xxpwQgEoCYEYg3LkROlx/fxwuANk7a+CjtWDwysR9+PlmM6iYVIgPcMXsw/xbfHfSE+5iiJ9WVx374LbAuJtLfHaFuJDxdeNmTxzEM7etF/11Wrz+iKxGyb2/CiqiO8aFerDwMoSLIh/m6YuODI+Gt26bqSDBUyvfKV4fzrEpPGpTHDDw7tK8X/l4+GZseGgkAOJZbiVW/nsPlG1qh8MWd5+2uJw8PT++Cfwp3MW/PH4Tk5GsYHc6fJODpGGoNiaLqZijb9SEgmOEqDCPSCwkCIV76qOhfH8kzcup2tqgWdYw8Tl2rwflqAiMbWuHlRmDTUa2QQmlcKO1NRwQgW9GQpIEApBf0XCUiRAW4058vlzXgx4wi+jPvw5eHh4eCF4B4eHoojcp2THn/oNH394/pi+/TCyEVszVALhIhUl+4hf58trgOf2XfgK+bBFUMr9JMTdG9X58AIMSlX7PwwT1DkXy+DAAg0glAw/p6o6m1HS42GiAzsUYzBQCR/m7IrWjC4BA5xCKGACQ2rcg2jFpA8hIQDw+PDl4A4uHpoRAcz32ZWIAl48MxvK83QrxdjBMwaFVpNUeG9jv1HEFI29o1rHQECES9mIwNi0ZgemzHTv1Zqzu6bUgwPtmfgwFBnhgQ5AmFXIbSOiUkQr3wVV6vxLa0a3DRGYhr+LhNPDw8JuAFoC5m8eaTuFgsRFBcLcZE+nd3dXh6MFyCg7erBFEBHogK8LB4fasucKmhANTU1s6ZXsRI5yoVol1D0jZBHSHUxwXZpfUW01EHCKhqUPVnaoAqG9vw33+uwt9DqhWADFQ+gVY48uTh4bk54I2gu5gbDa2oaSOgUlsfNZuHhwsuu5vSOiXeS7mErOt1Rr+p1BrM/ewo5nx6FA1KFVp1tkOGASBNbRNxnfRyRGTsp6fFAAD8LYSjcJOKEObrikCdj5Zvl4zG9kfHItRbH35DJGTbJqkNGjO8L+/xmYeHRwsvAHUhbe0aVOtsLVIulKGtnReCeOzHlOnMFwdz8fJvWdiZWWwkoJwrrsP563U4eqUCl3XH5Q3JKW+AWkOyrq1vUYFg6JxOF9YCAJ74IROj3vy7QwEiSbA1O1yoNSQOXanAtapm3KhTIq+iESv/dwZr9lzAmaJauq6UkNaue8Ew3AKz1t6Ih4en98NvgXURbydnY+ORfNooc1t6MX7IKMbSiRF2edDl4flb54OHizNFtThTVIv3/ryM1XNikRinYG2ZLfvhtMlrPz+Qi+/T2c4OL91oxPQPD3Gmr+hgJHUfNwn+NSECblLu5SglqxRr92TTmqpvj1/D1rRr9L20cGMaFHIZVs+JxUCFJwC9BohK4+MmwfgoP8T3kXeorjw8PL0HXgPUBbydnI0vD+cbnUjRkMCXh/PxdnJ291SMp8eSklWKp386YzFdWZ0Sy7ZlIiWrFH9dMC0wGVLbrGIdqQeAG2b8Awk7oFn5Pq0Qe7PKOENtpGSVYtm2TKNtOsN7iWrn0ZxKAHp/RUvGh+P4qlvQx9sFe8+XmhSyeHh4bj741aCTaWvXYOORfLNpNh7Jx4qZA2wKJMlz86LWkFi7J9sqnzYktMbSa3Zf6PCJKHNXd8QPUF2LCtdrW+gQHhT2tPO/+3PoawHAQybW/ROhXUMaGUXz8PDcvPBP3E5m6/ECo7dVQzSkNh0PjzVk5FcbaUTMQQIoq29FeWObxbS2QMXrAgBBB0JhUNqacgMNkz3tvKHbjmvXkKyQHtSfjjDa5uHh6R3wAlAnc6262aHpeHg6YnDsKOKCPfHdw/o4Yx2JBXahRHti7acTRazv7W3nypn98cdTEwBo7aRe25ONY7lVALSaMB4eHh6A3wLrdMJ8XC0nsiEdD0+Ah6y7qwAArO2kjtgAmbrS3naOCPPGoGCtsXNGQTW+STW/Bc3Dw3NzwmuAOpkHEsLNHu8FtMd/H0gI75L68PR8Rkf4QCGXWe1BmQAQ5ClFgLvEYXWgtq3iQjwRq/CEoCMriQnhyZ52KuQy1tacod0TvwHGw8NDwQtAnYxEJMDSiRFm0yydGMEbQPNYjVBAYPUc61wnUMLDmrmD8NrtcR0q11AQGfvWfsyLD0Hy0xONAq86AmY7LQlB1O+v3BqLLw/n4rN/cqBUqY0cIfLw8PBQ8E/dLmBVUiwemxRhpAkSEMBjk3g/QDy2kxinwPpFwy2mC5LLsH7RcCTGKZAYp8CGRcPhYiZ4KIWXqxhermKjvDx1R9VlYiHqle1oUam5LrcJfzOaKaqdQXL2dpjhvUS1c+agQLyXchnv/3UFSpXayKt1kKdzbB/y8PB0P91qA3T48GGsW7cOp06dQmlpKXbu3Inbb78dAKBSqfDyyy8jOTkZeXl5kMvlmD59Ot555x0EBwebzHPNmjVYu3Yt67v+/fvj0qVLndkUi6xKisWKmQOwJTUXR05fwsRhA/DQ+Ehe88NjN4lxCs7v7xnZB8FyF4zp54vRET4sA+Xv0wvhKhGiRaWBSEBgan9/BHrKMDTUC3UtKvi4SxHkqd9GOn61HH8dScfMiWOQEBWAie/+wzqu7ohYYA+Ni8DfF8sxIIg7fllinAIzYoOQkV+N8gYlAjxkGBHmjVPXaujPVDuZJ7/aDbxZA8CU/nz8PR4eHi3dKgA1NTUhPj4eDz/8MO644w7Wb83NzcjMzMQrr7yC+Ph41NTU4Omnn8bcuXNx8uRJs/kOGjQIf//9N/1ZJHIOW2+JSIAl48IRWJuNpHHhEPPCD08n8PPJYoyP8sVD48ONTmedKKiGUqUNEyF3EWPj4lFm8xoT4YOqiyTG6ASMEt2x9DNFtQC0fnf2nC3BgZVT7K4vZUxtLkyFUEAgIdKX9Z3hZyoPoYCgQ3kYboF1xF8RDw9P76JbJYPZs2dj9uzZnL/J5XLs27eP9d1nn32G0aNHo7CwEH379jWZr0gkQlBQkEPrysPTk0i9WoULJfUYH+XH+p4Zz8vXQUbRRR104RAkl+G+MX0dtj1FCUBMX0Bhvq6IDvBAVIC7Q8rg4eHp+fQoFURdXR0IgoCXl5fZdDk5OQgODka/fv1w//33o7Cw0Gx6Hp7eCJdvHkoBcvjZqfjrP5MdUk5HnCACwKlrNUjPq3JYcGCRrj5qNYnlM/pj/4rJiPJ3R0Z+Fe8JmoeHh8Y59oasQKlU4vnnn8fChQvh6elpMt2YMWOwZcsW9O/fH6WlpVi7di0mTpyIrKwseHhw2xi0traitVUf0LG+vh6A1g5JpVJxXmMvVH6OzteZuBnaCDhnO71cxKht0daHIDVGdaMEoLZ26+a2YRvjgj2RVVLPSiMgOtYHVQ1K5FY0obSu2SF9SQl+yrY2KDzd4CWTQiwkUK9sR3Mrd7udcSw7g5uhnTdDG4Gbo532tNGWtARJOscrEUEQLCNoJiqVCnfeeSeKi4tx8OBBswKQIbW1tQgLC8OHH36IRx55hDMNl+E0APzwww9wdeUdFPI4L++fE6KoSa+BcRWSaFZrPy+Pa0eYgcz/fIYQSjWBl4a2I8DF9vJ+KxDgQKkALkISQgJobCcgFZB4b4z9p8H+KibwR5EQQ3w0eKR/x7VAL54QoqmdwKr4dgTpbt8tVwQ4XSXAneFqTFI4xZLHw8PTCTQ3N+O+++5DXV2dRVnB6TVAKpUK99xzD65du4Z//vnHJuEHALy8vBATE4OrV6+aTLNq1SosX76c/lxfX4/Q0FDMnDnT5vIsoVKpsG/fPsyYMQNisdjyBT2Qm6GNgHO0c33+caCpQf+FUASotcLIpIkTMCiYPX9fPv0PlOp2rM9xweRoP7x352Cz+Ru2MTP5ElBaiIfG98P8YcGY+UkqJBIxkpJm2d2GrV9nAKjFuWoBkpIS7c6HQhFXCxLAwCAP/HO5ApdvNOB0ldYb9L4yKd555Baja5xhLLuCm6GdN0MbgZujnfa0kdrBsQanFoAo4ScnJwcHDhyAr6/xqQ9LNDY2Ijc3Fw888IDJNFKpFFKp1Oh7sVjcaROrM/N2Fm6GNgLd2876Fra6t7lNr4mRSozr5SoRokHZjuomFS6WNVpdb6qNR3K0MbUqmlQQCLXLh4AgOtR+AaE3RXREP46O1B9133+5EnvOltCfNaT5Mvg523u4GdoI3BzttKWNtvRFtxpBNzY24syZMzhz5gwAID8/H2fOnEFhYSFUKhXuuusunDx5Et9//z3UajXKyspQVlaGtjZ9VOtp06bhs88+oz+vXLkShw4dQkFBAY4dO4b58+dDKBRi4cKFXd08Hp5Op8RMtHQRh3Fy+ovT8a0uiKk9AUzzKpsAABdK6iESEIj0d0OEn5vN+bDoxJPpRqEwnGPHn4eHxwnoVg3QyZMnMXXqVPoztQ21ePFirFmzBrt37wYADB06lHXdgQMHMGXKFABAbm4uKisr6d+Ki4uxcOFCVFVVwd/fHxMmTEBaWhr8/XkHaDy9C0MnfwDgKRNhxaz+aFWp4edurNXUXqe1s+ESkCyVF+wlQ0mtEg0tbbj1k8PwcZciwtcVR65UYFyUn31R4RlCyfHcKiPnjbbWcd2fl3C+uA4xgR4or1ca/a7WkB2KXs/Dw9M76FYBaMqUKWbfyKx5WysoKGB9/umnnzpaLR4epyclqxRr92QbfV+vbMeGg7lYPScW3m7cfn7a1dr7yhYh4M8LN/Dm3sso1Wmcimu1/zfVtKCopgU7z5TATSLEB/fEm/RQbaodZ4vr6M8LN6ZBIZdh9ZxYm/Kh8nrh1/OobdZuC6bmVhmlUbZrMOHdf+zKn4eHp3fRo/wA8fDwaB/0y7Zl0sKIIaV1Sjy+LRMpWaVGvz3902k8uvUUAEBkZQj3s1UE/v3TWZPlUTS1qU2WywXVjlYD/z9ldUossyEfKq/Ht2XSwo857Mmfh4en98ELQDw8PQi1hsTaPdmwxpJl7Z5so22y1Kt6rYg1GiC1hsSvBQKryjNXLle+ptpBfWdNPlRea3ZfsLp+tubPw8PTO+EFIB6eHkRGfrVFTQxFaZ0SGfnVrO+YobBcJUKLeZy8VoPaNtvsZbjKNcRSO0gr86HyKqtvtZjO3vx5eHh6J059DJ6Hh4dNeYN1wo+p9JQo8/u/JyAuRG7F9bYJFqbKtfV3W9LZ2ieOupaHh6dnw2uAeHh6EAEetgUMNUxvazT0AA/uk2S2lmvr77aks7VPHHUtDw9Pz4YXgHh4ehCjI3ygkFv30A7ylGF0hA/rO0r+sTYo6Mgwb3hJSJtc9SjkxuUaQrXDVL6ElflQeQV52iao2ZI/Dw9P74QXgHh4ehBCAYHVc2KtEkheunWAkaEz9emBTRn4/IDp8DDM8u4I17CutcTqObEWDaypdnDlS322Jh8qrzVzB1lZO9vz5+Hh6Z3wAhAPTw8jMU6B9YuGW9QEJQ0ONvqO0KmA6lpUuFTWYPQ7F/G+JD69Nx5BFspzkwqxYdFwq/3rUO0wzDdILsN6G/Kh8tqwaDi8XC27wbcnfx4ent4HbwTNw9MDSYxTYEZsEDLyq7H4m3S0qUm8lDQQLhIhXv4tCwDApdw4+vxUbDqajzf+uGiTJ+hZgwIxe0gIMvKrUd6ghI+LBNll9Th1rQZuEiHuGN7HLk/QzHaUNygR4CGz2xM0lVdabhXu35TO+m3FjBj09XXtUP48PDy9C14A4uHpoQgFBBIifdGm8+wc4u2CyTH+qG1ug1qj1/YwIQgCKjs8QTPLo5jY3zHhZQzz7Whe7SSJ6AB35JQ30t/HBnti2sBAh5TBw8PTO+AFIB6eXsLfF28gabACT94SbTadvbHAegrfHM1nCT+A7affeHh4ej+8AMTD00sI9JQht6IRGfnVUMhlmNI/wCjNmt0XsOVYAQD7osH3BLjaJeilbeXh4bEf3giah6eHMydea+zs7y7FsauVWPXreby6izs0xOErFfTfvVUDxKXtEfIaIB4eHgN4AYiHp4dD+fQREEBxbQsAoLC6mTsxQw4QWhkMtafBJdf1UlmPh4enA/BbYDw8PZwruuPsLSoNLEUtpeSAnx4dizG91Amg4RbYz48loH+QRzfVhoeHx1npna+APDw3EZTBb3ZpvUUPz9T2EElynxLrDTC3wPw9pBgd4QO5i2X/QDw8PDcXvADEw9NLIEkSliJcULIBaWUojJ4I0+D5zdvjurEmPDw8zgwvAPHw9GDUGr0gE+AhRZtaQ38+nlvF+l2tIdHc2g4AWLw5Ax/+eZn1e2/hkQkR9N+rd2Vh1seH8dG+K2hr15i5ioeH52aDtwHi4emhpGSVYu2ebPrzN6kFrLhaCzemQSGX0TG3Xvj1PGqbVQAAlZrEfw9cxXfp1/DOHYN7VViIsroWENCaQ5XWt6K0vhWXyxrw339y8OjECKxKiu3uKvLw8DgBvADEw9MDSckqxbJtmUY2z4afy+qUeHxbpsl8aptVeHxbpk0xvJyZlKxSk+0lSeDLw/kAwAtBPDw8/BYYD09PQ60hsXZPtqUDXwAsHgqjWbsnu8dvh6k1JFbvyrKYbuORfH47jIeHhxeAeHh6Ghn51SitUzo0z9I6JTLyqx2aZ1eTkV+NGw1tFtNpSGDr8YLOrxAPD49Tw2+B8fD0MMobHCv8dHa+XYUt9b9mylFkF6DRaNDWZllQ6wxUKhVEIhGUSiXUanW31KGzuRnaCNwc7eRqo1gshlAodEj+vADEw9PDCPCQ9ah8uwpb6h/m49qJNTFNW1sb8vPzodF0zxYcSZIICgpCUVFRr/UDdTO0Ebg52mmqjV5eXggKCupwu3kBiIenhzE6wgcKuQxldUqrbXwsoZDLMLqHe4YeHeGDQA+JxW0wAQE8kBDeNZViQJIkSktLIRQKERoaCkE3hCLRaDRobGyEu7t7t5TfFdwMbQRujnYatpEkSTQ3N6O8vBwAoFB07OAGLwDx8PQwhAICq+fEYtm2TPq4tyks/U6xek5sj48OLxQQWDsvzuypNwBYOjECElHXPzDa29vR3NyM4OBguLp2jwaK2n6TyWS9+qHZ29sI3Bzt5Gqji4sLAKC8vBwBAQEd2g7rnb3Gw9PLSYxTYP2i4QiSs7d9DGWYILkMGxYNx4ZFw+HlahwOwttV3GuOwAPafpk2IIDzN4IAHpvUfX6AKBsGiUTSLeXz8PQWqBcIlUrVoXx4DRAPTw8lMU6BGbFByMivRnmDEgEeMowI88apazX059ERPrRmZ0ZsEB7anI4jOVVI6OeDJ2+Jxth+vj1e82NIVIA79l/Sqsin9veHWCjAqHAfLB4X3i2aH0N6q70GD09X4ah7iBeAeHh6MEIBgYRIX9Z3hp+Zafv6uAGowvG8arxzp0uvE34AYE58ML48nAcAeHbWAMQGe3ZzjXg6E4IgsHPnTtx+++3dXRWz9JR63kx0/+sQDw9PlyEV6ffLG5Tt3ViTziMuRA5fN+02U280jVBrSBzPrcKuM9eN4r11JsePH4dQKMStt95q87Xh4eH4+OOPHV8pK3jooYdAEAQIgoBEIkFUVBRee+01tLf3zPm/Y8cOTJkyBd7e3ujTpw+GDh2K1157DdXVXevHa82aNRg6dGiXluloeuHywMPDY4r/zIim/5aJe+/t7yIRwk0ihKiXabhSskox4d1/sHBjGp7+6QwWbkzDhHf/QUpWaaeXvWnTJvz73//G4cOHUVJS0unlOZLExESUlpYiJycHK1aswJo1a7Bu3brurpbNvPTSS1iwYAFGjRqFP/74A8eOHcO6detw9uxZbN26tbur1+PovSsgDw+PER4yMVzEWi0QUxvUm8iraMQrt8Vi+2MJiArw6O7qOAwq/puhF/CyOiWWbcvsVCGosbER27dvx7Jly3Drrbdiy5YtRmn27NmDUaNGQSaTwc/PD/PnzwcATJkyBdeuXcN//vMfWhMDcGsQPv74Y4SHh9OfT5w4gRkzZsDPzw9yuRyTJ09GZqb5U35cSKVSBAUFISwsDMuWLcP06dOxe/duAEBraytWrlyJkJAQuLm5YcyYMTh48CDr+h07dmDQoEGQSqUIDw/HBx98wPo9PDwcr7/+OhYuXAg3NzeEhITg888/N1unoqIi3HPPPfDy8oKPjw/mzZuHgoICk+kzMjLw1ltv4YMPPsC6deswbtw49O3bFzNmzMCOHTuwePFiOu369esRGRkJiUSC/v37s4SjgoICEASBM2fO0N/V1taCIAi63QcPHgRBENi/fz9GjhwJV1dXjBs3DpcvXwYAbNmyBWvXrsXZs2fpMeWaE84OLwDx8NxktLZrTyNJncAguDP4/VwpHtt6Ct+nF3Z3Vayiua3d5D+lSjtW5uK/Ud+tMYjnZipPe/j5558xYMAA9O/fH4sWLcI333wDktSX9ccff2D+/PlISkrC6dOnsX//fowePRoA8Ouvv6JPnz547bXXUFpaitJS6wW1hoYGLF68GEePHkVaWhqio6ORlJSEhoYGu9pB4eLiQnvjfvLJJ3H8+HH89NNPOHfuHO6++24kJiYiJycHAHDq1Cncc889uPfee3H+/HmsWbMGr7zyitEDf926dYiPj8fp06fxwgsv4Omnn8a+ffs4y1epVJg1axY8PDxw5MgRpKamwt3dHYmJiSa9hH///fdwd3fH//3f/3H+7uXlBQDYuXMnnn76aaxYsQJZWVl47LHHsGTJEhw4cMDmfnrppZfwwQcf4OTJkxCJRHj44YcBAAsWLMCKFSswaNAgekwXLFhgc/7dDW8EzcNzE3HsaiWoZ2Rv1QBRht2aHhLcNfbVP03+NrW/PzYvGW0x/hsJrSYoI7+aNoKf8O4BVDcZP0zPvDDe5jpu2rQJixYtAqDdTqqrq8OhQ4cwZcoUAMCbb76Je++9F2vXrqWviY+PBwD4+PhAKBTCw8MDQUFBNpV7yy23sD5/9dVX8PLywqFDh3DbbbfZ3A6SJLF//378+eef+Pe//43CwkJs3rwZhYWFCA4OBgCsXLkSKSkp2Lx5M9566y18+OGHmDZtGl555RUAQExMDLKzs7Fu3To89NBDdN7jx4/HCy+8QKdJTU3FRx99hBkzZhjVY/v27dBoNPj6669pjdjmzZvh5eWFgwcPYubMmUbX5OTkoF+/fhCLjd1ZMHn//ffx0EMP0YLS8uXLkZaWhvfffx9Tp061qb/efPNNTJ48GQDwwgsv4NZbb4VSqYSLiwvc3d0hEolsHlNnone+AvLw8HByoaSe/lvaS22AqBOy208WobKxtXsr4yCsjXPWGfHcLl++jIyMDCxcuBAAIBKJsGDBAmzatIlOc+bMGUybNs3hZd+4cQNLly5FdHQ05HI5PD090djYiMJC27R7v//+O9zd3SGTyTB79mwsWLAAa9aswfnz56FWqxETEwN3d3f636FDh5CbmwsAuHjxIsaPZwuN48ePR05ODisGV0JCAitNQkICLl68yFmfs2fP4urVq/Dw8KDL9PHxgVKppMs1hKlxM4ep+pqqizmGDBlC/015Xaa8MPcGeA0QD89NhIaxiGZeq8GYXugHSMjwEdLW3j0xt2wh+7VZJn8T6NpibZwzZrqjzxu/7Ws0GrQrbQsEu2nTJrS3t9MaEkD7MJZKpfjss88gl8tp77y2QIU2YGLo2G7x4sWoqqrCJ598grCwMEilUiQkJNgcTHbq1KlYv349JBIJgoODIRJpH32NjY0QCoU4deqUkUdhd3d3m9tkLY2NjRgxYgS+//57o9/8/f05r4mJicHRo0ehUqksaoHMQXlUZva9KYeCzHIoTVV3xbHrDLr1FfDw4cOYM2cOgoODQRAEfvvtN9bvJEni1VdfhUKhgIuLC6ZPn07vy5rj888/R3h4OGQyGcaMGYOMjIxOagEPT88hJasU6w/q3y7v+zq9y04QdSVMga4nCHeuEpHJfzKdwToV/81UawgYx3MzlacttLe347vvvsMHH3yAM2fO0P/Onj2L4OBg/PjjjwC0moL9+/ebzEcikRhFLPf390dZWRnrQcw0zAWA1NRUPPXUU0hKSqKNkCsrK21qAwC4ubkhKioKffv2pYUfABg2bBjUajXKy8sRFRXF+kdt7QwcOBCpqalG9YqJiWEJTWlpaaw0aWlpGDhwIGd9hg8fjpycHAQEBBiVK5fLOa+577770NjYiC+++ILz99raWrP1jY3VekCnBCymLZZhv1sD15j2NLpVAGpqakJ8fLxJa/n33nsP//3vf7Fhwwakp6fDzc0Ns2bNglJpWs27fft2LF++HKtXr0ZmZibi4+Mxa9asXqW24+GxFeoEUW0L+02vK04QdTVML7GCXuJ1mYr/BsBICKI+d0Y8t99//x01NTV45JFHEBcXx/p355130ttgq1evxo8//ojVq1fj4sWLOH/+PN599106n/DwcBw+fBjXr1+nBZgpU6agoqIC7733HnJzc/H5559j7969rPKjo6OxdetWXLx4Eenp6bj//vvt0jaZIiYmBvfffz8efPBB/Prrr8jPz0dGRgbefvtt/PHHHwCAFStWYP/+/Xj99ddx5coVfPvtt/jss8+wcuVKVl6pqal47733cOXKFXz++ef43//+h6effpqz3Pvvvx9+fn6YN28ejhw5gvz8fBw8eBBPPfUUiouLOa8ZM2YMnnvuOaxYsQLPPfccjh8/jsLCQuzfvx933303vv32WwDAs88+iy1btmD9+vXIycnBhx9+iF9//ZWur4uLC8aOHYt33nkHFy9exKFDh/Dyyy/b3Hfh4eHIz8/HmTNnUFlZidbWHrjdTDoJAMidO3fSnzUaDRkUFESuW7eO/q62tpaUSqXkjz/+aDKf0aNHk0888QT9Wa1Wk8HBweTbb79tdV3q6upIAGRdXZ1tjbCCtrY28rfffiPb2tocnrezcDO0kSR7Tjvb1Rpy7Ft/k2HP/875L/z538mxb/1Ntqs1Rtf2lDYy+eZoHt22ygalVdd0RTtbWlrI7OxssqWlxe489p4vMRrLsW/9Te49X2LV9Wq1mqypqSHVarVV6W+77TYyKSmJ87f09HQSAHn27FmSJElyx44d5NChQ0mJREL6+fmRd9xxB532+PHj5JAhQ0ipVEoyHzvr168nQ0NDSTc3N/LBBx8k33zzTTIsLIz+PTMzkxw5ciQpk8nI6Oho8n//+x8ZFhZGfvTRR3Qaw2eHYRsXL15Mzps3z2Qb29rayFdffZUMDw8nxWIxqVAoyPnz55Pnzp2j0/zyyy9kbGwsKRaLyb59+7KeSyRJkmFhYeTatWvJu+++m3R1dSWDgoLITz75hJXGsJ6lpaXkgw8+SPr5+ZFSqZTs168fuXTpUovPne3bt5OTJk0iPTw8SDc3N3LIkCHka6+9RtbU1NBpvvjiC7Jfv36kWCwmY2JiyO+++46VR3Z2NpmQkEC6uLiQQ4cOJf/66y8SAHngwAGSJEnywIEDJABWnqdPnyYBkPn5+SRJkqRSqSTvvPNO0svLiwRAbt682Wy97cHUfDV3L9ny/CZI0krLqk7G0E14Xl4eIiMjcfr0aZaviMmTJ2Po0KH45JNPjPJoa2uDq6srfvnlF5a78cWLF6O2tha7du3iLLu1tZUlvdbX1yM0NBSVlZXw9HSsG32VSoV9+/ZhxowZHdrHdWZuhjYCPaed6fnVWPTNSYvptj08EmMYWyhAz2kjk4ulDZj7xXEAwIlVUzmDwBrSFe1UKpUoKiqit+ftRa0hcaKgGuUNrQjwkGJUuI/Vmh+SJNHQ0AAPD49eG5OsO9rYr18/PP300yY1Pp3BzTyWSqUSBQUFCA0NNbqX6uvr4efnh7q6OovPb6c1gi4rKwMABAYGsr4PDAykfzOksrISarWa85pLly6ZLOvtt99mHd+k+Ouvv+ios47GlH+I3sTN0EbA+dt5qpIAYPnI+19H0lF1kft9yNnbyERr96xd2v7+ex9cbVjlOrOd1JHhxsZGm414DYn1EyPWTyuoNTXa7hOno350egJd2UaNRgOlUon6+nrLiR3MzTiWbW1taGlpweHDh41CmjQ3W2/k77QCUFeyatUqLF++nP5MaYBmzpzJa4Ds4GZoI9Bz2umbX43vcixrgGZOHNMrNEBKlRqiE/9ATZJInDUT7lLLy1xXaoCo49jdwc2sNehMBAIBZDKZw58X5riZx5LyRTRp0iRODZC1OK0ARFng37hxg/Y/QH02FYDNz88PQqEQN27cYH1/48YNs86apFIppFKp0fdisbjTFsPOzNtZuBnaCDh/OxOiAqCQy1BWp+T0JEwACJLLkBAVYHIrxdnbyKS6RY3NS0bB21UCb3fbDGY7s51qtRoEQUAgENBHkbsa6ggzVY/eSHe00VwIi87iZh5LgUAAgiA471db7l+n7bWIiAgEBQWxjlbW19cjPT3dyOEUhUQiwYgRI1jXaDQa7N+/3+Q1PDy9ne46QdRdHL5SgQc2ZeD9vy53d1V4eHicmG4VgBobG2m/EgDoI3WFhYUgCALPPPMM3njjDezevRvnz5/Hgw8+iODgYJaB87Rp0/DZZ5/Rn5cvX46NGzfi22+/xcWLF7Fs2TI0NTVhyZIlXdw6Hh7nITFOgfWLhiNIzlYXB8llWL9oOBLjFCau7HlQgpy6h4TC4OHh6R66dQvs5MmTrNgklB3O4sWLsWXLFjz33HNoamrCo48+itraWkyYMAEpKSmsPb/c3FyWY6wFCxagoqICr776KsrKyjB06FCkpKQYGUbz8NxsJMYpMCM2CBn51ShvUCLAQ+s4r7dofiia2rTO2Y7kVEKjISHoZe3j4eFxDN0qAE2ZMsVsfBOCIPDaa6/htddeM5mGa+/1ySefxJNPPumIKvLw9CqEAoIOltlbaVfrXfX3UttQHh4eB+C0NkA8/9/e/cdFVeX/A38NAzMwDDAKwoDxU8QfgYS/EMlVkw3MVVNrNVFgMUvFgFRELX/lIribpvY1dMvAX4laSoakIQoKK6gIKAqIiMoaRuUiIAIDcz5/8OVuV34rDDjzfj4e83jIPWfOPe97YebtveeeQwh5Xur6dAwh5PlRAkQIIYQQjUMJECFErfSMue3Js/Dz8+M95DJu3DgEBwervB9JSUkQCATcAqM9VUpKCoRCYY/vZ09FCRAhRK04mBl0dxe6Rlkx8HNWy6+y4i7ZrZ+fHwQCAQQCAUQiEezt7fHJJ580mYG3Kxw9ehQbNmxoV11VJy02NjbccdHX18fQoUNx5MgRley7s9XW1uIf//gHnJ2dIZFIYGJiAnd3d0RFRUGhULTdQCdSZdLbYydCJISQZ/FSr4bJD9szA/QLo6wY+H/DgLpWVtzWFgOLMwCZZafv3svLC1FRUaipqUF8fDwCAgKgo6ODlStXNqlbW1sLkUjUKfvt3bt325W60SeffIL58+ejvLwcmzdvxsyZM9G3b1+MHj26u7vWbrW1tfD09ER2djY2bNgAd3d3GBoaIi0tDZ9++ilcXFxanHz4RUdXgAghakX5/++BqdXT71W/t578AA3lVb93ye7FYjHkcjmsra2xcOFCeHh44Pjx4wD+d9sqLCwMFhYWGDBgAACguLgYf/3rXyGTydC7d29MnTqV99RufX09lixZAplMBmNjYyxfvrzJU8FPXw2oqalBaGgoLC0tIRaLYW9vj927d+POnTvclCrGxsbo1asXN/ebUqlEeHg4bG1toaenB2dnZ3z77be8/cTHx8PBwQF6enoYP358u2d2NjAwgFwuh4ODA3bs2AE9PT388MMP7YpfqVTik08+wUsvvQSxWMxN2dLozp07EAgEiImJwejRo6GrqwtHR0ckJye32qeUlBSMGTMGenp6sLS0RGBgIB4/ftxi/a1bt+LcuXNITExEQEAAXnnlFdjZ2WH27NlIT09H//79uWMfGBgIU1NT6Orq4tVXX8WlS5e4dqKjoyGTyXhtx8bG8h5EWLduHV555RXs27cPNjY2MDIywqxZs7i1vvz8/JCcnIxt27ZBIBBAKBTi3r17rZ+E50AJECFErRhLxTg4fxSi/jayu7vSOsaA2sfte9U9aV+bdU/abktR9dwDpfT09HgLuiYmJiI/Px8JCQmIi4uDQqGAp6cnDAwMcP78eaSmpkIqlcLLy4t73+bNmxEdHY2vv/4aKSkpePjwIY4dO9bqfn18fHDw4EFs374dubm52LVrF6RSKSwtLfHdd98BAHJzc5GXl4etW7cCaFjseu/evdi5cyeuX7+ODz/8EHPmzOESieLiYkyfPh2TJ09GVlYW3n33XaxYsaLDx0RbWxs6Ojqora1tV/zbtm3D5s2b8emnn+Lq1avw9PTElClTUFBQwGs3JCQES5cuRWZmJtzc3DB58mT8/nvziW5hYSG8vLwwY8YMXL16FYcOHUJKSkqr08IcOHAAHh4ecHFxaVKmo6MDfX19AMDy5cvx3XffYc+ePbhy5Qrs7e3h6emJhw8fdug4FRYWIjY2FnFxcYiLi0NycjIiIiK4Y+Lm5ob58+ejpKQE9+/fR9++fTvUfkeo0TViQggBrhaXYe7XF2FuqIstM1/puZM9KqqAjRad2+bXXq0WawGQAVCu+A8g7PhYKcYYEhMTcerUKXzwwQfcdn19fXz11Vfcra/9+/dDqVTiq6++4q4AREVFQSaTISkpCa+//jq2bt2KlStXYvr06QCAnTt34tSpUy3u++bNmzh8+DASEhLg4eEBALCzs+PKG2+XmZqaQktLC4aGhqipqcHGjRtx+vRpbjkkOzs7pKSkYNeuXRg7diwiIyPRr18/bN68GQAwYMAAXLt2DZs2bWr3camtrcXmzZvx6NEjvPbaazh06FCb8X/66acIDQ3FrFmzAACbNm3C2bNnsXXrVuzYsYNre/HixZgxYwYAIDIyEidPnsTu3buxbNmyJv0IDw+Ht7c3d9Wsf//+2L59Oxdnc4vwFhQUYNy4ca3G9/jxY0RGRiI6OhoTJ04EAHz55ZdISEjA7t27ERIS0u5jpVQqER0dDQODht+/uXPnIjExEWFhYTAyMoJIJIJEIoFcLodSqezQ4qYdRQkQIURtnMwpwapjOQCAkvJqvPNlGsyNdLF28mC1Wu5D1eLi4iCVSqFQKKBUKjF79mysW7eOK3dycuKN+8nOzsatW7e4L7lG1dXVKCwsxKNHj1BSUgJXV1euTFtbG8OHD29xctysrCwIhUKMHTu23f2+desWqqqq8Oc//5m3vba2lrvikZuby+sHgHavHRkaGoqPP/4Y1dXVkEqliIiIwKRJkxASEtJq/OXl5fj555/h7u7OK3d3d0d2dnaLfWk8Rrm5uc32Jzs7G1evXsWBAwe4bYwxKJVKFBUVYdCgQU3e09pkxI0KCwuhUCh4/dXR0cHIkSNb7EtLbGxseMfF3NwcpaWlHWqjs1ACRAhRCydzSrBw/5UmK94/eFSNhfuv9Lw1z3QkwKqf21f3wdU2r+4AAPxPAvIhLRYrlUqUV1TAUEfSzk42GD9+PCIjIyESiWBhYQFtbf5XR+NtkkaVlZUYNmwY74u4UZ8+fTq070Z6enodfk9lZSUA4MSJE01upYjF4mfqxx+FhITAz88PUqkUZmZm3NWeroi/PSorK/H+++8jMDCwSZmVlVWz73FwcEBeXt5z71tLS6tJMtXcE2RPr9YuEAi4Vd9VjcYAEUJeePVKhvU/3GiS/ADgtq3/4UbPWiBVIABE+u17abfzy19br+22dCQdXiNEX18f9vb2sLKyapL8NGfo0KEoKCiAqakp7O3teS8jIyMYGRnB3Nwc6enp3Hvq6uqQkZHRYptOTk5QKpUtDgJuvAJVX1/PbRs8eDDEYjHu3bvXpB+Wlg1Pyw0aNAgXL17ktZWWltZmjABgYmICe3t7yOVy3mDftuI3NDSEhYUFUlNTee2lpqZi8ODBLfal8Rg1dyWncb83btxosk97e/sWn8ybPXs2Tp8+jczMzCZlCoUCjx8/Rr9+/SASiXj9VSgUuHTpEtffPn36oKKigjfgunGh844QiUS8c9iVKAEihLzwLhY9RMmj6hbLGYCSR9W4WNSxAZvk2Xh7e8PExARTp07F+fPnUVRUhKSkJAQGBuI///kPACAoKAgRERGIjY1FXl4eFi1a1OocPjY2NvD19YW/vz9iY2O5Ng8fPgwAsLa2hkAgQFxcHH777TdUVlbCwMAAy5Ytw4cffog9e/agsLAQV65cweeff449e/YAABYsWICCggKEhIQgPz8f33zzDaKjo7s8/pCQEGzatAmHDh1Cfn4+VqxYgaysLAQFBfHa2rFjB44dO4a8vDwEBATgv//9L/z9/Zvdb2hoKP79739j8eLFyMrKQkFBAb7//vtWB0EHBwfD3d0dEyZMwI4dO5CdnY3bt2/j8OHDGDVqFAoKCqCvr4+FCxciJCQEJ0+exI0bNzB//nxUVVVh3rx5AABXV1dIJBKsWrUKhYWFz3wcbWxskJ6ejjt37uC3337r0qtDlAARQl54pRUtJz/PUq/HkRg3zPPTGm1xQ70eQCKR4Ny5c7CyssL06dMxaNAgzJs3D9XV1TA0NAQALF26FHPnzoWvry/c3NxgYGCAadOmtdpuZGQk3nrrLSxatAgDBw7E/PnzuSsOffv2xfr167Fq1So4ODhwg7Q3bNiA1atXIzw8HIMGDYKXlxdOnDgBW1tbAA23hr777jvExsbC2dkZO3fuxMaNG7s8/sDAQCxZsgRLly6Fk5MTTp48iePHj3OPnTeKiIhAREQEnJ2dkZKSguPHj8PExKTZ/Q4ZMgTJycm4efMmxowZAxcXF6xZswYWFi0PtheLxUhISMDy5cuxa9cujBo1CiNGjMD27dsRGBgIR0dHrh8zZszA3LlzMXToUNy6dQunTp1Cr169ADQMQt+/fz/i4+Ph5OSEgwcP8saJtdeyZcsgFAoxePBgmJmZcQljVxCw9oyA0jDl5eUwMjLCo0ePuF/WzqJQKBAfH4833nijyb1QdaEJMQKaEeeLEuOFwt/xzpdt37Y4OH8U3Po1TRJUEWd1dTWKiopga2vb7NM4bSorbn2eH4lxm5MgNj5VY2hoCC0t9fz/r7rEeOfOHdja2iIzM7PZiQjVJc7WtBRja39LHfn+pkHQhJAX3kjb3jA30sWDR9XNjgMSAJAb6WKkbc+eWbhVMssumeWZEE2lnmkjIUSjCLUEWDu5YTDm08N7G39eO3lwz5wPiBDSLSgBIoSoBS9Hc0TOGQq5Ef+SuNxIt+c9Ak9IG2xsbMAYU9t1uHoCugVGCFEbXo7m+PNgOS4WPURpRTVMDXR77kzQhJBuRQkQIUStCLUEzQ50JoSQP6JbYIQQokL04C0hz6ez/oYoASKEEBUQCoUAwFtFnRDScVVVVQCaLqvRUXQLjBBCVEBbWxsSiQS//vordHR0umXuFqVSidraWlRXV6v13DHqHiOgGXE+HSNjDFVVVSgtLYVMJuP+U/GsKAEihBAVEAgEMDc3R1FREe7evdstfWCM4cmTJ9DT0+OtXaVONCFGQDPibClGmUwGuVz+3O1TAkQIISoiEonQv3//brsNplAocO7cOfzpT3/q0TN7Pw9NiBHQjDibi1FHR+e5r/w0ogSIEEJUSEtL69mWwugEQqEQdXV10NXVVdsvTU2IEdCMOLs6RvW8cUgIIYQQ0gpKgAghhBCicSgBIoQQQojGoTFAzWicZKm8vLzT21YoFKiqqkJ5ebna3rfVhBgBzYhTE2IEKE51ogkxApoR57PE2Pi93Z7JEikBakZFRQUAwNLSspt7QgghhJCOqqiogJGRUat1BIzmZW9CqVTi559/hoGBQafPr1BeXg5LS0sUFxfD0NCwU9vuKTQhRkAz4tSEGAGKU51oQoyAZsT5LDEyxlBRUQELC4s2J4ikK0DN0NLSwksvvdSl+zA0NFTbX9pGmhAjoBlxakKMAMWpTjQhRkAz4uxojG1d+WlEg6AJIYQQonEoASKEEEKIxqEESMXEYjHWrl0LsVjc3V3pMpoQI6AZcWpCjADFqU40IUZAM+Ls6hhpEDQhhBBCNA5dASKEEEKIxqEEiBBCCCEahxIgQgghhGgcSoAIIYQQonEoAVKhHTt2wMbGBrq6unB1dcXFixe7u0sdcu7cOUyePBkWFhYQCASIjY3llTPGsGbNGpibm0NPTw8eHh4oKCjg1Xn48CG8vb1haGgImUyGefPmobKyUoVRtC48PBwjRoyAgYEBTE1N8eabbyI/P59Xp7q6GgEBATA2NoZUKsWMGTPwyy+/8Orcu3cPkyZNgkQigampKUJCQlBXV6fKUFoUGRmJIUOGcJOLubm54ccff+TKX/T4mhMREQGBQIDg4GBumzrEuW7dOggEAt5r4MCBXLk6xNjo/v37mDNnDoyNjaGnpwcnJydcvnyZK1eHzx8bG5sm51MgECAgIACAepzP+vp6rF69Gra2ttDT00O/fv2wYcMG3tpdKjuXjKhETEwME4lE7Ouvv2bXr19n8+fPZzKZjP3yyy/d3bV2i4+PZx999BE7evQoA8COHTvGK4+IiGBGRkYsNjaWZWdnsylTpjBbW1v25MkTro6XlxdzdnZmaWlp7Pz588ze3p698847Ko6kZZ6eniwqKorl5OSwrKws9sYbbzArKytWWVnJ1VmwYAGztLRkiYmJ7PLly2zUqFFs9OjRXHldXR1zdHRkHh4eLDMzk8XHxzMTExO2cuXK7gipiePHj7MTJ06wmzdvsvz8fLZq1Sqmo6PDcnJyGGMvfnxPu3jxIrOxsWFDhgxhQUFB3HZ1iHPt2rXs5ZdfZiUlJdzr119/5crVIUbGGHv48CGztrZmfn5+LD09nd2+fZudOnWK3bp1i6ujDp8/paWlvHOZkJDAALCzZ88yxtTjfIaFhTFjY2MWFxfHioqK2JEjR5hUKmXbtm3j6qjqXFICpCIjR45kAQEB3M/19fXMwsKChYeHd2Ovnt3TCZBSqWRyuZz985//5LaVlZUxsVjMDh48yBhj7MaNGwwAu3TpElfnxx9/ZAKBgN2/f19lfe+I0tJSBoAlJyczxhpi0tHRYUeOHOHq5ObmMgDswoULjLGGRFFLS4s9ePCAqxMZGckMDQ1ZTU2NagNop169erGvvvpK7eKrqKhg/fv3ZwkJCWzs2LFcAqQuca5du5Y5Ozs3W6YuMTLGWGhoKHv11VdbLFfXz5+goCDWr18/plQq1eZ8Tpo0ifn7+/O2TZ8+nXl7ezPGVHsu6RaYCtTW1iIjIwMeHh7cNi0tLXh4eODChQvd2LPOU1RUhAcPHvBiNDIygqurKxfjhQsXIJPJMHz4cK6Oh4cHtLS0kJ6ervI+t8ejR48AAL179wYAZGRkQKFQ8OIcOHAgrKyseHE6OTnBzMyMq+Pp6Yny8nJcv35dhb1vW319PWJiYvD48WO4ubmpXXwBAQGYNGkSLx5Avc5jQUEBLCwsYGdnB29vb9y7dw+AesV4/PhxDB8+HG+//TZMTU3h4uKCL7/8kitXx8+f2tpa7N+/H/7+/hAIBGpzPkePHo3ExETcvHkTAJCdnY2UlBRMnDgRgGrPJS2GqgK//fYb6uvreb+UAGBmZoa8vLxu6lXnevDgAQA0G2Nj2YMHD2Bqasor19bWRu/evbk6PYlSqURwcDDc3d3h6OgIoCEGkUgEmUzGq/t0nM0dh8aynuDatWtwc3NDdXU1pFIpjh07hsGDByMrK0st4gOAmJgYXLlyBZcuXWpSpi7n0dXVFdHR0RgwYABKSkqwfv16jBkzBjk5OWoTIwDcvn0bkZGRWLJkCVatWoVLly4hMDAQIpEIvr6+avn5Exsbi7KyMvj5+QFQn9/ZFStWoLy8HAMHDoRQKER9fT3CwsLg7e0NQLXfJZQAEdKCgIAA5OTkICUlpbu70ukGDBiArKwsPHr0CN9++y18fX2RnJzc3d3qNMXFxQgKCkJCQgJ0dXW7uztdpvF/zQAwZMgQuLq6wtraGocPH4aenl439qxzKZVKDB8+HBs3bgQAuLi4ICcnBzt37oSvr283965r7N69GxMnToSFhUV3d6VTHT58GAcOHMA333yDl19+GVlZWQgODoaFhYXKzyXdAlMBExMTCIXCJqP1f/nlF8jl8m7qVedqjKO1GOVyOUpLS3nldXV1ePjwYY87DosXL0ZcXBzOnj2Ll156idsul8tRW1uLsrIyXv2n42zuODSW9QQikQj29vYYNmwYwsPD4ezsjG3btqlNfBkZGSgtLcXQoUOhra0NbW1tJCcnY/v27dDW1oaZmZlaxPk0mUwGBwcH3Lp1S23OJQCYm5tj8ODBvG2DBg3ibvep2+fP3bt3cfr0abz77rvcNnU5nyEhIVixYgVmzZoFJycnzJ07Fx9++CHCw8MBqPZcUgKkAiKRCMOGDUNiYiK3TalUIjExEW5ubt3Ys85ja2sLuVzOi7G8vBzp6elcjG5ubigrK0NGRgZX58yZM1AqlXB1dVV5n5vDGMPixYtx7NgxnDlzBra2trzyYcOGQUdHhxdnfn4+7t27x4vz2rVrvD/QhIQEGBoaNvkQ7ymUSiVqamrUJr4JEybg2rVryMrK4l7Dhw+Ht7c39291iPNplZWVKCwshLm5udqcSwBwd3dvMh3FzZs3YW1tDUB9Pn8aRUVFwdTUFJMmTeK2qcv5rKqqgpYWP/UQCoVQKpUAVHwun2MwN+mAmJgYJhaLWXR0NLtx4wZ77733mEwm443W7+kqKipYZmYmy8zMZADYli1bWGZmJrt79y5jrOHRRZlMxr7//nt29epVNnXq1GYfXXRxcWHp6eksJSWF9e/fv0c9hrpw4UJmZGTEkpKSeI+jVlVVcXUWLFjArKys2JkzZ9jly5eZm5sbc3Nz48obH0V9/fXXWVZWFjt58iTr06dPj3kUdcWKFSw5OZkVFRWxq1evshUrVjCBQMB++uknxtiLH19L/vgUGGPqEefSpUtZUlISKyoqYqmpqczDw4OZmJiw0tJSxph6xMhYw1QG2traLCwsjBUUFLADBw4wiUTC9u/fz9VRh88fxhqeELaysmKhoaFNytThfPr6+rK+fftyj8EfPXqUmZiYsOXLl3N1VHUuKQFSoc8//5xZWVkxkUjERo4cydLS0rq7Sx1y9uxZBqDJy9fXlzHW8Pji6tWrmZmZGROLxWzChAksPz+f18bvv//O3nnnHSaVSpmhoSH729/+xioqKrohmuY1Fx8AFhUVxdV58uQJW7RoEevVqxeTSCRs2rRprKSkhNfOnTt32MSJE5menh4zMTFhS5cuZQqFQsXRNM/f359ZW1szkUjE+vTpwyZMmMAlP4y9+PG15OkESB3inDlzJjM3N2cikYj17duXzZw5kzc3jjrE2OiHH35gjo6OTCwWs4EDB7J//etfvHJ1+PxhjLFTp04xAE36zph6nM/y8nIWFBTErKysmK6uLrOzs2MfffQR7zF9VZ1LAWN/mH6REEIIIUQD0BggQgghhGgcSoAIIYQQonEoASKEEEKIxqEEiBBCCCEahxIgQgghhGgcSoAIIYQQonEoASKEEEKIxqEEiBBCVCA6OrrJSt6EkO5DCRAhpF38/PwgEAiavG7dutXdXWsXGxsbCAQCpKWl8bYHBwdj3Lhx3dMpQki3oQSIENJuXl5eKCkp4b2eXjAWAGpra7uhd23T1dVFaGhod3ejUykUiu7uAiEvJEqACCHtJhaLIZfLeS+hUIhx48Zh8eLFCA4OhomJCTw9PQEAW7ZsgZOTE/T19WFpaYlFixahsrKSa6/xtlBcXBwGDBgAiUSCt956C1VVVdizZw9sbGzQq1cvBAYGor6+nntfTU0Nli1bhr59+0JfXx+urq5ISkpqs//vvfce0tLSEB8f32KdcePGITg4mLftzTffhJ+fH/ezjY0N/v73v8PHxwdSqRTW1tY4fvw4fv31V0ydOhVSqRRDhgzB5cuXm7QfGxuL/v37Q1dXF56eniguLuaVf//99xg6dCh0dXVhZ2eH9evXo66ujisXCASIjIzElClToK+vj7CwsDbjJoQ0RQkQIaRT7NmzByKRCKmpqdi5cycAQEtLC9u3b8f169exZ88enDlzBsuXL+e9r6qqCtu3b0dMTAxOnjyJpKQkTJs2DfHx8YiPj8e+ffuwa9cufPvtt9x7Fi9ejAsXLiAmJgZXr17F22+/DS8vLxQUFLTaR1tbWyxYsAArV66EUql8rng/++wzuLu7IzMzE5MmTcLcuXPh4+ODOXPm4MqVK+jXrx98fHzwx+UWq6qqEBYWhr179yI1NRVlZWWYNWsWV37+/Hn4+PggKCgIN27cwK5duxAdHd0kyVm3bh2mTZuGa9euwd/f/7niIERjPf/aroQQTeDr68uEQiHT19fnXm+99RZjrGGldRcXlzbbOHLkCDM2NuZ+joqKYgB4K5i///77TCKR8FZ29vT0ZO+//z5jjLG7d+8yoVDI7t+/z2t7woQJbOXKlS3u29ramn322WestLSUGRgYsL179zLGGAsKCmJjx47l6j29ajxjjE2dOpX5+vry2pozZw73c0lJCQPAVq9ezW27cOECA8Ct1t0Ya1paGlcnNzeXAWDp6elcDBs3buTte9++fczc3Jz7GQALDg5uMU5CSPtod2fyRQh5sYwfPx6RkZHcz/r6+ty/hw0b1qT+6dOnER4ejry8PJSXl6Ourg7V1dWoqqqCRCIBAEgkEvTr1497j5mZGWxsbCCVSnnbSktLAQDXrl1DfX09HBwcePuqqamBsbFxmzH06dMHy5Ytw5o1azBz5sx2Rt7UkCFDeP0DACcnpybbSktLIZfLAQDa2toYMWIEV2fgwIGQyWTIzc3FyJEjkZ2djdTUVN4Vn/r6+ibHbPjw4c/cb0JIA0qACCHtpq+vD3t7+xbL/ujOnTv4y1/+goULFyIsLAy9e/dGSkoK5s2bh9raWu7LXEdHh/c+gUDQ7LbGW1aVlZUQCoXIyMiAUCjk1ftj0tSaJUuW4IsvvsAXX3zRpExLS4t32wpofqDxH/soEAha3NaRW22VlZVYv349pk+f3qRMV1eX+/fTx5oQ0nGUABFCukRGRgaUSiU2b94MLa2G4YaHDx9+7nZdXFxQX1+P0tJSjBkz5pnakEqlWL16NdatW4cpU6bwyvr06YOSkhLu5/r6euTk5GD8+PHP1W8AqKurw+XLlzFy5EgAQH5+PsrKyjBo0CAAwNChQ5Gfn99ikkkI6Tw0CJoQ0iXs7e2hUCjw+eef4/bt29i3bx83OPp5ODg4wNvbGz4+Pjh69CiKiopw8eJFhIeH48SJE+1u57333oORkRG++eYb3vbXXnsNJ06cwIkTJ5CXl4eFCxeirKzsufsNNFwh+uCDD5Ceno6MjAz4+flh1KhRXEK0Zs0a7N27F+vXr8f169eRm5uLmJgYfPzxx52yf0LI/1ACRAjpEs7OztiyZQs2bdoER0dHHDhwAOHh4Z3SdlRUFHx8fLB06VIMGDAAb775Ji5dugQrK6t2t6Gjo4MNGzagurqat93f3x++vr7w8fHB2LFjYWdn1ylXf4CG8U6hoaGYPXs23N3dIZVKcejQIa7c09MTcXFx+OmnnzBixAiMGjUKn332GaytrTtl/4SQ/xGwp292E0IIIYSoOboCRAghhBCNQwkQIYQQQjQOJUCEEEII0TiUABFCCCFE41ACRAghhBCNQwkQIYQQQjQOJUCEEEII0TiUABFCCCFE41ACRAghhBCNQwkQIYQQQjQOJUCEEEII0TiUABFCCCFE4/wfEttGmta6F5QAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot actual data\n",
        "plt.plot(df[\"Frame\"], df[\"People Count\"], label=\"Actual People Count\", marker='o', linestyle='dashed')\n",
        "\n",
        "# Plot predicted data\n",
        "plt.plot(future_df[\"Frame\"], future_df[\"Predicted People Count\"], label=\"Predicted People Count\", marker='s', linestyle='solid')\n",
        "\n",
        "plt.xlabel(\"Frame Number\")\n",
        "plt.ylabel(\"People Count\")\n",
        "plt.title(\"Predicted vs Actual People Count\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "KBY5kNJBK_by"
      },
      "outputs": [],
      "source": [
        "alert_threshold = 30  # Set congestion limit\n",
        "\n",
        "for index, row in future_df.iterrows():\n",
        "    if row[\"Predicted People Count\"] > alert_threshold:\n",
        "        print(f\"⚠️ ALERT! High crowd expected at Frame {row['Frame']}: {row['Predicted People Count']} people\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-KvyZe7K_NE",
        "outputId": "dd92b543-1a51-4ba5-f4f5-5524f7cf10a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Frame  People Count  Staff Allocated\n",
            "0      0            13                2\n",
            "1      1            13                2\n",
            "2      2            16                2\n",
            "3      3            15                2\n",
            "4      4            17                2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"people_count_log.csv\")\n",
        "\n",
        "# Define a function to allocate staff based on predicted crowd size\n",
        "def allocate_resources(predicted_crowd):\n",
        "    if predicted_crowd <= 30:\n",
        "        return 2  # Minimum staff needed\n",
        "    elif 30 < predicted_crowd <= 70:\n",
        "        return 5  # Moderate crowd\n",
        "    elif 70 < predicted_crowd <= 100:\n",
        "        return 8  # High crowd\n",
        "    else:\n",
        "        return 10  # Maximum deployment for extreme congestion\n",
        "\n",
        "# Apply the function to create a new \"Staff Allocated\" column\n",
        "df[\"Staff Allocated\"] = df[\"People Count\"].apply(allocate_resources)\n",
        "\n",
        "# Save the modified dataset with staff allocation\n",
        "df.to_csv(\"people_count_with_staff.csv\", index=False)\n",
        "\n",
        "# Display the updated dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE4cDVqfLNqm",
        "outputId": "65ad7bbd-52ad-44c0-9984-e80c6e616ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ AI Model for Staff Allocation Trained Successfully!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Features (X) → Predicted People Count\n",
        "X = df[[\"People Count\"]]\n",
        "\n",
        "# Target (y) → Staff Allocated (Generated)\n",
        "y = df[\"Staff Allocated\"]\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "# Train a Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42,  min_samples_split=10)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"✅ AI Model for Staff Allocation Trained Successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHGj8n6YLUFQ",
        "outputId": "9fff5dda-73b1-4df5-9475-969e78645393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frame 1: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 2: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 3: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 4: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 5: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 6: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 7: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 8: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 9: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 10: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 11: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 12: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 13: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 14: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 15: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 16: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 17: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 18: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 19: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 20: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 21: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 22: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 23: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 24: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 25: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 26: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 27: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 28: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 29: Predicted Crowd = 26, AI-Recommended Staff = 2\n",
            "Frame 30: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 31: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 32: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 33: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 34: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 35: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 36: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 37: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 38: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 39: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 40: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 41: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 42: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 43: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 44: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 45: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 46: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 47: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 48: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 49: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 50: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 51: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 52: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 53: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 54: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 55: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 56: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 57: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 58: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 59: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 60: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 61: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 62: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 63: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 64: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 65: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 66: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 67: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 68: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 69: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 70: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 71: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 72: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 73: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 74: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 75: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 76: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 77: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 78: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 79: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 80: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 81: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 82: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 83: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 84: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 85: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 86: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 87: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 88: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 89: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 90: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 91: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 92: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 93: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 94: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 95: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 96: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 97: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 98: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 99: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 100: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 101: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 102: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 103: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 104: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 105: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 106: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 107: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 108: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 109: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 110: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 111: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 112: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 113: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 114: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 115: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 116: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 117: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 118: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 119: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 120: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 121: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 122: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 123: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 124: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 125: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 126: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 127: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 128: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 129: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 130: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 131: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 132: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 133: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 134: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 135: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 136: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 137: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 138: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 139: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 140: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 141: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 142: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 143: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 144: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 145: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 146: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 147: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 148: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 149: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 150: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 151: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 152: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 153: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 154: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 155: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 156: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 157: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 158: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 159: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 160: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 161: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 162: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 163: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 164: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 165: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 166: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 167: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 168: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 169: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 170: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 171: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 172: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 173: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 174: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 175: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 176: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 177: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 178: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 179: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 180: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 181: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 182: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 183: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 184: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 185: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 186: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 187: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 188: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 189: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 190: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 191: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 192: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 193: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 194: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 195: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 196: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 197: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 198: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 199: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 200: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 201: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 202: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 203: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 204: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 205: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 206: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 207: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 208: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 209: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 210: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 211: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 212: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 213: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 214: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 215: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 216: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 217: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 218: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 219: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 220: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 221: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 222: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 223: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 224: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 225: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 226: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 227: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 228: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 229: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 230: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 231: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 232: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 233: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 234: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 235: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 236: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 237: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 238: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 239: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 240: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 241: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 242: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 243: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 244: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 245: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 246: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 247: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 248: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 249: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 250: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 251: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 252: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 253: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 254: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 255: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 256: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 257: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 258: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 259: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 260: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 261: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 262: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 263: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 264: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 265: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 266: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 267: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 268: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 269: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 270: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 271: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 272: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 273: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 274: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 275: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 276: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 277: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 278: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 279: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 280: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 281: Predicted Crowd = 10, AI-Recommended Staff = 2\n",
            "Frame 282: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 283: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 284: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 285: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 286: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 287: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 288: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 289: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 290: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 291: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 292: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 293: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 294: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 295: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 296: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 297: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 298: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 299: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 300: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 301: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 302: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 303: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 304: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 305: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 306: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 307: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 308: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 309: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 310: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 311: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 312: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 313: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 314: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 315: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 316: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 317: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 318: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 319: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 320: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 321: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 322: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 323: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 324: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 325: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 326: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 327: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 328: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 329: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 330: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 331: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 332: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 333: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 334: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 335: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 336: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 337: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 338: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 339: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 340: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 341: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 342: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 343: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 344: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 345: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 346: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 347: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 348: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 349: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 350: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 351: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 352: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 353: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 354: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 355: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 356: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 357: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 358: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 359: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 360: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 361: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 362: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 363: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 364: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 365: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 366: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 367: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 368: Predicted Crowd = 13, AI-Recommended Staff = 2\n",
            "Frame 369: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 370: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 371: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 372: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 373: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 374: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 375: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 376: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 377: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 378: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 379: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 380: Predicted Crowd = 9, AI-Recommended Staff = 2\n",
            "Frame 381: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 382: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 383: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 384: Predicted Crowd = 11, AI-Recommended Staff = 2\n",
            "Frame 385: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 386: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 387: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 388: Predicted Crowd = 12, AI-Recommended Staff = 2\n",
            "Frame 389: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 390: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 391: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 392: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 393: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 394: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 395: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 396: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 397: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 398: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 399: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 400: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 401: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 402: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 403: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 404: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 405: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 406: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 407: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 408: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 409: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 410: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 411: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 412: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 413: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 414: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 415: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 416: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 417: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 418: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 419: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 420: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 421: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 422: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 423: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 424: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 425: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 426: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 427: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 428: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 429: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 430: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 431: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 432: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 433: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 434: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 435: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 436: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 437: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 438: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 439: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 440: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 441: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 442: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 443: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 444: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 445: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 446: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 447: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 448: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 449: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 450: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 451: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 452: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 453: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 454: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 455: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 456: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 457: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 458: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 459: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 460: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 461: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 462: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 463: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 464: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 465: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 466: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 467: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 468: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 469: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 470: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 471: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 472: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 473: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 474: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 475: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 476: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 477: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 478: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 479: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 480: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 481: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 482: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 483: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 484: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 485: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 486: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 487: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 488: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 489: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 490: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 491: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 492: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 493: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 494: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 495: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 496: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 497: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 498: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 499: Predicted Crowd = 26, AI-Recommended Staff = 2\n",
            "Frame 500: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 501: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 502: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 503: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 504: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 505: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 506: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 507: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 508: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 509: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 510: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 511: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 512: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 513: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 514: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 515: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 516: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 517: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 518: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 519: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 520: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 521: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 522: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 523: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 524: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 525: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 526: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 527: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 528: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 529: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 530: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 531: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 532: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 533: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 534: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 535: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 536: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 537: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 538: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 539: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 540: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 541: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 542: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 543: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 544: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 545: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 546: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 547: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 548: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 549: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 550: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 551: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 552: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 553: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 554: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 555: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 556: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 557: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 558: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 559: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 560: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 561: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 562: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 563: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 564: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 565: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 566: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 567: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 568: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 569: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 570: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 571: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 572: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 573: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 574: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 575: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 576: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 577: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 578: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 579: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 580: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 581: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 582: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 583: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 584: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 585: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 586: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 587: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 588: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 589: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 590: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 591: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 592: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 593: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 594: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 595: Predicted Crowd = 26, AI-Recommended Staff = 2\n",
            "Frame 596: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 597: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 598: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 599: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 600: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 601: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 602: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 603: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 604: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 605: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 606: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 607: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 608: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 609: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 610: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 611: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 612: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 613: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 614: Predicted Crowd = 27, AI-Recommended Staff = 2\n",
            "Frame 615: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 616: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 617: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 618: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 619: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 620: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 621: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 622: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 623: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 624: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 625: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 626: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 627: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 628: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 629: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 630: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 631: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 632: Predicted Crowd = 14, AI-Recommended Staff = 2\n",
            "Frame 633: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 634: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 635: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 636: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 637: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 638: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 639: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 640: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 641: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 642: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 643: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 644: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 645: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 646: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 647: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 648: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 649: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 650: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 651: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 652: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 653: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 654: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 655: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 656: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 657: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 658: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 659: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 660: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 661: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 662: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 663: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 664: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 665: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 666: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 667: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 668: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 669: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 670: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 671: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 672: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 673: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 674: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 675: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 676: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 677: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 678: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 679: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 680: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 681: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 682: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 683: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 684: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 685: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 686: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 687: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 688: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 689: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 690: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 691: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 692: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 693: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 694: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 695: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 696: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 697: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 698: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 699: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 700: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 701: Predicted Crowd = 27, AI-Recommended Staff = 2\n",
            "Frame 702: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 703: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 704: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 705: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 706: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 707: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 708: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 709: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 710: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 711: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 712: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 713: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 714: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 715: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 716: Predicted Crowd = 25, AI-Recommended Staff = 2\n",
            "Frame 717: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 718: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 719: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 720: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 721: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 722: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 723: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 724: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 725: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 726: Predicted Crowd = 20, AI-Recommended Staff = 2\n",
            "Frame 727: Predicted Crowd = 24, AI-Recommended Staff = 2\n",
            "Frame 728: Predicted Crowd = 23, AI-Recommended Staff = 2\n",
            "Frame 729: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 730: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 731: Predicted Crowd = 22, AI-Recommended Staff = 2\n",
            "Frame 732: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 733: Predicted Crowd = 21, AI-Recommended Staff = 2\n",
            "Frame 734: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 735: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 736: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 737: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 738: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 739: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 740: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 741: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 742: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 743: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 744: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 745: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 746: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 747: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 748: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 749: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 750: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 751: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 752: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 753: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 754: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 755: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 756: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 757: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 758: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 759: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 760: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 761: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 762: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 763: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 764: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 765: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 766: Predicted Crowd = 19, AI-Recommended Staff = 2\n",
            "Frame 767: Predicted Crowd = 16, AI-Recommended Staff = 2\n",
            "Frame 768: Predicted Crowd = 15, AI-Recommended Staff = 2\n",
            "Frame 769: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 770: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 771: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 772: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 773: Predicted Crowd = 18, AI-Recommended Staff = 2\n",
            "Frame 774: Predicted Crowd = 17, AI-Recommended Staff = 2\n",
            "Frame 775: Predicted Crowd = 18, AI-Recommended Staff = 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Get future predicted crowd sizes from the dataset\n",
        "future_predictions = df[\"People Count\"].tolist()\n",
        "\n",
        "# Predict the required number of staff for each future frame\n",
        "predicted_staff = rf_model.predict([[x] for x in future_predictions])\n",
        "\n",
        "# Display AI recommendations\n",
        "for frame, (crowd, staff) in enumerate(zip(future_predictions, predicted_staff), 1):\n",
        "    print(f\"Frame {frame}: Predicted Crowd = {crowd}, AI-Recommended Staff = {int(staff)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhk-dBldLm8o",
        "outputId": "04d2a31d-398f-4db3-b0ed-1fb51b959c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Model Accuracy Metrics:\n",
            "✅ Mean Absolute Error (MAE): 0.00\n",
            "✅ Mean Squared Error (MSE): 0.00\n",
            "✅ Root Mean Squared Error (RMSE): 0.00\n",
            "✅ R² Score: 1.00 (closer to 1 is better)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"📊 Model Accuracy Metrics:\")\n",
        "print(f\"✅ Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"✅ Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"✅ Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"✅ R² Score: {r2:.2f} (closer to 1 is better)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uee-tqaEMOzS",
        "outputId": "f008086e-2b78-4c24-94f6-837e2b1032ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Actual  Predicted\n",
            "428       2        2.0\n",
            "712       2        2.0\n",
            "326       2        2.0\n",
            "765       2        2.0\n",
            "361       2        2.0\n",
            "541       2        2.0\n",
            "737       2        2.0\n",
            "218       2        2.0\n",
            "120       2        2.0\n",
            "518       2        2.0\n"
          ]
        }
      ],
      "source": [
        "comparison = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
        "print(comparison.head(10))  # Show first 10 comparisons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6S59H93NiQa"
      },
      "outputs": [],
      "source": [
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "alert_threshold = 30  # Change as needed\n",
        "\n",
        "# SMTP server configuration\n",
        "SMTP_SERVER = \"smtp.mailersend.net\"\n",
        "SMTP_PORT = 587  # TLS port\n",
        "SENDER_EMAIL = \"\"\n",
        "PASSWORD = \"\"  # Replace with your actual password\n",
        "RECEIVER_EMAIL = \"\"\n",
        "\n",
        "def send_email_alert(frame, crowd):\n",
        "    subject = f\"🚨 ALERT: High Crowd Expected at Frame {frame}\"\n",
        "    body = f\"⚠️ Warning! High crowd of {crowd} people expected.\\nPlease allocate extra staff immediately!\"\n",
        "\n",
        "    msg = MIMEText(body)\n",
        "    msg[\"Subject\"] = subject\n",
        "    msg[\"From\"] = SENDER_EMAIL\n",
        "    msg[\"To\"] = RECEIVER_EMAIL\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
        "        server.starttls()\n",
        "        server.login(SENDER_EMAIL,PASSWORD)\n",
        "        server.sendmail(SENDER_EMAIL, RECEIVER_EMAIL, msg.as_string())\n",
        "        server.quit()\n",
        "        print(f\"📧 Email Alert Sent for Frame {frame}!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to send email: {e}\")\n",
        "\n",
        "# Loop through predictions and send email alerts if needed\n",
        "for frame, crowd in enumerate(future_predictions, 1):\n",
        "    if crowd > alert_threshold:\n",
        "        send_email_alert(frame, crowd)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
